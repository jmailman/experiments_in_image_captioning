{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "assisted-november",
   "metadata": {},
   "source": [
    "## 1 — Recognize objects in image (or classify image)\n",
    "\n",
    "Using trained NN, get object label or labels for image, or otherwise provide a label for the image. Also store the centrality of the object. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proper-neighborhood",
   "metadata": {},
   "source": [
    "## 2  — Generate semantic word families\n",
    "\n",
    "For each label, use Word2Vec `similar` to retrieve list of words semantically related to the image object labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-hampton",
   "metadata": {},
   "source": [
    "## 3 — Generate all related words\n",
    "\n",
    "For each semantically related (below a distance threshold) word to each object label, measure its phonetic similarity to all words in the dictionary. Also store each words's distance.\n",
    "\n",
    "For each word in each semantic family, sort and choose the phonetically closest (below a distance threshold) words.\n",
    "(One way is to convert the word to IPA and compare to an IPA converted version of every word in the CMU dictionary.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-norfolk",
   "metadata": {},
   "source": [
    "## 4 — Gather candidate phrases\n",
    "\n",
    "For each word in the phonetic family, of each word in the semantic family, of each object label, retrieve each idiom containing the word.\n",
    "Add the idiom Id, as well as the stats on the object centrality, semantic distance, and phonetic distance, to a dataframe.\n",
    "\n",
    "Compute _suitability score_ for each word-idiom match and add this to that column of the dataframe\n",
    "\n",
    "Also, for each word in the semantic family, search the joke list for match and add that these to a joke_match dataframe, to use if there's too low a suitability score using a substitution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-diving",
   "metadata": {},
   "source": [
    "## 5 — Choose captions\n",
    "\n",
    "Sort captions dataframe by the _suitability score_\n",
    "\n",
    "Choose the top 10 and generate a list containing each caption with the original semantic family word substituted into the idiom in addition to jokes containing any of the semantic family words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "suburban-sellers",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_topic=  'two'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "noted-repeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-reservation",
   "metadata": {},
   "source": [
    "## -1  — Webscrape and process phrases (idioms, sayings, aphorisms)\n",
    "\n",
    "They should be converted into lists of phonetic sounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-beast",
   "metadata": {},
   "source": [
    "## 0  — Load `phrase_dict` pickled and processed after being scraped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-visitor",
   "metadata": {},
   "source": [
    "#### Data structures defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "environmental-closer",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Phrase = namedtuple('Phrase',['text_string', 'word_list','phon_list','string_length', 'word_count', 'prefix', 'phrase_type'])\n",
    "phrase_dict = dict()\n",
    "\n",
    "Close_word = namedtuple('Close_word', ['word', 'distance'])\n",
    "\n",
    "Sem_family = namedtuple('Sem_family', ['locus_word', 'sem_fam_words'])\n",
    "\n",
    "Phon_family = namedtuple('Phon_family', ['locus_word', 'close_words'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-assessment",
   "metadata": {},
   "source": [
    "#### Temporary toy example of the dict of phrases, to be replaced with idioms etc. scraped from web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "union-rhythm",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_string = 'Smarter than the average bear'\n",
    "w_list = t_string.lower().split()\n",
    "ph_id1 = uuid.uuid1()\n",
    "phrase_dict[ph_id1] = Phrase(text_string = t_string, word_list = w_list, phon_list = w_list, string_length = len(t_string), word_count = len(w_list), prefix=\"As usual: \", phrase_type='idiom' )\n",
    "\n",
    "# toy example of the dict\n",
    "t_string = 'Not a hair out of place'\n",
    "w_list = t_string.lower().split()\n",
    "ph_id2 = uuid.uuid1()\n",
    "phrase_dict[ph_id2] = Phrase(text_string = t_string, word_list = w_list, phon_list = w_list, string_length = len(t_string), word_count = len(w_list), prefix=\"As usual: \", phrase_type='idiom' )\n",
    "\n",
    "# toy example of the dict\n",
    "t_string = 'Three blind mice'\n",
    "w_list = t_string.lower().split()\n",
    "ph_id3 = uuid.uuid1()\n",
    "phrase_dict[ph_id3] = Phrase(text_string = t_string, word_list = w_list, phon_list = w_list, string_length = len(t_string), word_count = len(w_list), prefix=\"As usual: \", phrase_type='idiom' )\n",
    "\n",
    "# toy example of the dict\n",
    "t_string = 'I just called to say I love you'\n",
    "w_list = t_string.lower().split()\n",
    "ph_id3 = uuid.uuid1()\n",
    "phrase_dict[ph_id3] = Phrase(text_string = t_string, word_list = w_list, phon_list = w_list, string_length = len(t_string), word_count = len(w_list), prefix=\"As usual: \", phrase_type='idiom' )\n",
    "\n",
    "t_string = 'Up, up in the air'\n",
    "w_list = t_string.lower().split()\n",
    "ph_id1 = uuid.uuid1()\n",
    "phrase_dict[ph_id1] = Phrase(text_string = t_string, word_list = w_list, phon_list = w_list, string_length = len(t_string), word_count = len(w_list), prefix=\"As usual: \", phrase_type='idiom' )\n",
    "\n",
    "t_string = 'Wouldn\\'t it be nice'\n",
    "w_list = t_string.lower().split()\n",
    "ph_id1 = uuid.uuid1()\n",
    "phrase_dict[ph_id1] = Phrase(text_string = t_string, word_list = w_list, phon_list = w_list, string_length = len(t_string), word_count = len(w_list), prefix=\"As usual: \", phrase_type='idiom' )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-wrestling",
   "metadata": {},
   "source": [
    "## 1 — Recognize objects in image (or classify image)\n",
    "\n",
    "Using trained NN, get object label or labels for image, or otherwise provide a label for the image. Also store the centrality of the object. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-kennedy",
   "metadata": {},
   "source": [
    "## 2 — Generate semantic word families\n",
    "\n",
    "For each label, use Word2Vec `similar` to retrieve list of words semantically related to the image object labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_synonyms( w ):\n",
    "    return [l.name() for l in wordnet.synsets( w )[0].lemmas()]  # There may be other synonyms in the synset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-mapping",
   "metadata": {},
   "source": [
    "## 3 — Generate all related words\n",
    "\n",
    "For each semantically related (below a distance threshold) word to each object label, measure its phonetic similarity to all words in the dictionary. Also store each words's distance.\n",
    "\n",
    "For each word in each semantic family, sort and choose the phonetically closest (below a distance threshold) words.\n",
    "(One way is to convert the word to IPA and compare to an IPA converted version of every word in the CMU dictionary.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "timely-bacteria",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_dictionary = ['two', 'pair', 'bear', 'scare', 'you', 'twice', 'hair', 'mice', 'speaker', 'book']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cordless-fairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two_phon_fam = Phon_family(locus_word=Close_word('two', 3), close_words = [Close_word('you', 2.1)])\n",
    "# two_phon_fam\n",
    "\n",
    "# pair_phon_fam = Phon_family(locus_word=Close_word('pair', 5), close_words = [Close_word('bear', 1.5), Close_word('hair', 2.7)])\n",
    "# pair_phon_fam\n",
    "\n",
    "# twice_phon_fam = Phon_family(locus_word=Close_word('twice', 4.1), close_words = [Close_word('mice', 2.1)])\n",
    "# twice_phon_fam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "confidential-homeless",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "included-discipline",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eng_to_ipa as ipa\n",
    "\n",
    "def syllable_count_diff( w1, w2 ):\n",
    "    return abs( ipa.syllable_count( w1 ) - ipa.syllable_count( w2 ))\n",
    "\n",
    "def same_syllable_count( w1, w2 ):\n",
    "    return syllable_count_diff(w1, w2) == 0\n",
    "\n",
    "def close_syllable_count( w1, w2, threshold=1):\n",
    "    return syllable_count_diff( w1, w2 ) <= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "clean-problem",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_sized_rhymes( w ):\n",
    "    word_length_min = 2\n",
    "    rhyme_list = ipa.get_rhymes( w )\n",
    "    return [ [rhyme for rhyme  in rhyme_list if same_syllable_count( w, rhyme) and len(rhyme) >= word_length_min]]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-holmes",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "previous-defendant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipa.isin_cmu('xue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "removable-croatia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['beu',\n",
       "  'bleu',\n",
       "  'blew',\n",
       "  'blue',\n",
       "  'boo',\n",
       "  'breaux',\n",
       "  'brew',\n",
       "  'brue',\n",
       "  'chew',\n",
       "  'chiu',\n",
       "  'choo',\n",
       "  'chou',\n",
       "  'chu',\n",
       "  'clue',\n",
       "  'coo',\n",
       "  'cou',\n",
       "  'coup',\n",
       "  'crew',\n",
       "  'crewe',\n",
       "  'cue',\n",
       "  'deux',\n",
       "  'dew',\n",
       "  'do',\n",
       "  'doo',\n",
       "  'douwe',\n",
       "  'drew',\n",
       "  'dru',\n",
       "  'du',\n",
       "  'due',\n",
       "  'ewe',\n",
       "  'few',\n",
       "  'flew',\n",
       "  'flu',\n",
       "  'flue',\n",
       "  'foo',\n",
       "  'frew',\n",
       "  'frueh',\n",
       "  'fu',\n",
       "  'geroux',\n",
       "  'glew',\n",
       "  'glue',\n",
       "  'gnu',\n",
       "  'goo',\n",
       "  'graue',\n",
       "  'grew',\n",
       "  'grewe',\n",
       "  'gu',\n",
       "  'gue',\n",
       "  'heroux',\n",
       "  'hew',\n",
       "  'hewe',\n",
       "  'hoo',\n",
       "  'hou',\n",
       "  'houx',\n",
       "  'hsu',\n",
       "  'hu',\n",
       "  'hue',\n",
       "  'hugh',\n",
       "  'jew',\n",
       "  'joo',\n",
       "  'ju',\n",
       "  'jue',\n",
       "  'jus',\n",
       "  'kew',\n",
       "  'khoo',\n",
       "  'khuu',\n",
       "  'klu',\n",
       "  'knew',\n",
       "  'koo',\n",
       "  'ku',\n",
       "  'kyu',\n",
       "  'laroux',\n",
       "  'larue',\n",
       "  'leroux',\n",
       "  'leu',\n",
       "  'lew',\n",
       "  'lieu',\n",
       "  'liou',\n",
       "  'liu',\n",
       "  'loo',\n",
       "  'lou',\n",
       "  'louw',\n",
       "  'loux',\n",
       "  'lu',\n",
       "  'lue',\n",
       "  'mew',\n",
       "  'moo',\n",
       "  'mu',\n",
       "  'new',\n",
       "  'nu',\n",
       "  'ooh',\n",
       "  'oooh',\n",
       "  'ou',\n",
       "  'peru',\n",
       "  'peugh',\n",
       "  'pew',\n",
       "  'phew',\n",
       "  'phu',\n",
       "  'plew',\n",
       "  'plue',\n",
       "  'poo',\n",
       "  'pooh',\n",
       "  'pou',\n",
       "  'prew',\n",
       "  'pru',\n",
       "  'prue',\n",
       "  'prugh',\n",
       "  'pshew',\n",
       "  'pu',\n",
       "  'pugh',\n",
       "  'q.',\n",
       "  'qu',\n",
       "  'que',\n",
       "  'queue',\n",
       "  'raoux',\n",
       "  'rew',\n",
       "  'rhew',\n",
       "  'rhue',\n",
       "  'rioux',\n",
       "  'roux',\n",
       "  'ru',\n",
       "  'rue',\n",
       "  'schewe',\n",
       "  'schoo',\n",
       "  'schou',\n",
       "  'schue',\n",
       "  'schuh',\n",
       "  'screw',\n",
       "  'shew',\n",
       "  'shiu',\n",
       "  'shoe',\n",
       "  'shoo',\n",
       "  'shu',\n",
       "  'shue',\n",
       "  'siew',\n",
       "  'sioux',\n",
       "  'skew',\n",
       "  'slew',\n",
       "  'soo',\n",
       "  'spew',\n",
       "  'stew',\n",
       "  'strew',\n",
       "  'stu',\n",
       "  'stuewe',\n",
       "  'su',\n",
       "  'sue',\n",
       "  'theroux',\n",
       "  'thew',\n",
       "  'threw',\n",
       "  'through',\n",
       "  'thru',\n",
       "  'tieu',\n",
       "  'toyoo',\n",
       "  'treu',\n",
       "  'trew',\n",
       "  'trieu',\n",
       "  'troyu',\n",
       "  'true',\n",
       "  'tsu',\n",
       "  'u.',\n",
       "  'uwe',\n",
       "  'view',\n",
       "  'vous',\n",
       "  'vu',\n",
       "  'vue',\n",
       "  'whew',\n",
       "  'who',\n",
       "  'whoo',\n",
       "  'woo',\n",
       "  'wu',\n",
       "  'xu',\n",
       "  'xue',\n",
       "  'yew',\n",
       "  'yoo',\n",
       "  'you',\n",
       "  'yu',\n",
       "  'yue',\n",
       "  'zhou',\n",
       "  'zhu',\n",
       "  'zoo',\n",
       "  'zue']]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sized_rhymes('two')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-programmer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "resident-germany",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Temporary stand-in function, to be replaced with one that computes phonetic distance\n",
    "def lev_dist( phon1, phon2 ):\n",
    "    return 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "sporting-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "two_fam_member_list = ['you']\n",
    "pair_fam_member_list = ['bear', 'hair']\n",
    "twice_fam_member_list = ['mice']\n",
    "\n",
    "def make_phon_fam_for_sem_fam_member( w_record, thresh=.2 ):\n",
    "    w_phon_code = w_record.word # To be replaced with phonetic version if needed\n",
    "    close_word_list = []\n",
    "    \n",
    "    # Find words that are not necessarily rhyms but phonetically similar\n",
    "    for word in english_dictionary:\n",
    "        word_phon_code = word\n",
    "        dist = lev_dist(w_phon_code, word_phon_code)\n",
    "        if dist < thresh:\n",
    "            close_word_list.append( Close_word(word, dist) )\n",
    "    \n",
    "    rhyme_dist = .1 + random()/10\n",
    "    rhyme_word_list = get_sized_rhymes( w_record.word )[0]\n",
    "    \n",
    "    # Find words that are rhymes\n",
    "    for word in rhyme_word_list:\n",
    "         close_word_list.append( Close_word(word, rhyme_dist) )\n",
    "    \n",
    "    return Phon_family(locus_word = w_record, close_words=close_word_list )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-blanket",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fiscal-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two_phon_fam = get_phon_fam_for_sem_fam_member( 'two' )\n",
    "# pair_phon_fam = get_phon_fam_for_sem_fam_member( 'pair' )\n",
    "# twice_phon_fam = get_phon_fam_for_sem_fam_member( 'twice' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "double-cover",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALERT:  Need to incorporate the semantic distance somewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "indie-nancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two_sem_fam = Sem_family(locus_word='two', phon_fams = [make_phon_fam_for_sem_fam_member( 'two' ), \\\n",
    "#                                                         make_phon_fam_for_sem_fam_member( 'pair' ), \\\n",
    "#                                                         make_phon_fam_for_sem_fam_member( 'twice' )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "remarkable-ribbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be replaced with Word2Vec `most_similar()`\n",
    "\n",
    "def get_most_similar_obsolete( w ):  \n",
    "    list_of_duples =  [('pair', .95), ('twice', .90)]\n",
    "    list_of_close_words = [Close_word( word=w_str, distance= 1 - w_sim) for w_str, w_sim in list_of_duples ]\n",
    "        \n",
    "    return list_of_close_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "suburban-video",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_similar( w ):  \n",
    "    list_of_duples = [(syn, 1) for syn in get_synonyms( w )]\n",
    "    if(w == 'two'):\n",
    "        additional_words =  [('pair', .95), ('twice', .90)]\n",
    "        list_of_duples.extend( additional_words )\n",
    "    list_of_close_words = [Close_word( word=w_str, distance= 1 - w_sim) for w_str, w_sim in list_of_duples ]\n",
    "        \n",
    "    return list_of_close_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "specific-fusion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Close_word(word='three', distance=0),\n",
       " Close_word(word='3', distance=0),\n",
       " Close_word(word='III', distance=0),\n",
       " Close_word(word='trio', distance=0),\n",
       " Close_word(word='threesome', distance=0),\n",
       " Close_word(word='tierce', distance=0),\n",
       " Close_word(word='leash', distance=0),\n",
       " Close_word(word='troika', distance=0),\n",
       " Close_word(word='triad', distance=0),\n",
       " Close_word(word='trine', distance=0),\n",
       " Close_word(word='trinity', distance=0),\n",
       " Close_word(word='ternary', distance=0),\n",
       " Close_word(word='ternion', distance=0),\n",
       " Close_word(word='triplet', distance=0),\n",
       " Close_word(word='tercet', distance=0),\n",
       " Close_word(word='terzetto', distance=0),\n",
       " Close_word(word='trey', distance=0),\n",
       " Close_word(word='deuce-ace', distance=0)]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_most_similar( 'three' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "corrected-slope",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_phon_fams_and_sem_family( w ):\n",
    "    word_record_ = Close_word(w, 0.0)\n",
    "    \n",
    "    sem_sim_words = get_most_similar( w )  # Eventually replace with call to Word2Vec\n",
    "    \n",
    "    phon_fams_list = [make_phon_fam_for_sem_fam_member( word_record_  )]\n",
    "    \n",
    "    for close_w_record in sem_sim_words:\n",
    "        print( close_w_record )\n",
    "        phon_fams_list.append( make_phon_fam_for_sem_fam_member( close_w_record ) )\n",
    "    \n",
    "    return Sem_family(locus_word= word_record_, sem_fam_words = phon_fams_list)\n",
    "   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "recovered-aaron",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Close_word(word='two', distance=0)\n",
      "Close_word(word='2', distance=0)\n",
      "Close_word(word='II', distance=0)\n",
      "Close_word(word='deuce', distance=0)\n",
      "Close_word(word='pair', distance=0.050000000000000044)\n",
      "Close_word(word='twice', distance=0.09999999999999998)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sem_family(locus_word=Close_word(word='two', distance=0.0), sem_fam_words=[Phon_family(locus_word=Close_word(word='two', distance=0.0), close_words=[Close_word(word='beu', distance=0.16464397316487445), Close_word(word='bleu', distance=0.16464397316487445), Close_word(word='blew', distance=0.16464397316487445), Close_word(word='blue', distance=0.16464397316487445), Close_word(word='boo', distance=0.16464397316487445), Close_word(word='breaux', distance=0.16464397316487445), Close_word(word='brew', distance=0.16464397316487445), Close_word(word='brue', distance=0.16464397316487445), Close_word(word='chew', distance=0.16464397316487445), Close_word(word='chiu', distance=0.16464397316487445), Close_word(word='choo', distance=0.16464397316487445), Close_word(word='chou', distance=0.16464397316487445), Close_word(word='chu', distance=0.16464397316487445), Close_word(word='clue', distance=0.16464397316487445), Close_word(word='coo', distance=0.16464397316487445), Close_word(word='cou', distance=0.16464397316487445), Close_word(word='coup', distance=0.16464397316487445), Close_word(word='crew', distance=0.16464397316487445), Close_word(word='crewe', distance=0.16464397316487445), Close_word(word='cue', distance=0.16464397316487445), Close_word(word='deux', distance=0.16464397316487445), Close_word(word='dew', distance=0.16464397316487445), Close_word(word='do', distance=0.16464397316487445), Close_word(word='doo', distance=0.16464397316487445), Close_word(word='douwe', distance=0.16464397316487445), Close_word(word='drew', distance=0.16464397316487445), Close_word(word='dru', distance=0.16464397316487445), Close_word(word='du', distance=0.16464397316487445), Close_word(word='due', distance=0.16464397316487445), Close_word(word='ewe', distance=0.16464397316487445), Close_word(word='few', distance=0.16464397316487445), Close_word(word='flew', distance=0.16464397316487445), Close_word(word='flu', distance=0.16464397316487445), Close_word(word='flue', distance=0.16464397316487445), Close_word(word='foo', distance=0.16464397316487445), Close_word(word='frew', distance=0.16464397316487445), Close_word(word='frueh', distance=0.16464397316487445), Close_word(word='fu', distance=0.16464397316487445), Close_word(word='geroux', distance=0.16464397316487445), Close_word(word='glew', distance=0.16464397316487445), Close_word(word='glue', distance=0.16464397316487445), Close_word(word='gnu', distance=0.16464397316487445), Close_word(word='goo', distance=0.16464397316487445), Close_word(word='graue', distance=0.16464397316487445), Close_word(word='grew', distance=0.16464397316487445), Close_word(word='grewe', distance=0.16464397316487445), Close_word(word='gu', distance=0.16464397316487445), Close_word(word='gue', distance=0.16464397316487445), Close_word(word='heroux', distance=0.16464397316487445), Close_word(word='hew', distance=0.16464397316487445), Close_word(word='hewe', distance=0.16464397316487445), Close_word(word='hoo', distance=0.16464397316487445), Close_word(word='hou', distance=0.16464397316487445), Close_word(word='houx', distance=0.16464397316487445), Close_word(word='hsu', distance=0.16464397316487445), Close_word(word='hu', distance=0.16464397316487445), Close_word(word='hue', distance=0.16464397316487445), Close_word(word='hugh', distance=0.16464397316487445), Close_word(word='jew', distance=0.16464397316487445), Close_word(word='joo', distance=0.16464397316487445), Close_word(word='ju', distance=0.16464397316487445), Close_word(word='jue', distance=0.16464397316487445), Close_word(word='jus', distance=0.16464397316487445), Close_word(word='kew', distance=0.16464397316487445), Close_word(word='khoo', distance=0.16464397316487445), Close_word(word='khuu', distance=0.16464397316487445), Close_word(word='klu', distance=0.16464397316487445), Close_word(word='knew', distance=0.16464397316487445), Close_word(word='koo', distance=0.16464397316487445), Close_word(word='ku', distance=0.16464397316487445), Close_word(word='kyu', distance=0.16464397316487445), Close_word(word='laroux', distance=0.16464397316487445), Close_word(word='larue', distance=0.16464397316487445), Close_word(word='leroux', distance=0.16464397316487445), Close_word(word='leu', distance=0.16464397316487445), Close_word(word='lew', distance=0.16464397316487445), Close_word(word='lieu', distance=0.16464397316487445), Close_word(word='liou', distance=0.16464397316487445), Close_word(word='liu', distance=0.16464397316487445), Close_word(word='loo', distance=0.16464397316487445), Close_word(word='lou', distance=0.16464397316487445), Close_word(word='louw', distance=0.16464397316487445), Close_word(word='loux', distance=0.16464397316487445), Close_word(word='lu', distance=0.16464397316487445), Close_word(word='lue', distance=0.16464397316487445), Close_word(word='mew', distance=0.16464397316487445), Close_word(word='moo', distance=0.16464397316487445), Close_word(word='mu', distance=0.16464397316487445), Close_word(word='new', distance=0.16464397316487445), Close_word(word='nu', distance=0.16464397316487445), Close_word(word='ooh', distance=0.16464397316487445), Close_word(word='oooh', distance=0.16464397316487445), Close_word(word='ou', distance=0.16464397316487445), Close_word(word='peru', distance=0.16464397316487445), Close_word(word='peugh', distance=0.16464397316487445), Close_word(word='pew', distance=0.16464397316487445), Close_word(word='phew', distance=0.16464397316487445), Close_word(word='phu', distance=0.16464397316487445), Close_word(word='plew', distance=0.16464397316487445), Close_word(word='plue', distance=0.16464397316487445), Close_word(word='poo', distance=0.16464397316487445), Close_word(word='pooh', distance=0.16464397316487445), Close_word(word='pou', distance=0.16464397316487445), Close_word(word='prew', distance=0.16464397316487445), Close_word(word='pru', distance=0.16464397316487445), Close_word(word='prue', distance=0.16464397316487445), Close_word(word='prugh', distance=0.16464397316487445), Close_word(word='pshew', distance=0.16464397316487445), Close_word(word='pu', distance=0.16464397316487445), Close_word(word='pugh', distance=0.16464397316487445), Close_word(word='q.', distance=0.16464397316487445), Close_word(word='qu', distance=0.16464397316487445), Close_word(word='que', distance=0.16464397316487445), Close_word(word='queue', distance=0.16464397316487445), Close_word(word='raoux', distance=0.16464397316487445), Close_word(word='rew', distance=0.16464397316487445), Close_word(word='rhew', distance=0.16464397316487445), Close_word(word='rhue', distance=0.16464397316487445), Close_word(word='rioux', distance=0.16464397316487445), Close_word(word='roux', distance=0.16464397316487445), Close_word(word='ru', distance=0.16464397316487445), Close_word(word='rue', distance=0.16464397316487445), Close_word(word='schewe', distance=0.16464397316487445), Close_word(word='schoo', distance=0.16464397316487445), Close_word(word='schou', distance=0.16464397316487445), Close_word(word='schue', distance=0.16464397316487445), Close_word(word='schuh', distance=0.16464397316487445), Close_word(word='screw', distance=0.16464397316487445), Close_word(word='shew', distance=0.16464397316487445), Close_word(word='shiu', distance=0.16464397316487445), Close_word(word='shoe', distance=0.16464397316487445), Close_word(word='shoo', distance=0.16464397316487445), Close_word(word='shu', distance=0.16464397316487445), Close_word(word='shue', distance=0.16464397316487445), Close_word(word='siew', distance=0.16464397316487445), Close_word(word='sioux', distance=0.16464397316487445), Close_word(word='skew', distance=0.16464397316487445), Close_word(word='slew', distance=0.16464397316487445), Close_word(word='soo', distance=0.16464397316487445), Close_word(word='spew', distance=0.16464397316487445), Close_word(word='stew', distance=0.16464397316487445), Close_word(word='strew', distance=0.16464397316487445), Close_word(word='stu', distance=0.16464397316487445), Close_word(word='stuewe', distance=0.16464397316487445), Close_word(word='su', distance=0.16464397316487445), Close_word(word='sue', distance=0.16464397316487445), Close_word(word='theroux', distance=0.16464397316487445), Close_word(word='thew', distance=0.16464397316487445), Close_word(word='threw', distance=0.16464397316487445), Close_word(word='through', distance=0.16464397316487445), Close_word(word='thru', distance=0.16464397316487445), Close_word(word='tieu', distance=0.16464397316487445), Close_word(word='toyoo', distance=0.16464397316487445), Close_word(word='treu', distance=0.16464397316487445), Close_word(word='trew', distance=0.16464397316487445), Close_word(word='trieu', distance=0.16464397316487445), Close_word(word='troyu', distance=0.16464397316487445), Close_word(word='true', distance=0.16464397316487445), Close_word(word='tsu', distance=0.16464397316487445), Close_word(word='u.', distance=0.16464397316487445), Close_word(word='uwe', distance=0.16464397316487445), Close_word(word='view', distance=0.16464397316487445), Close_word(word='vous', distance=0.16464397316487445), Close_word(word='vu', distance=0.16464397316487445), Close_word(word='vue', distance=0.16464397316487445), Close_word(word='whew', distance=0.16464397316487445), Close_word(word='who', distance=0.16464397316487445), Close_word(word='whoo', distance=0.16464397316487445), Close_word(word='woo', distance=0.16464397316487445), Close_word(word='wu', distance=0.16464397316487445), Close_word(word='xu', distance=0.16464397316487445), Close_word(word='xue', distance=0.16464397316487445), Close_word(word='yew', distance=0.16464397316487445), Close_word(word='yoo', distance=0.16464397316487445), Close_word(word='you', distance=0.16464397316487445), Close_word(word='yu', distance=0.16464397316487445), Close_word(word='yue', distance=0.16464397316487445), Close_word(word='zhou', distance=0.16464397316487445), Close_word(word='zhu', distance=0.16464397316487445), Close_word(word='zoo', distance=0.16464397316487445), Close_word(word='zue', distance=0.16464397316487445)]), Phon_family(locus_word=Close_word(word='two', distance=0), close_words=[Close_word(word='beu', distance=0.1622067308253734), Close_word(word='bleu', distance=0.1622067308253734), Close_word(word='blew', distance=0.1622067308253734), Close_word(word='blue', distance=0.1622067308253734), Close_word(word='boo', distance=0.1622067308253734), Close_word(word='breaux', distance=0.1622067308253734), Close_word(word='brew', distance=0.1622067308253734), Close_word(word='brue', distance=0.1622067308253734), Close_word(word='chew', distance=0.1622067308253734), Close_word(word='chiu', distance=0.1622067308253734), Close_word(word='choo', distance=0.1622067308253734), Close_word(word='chou', distance=0.1622067308253734), Close_word(word='chu', distance=0.1622067308253734), Close_word(word='clue', distance=0.1622067308253734), Close_word(word='coo', distance=0.1622067308253734), Close_word(word='cou', distance=0.1622067308253734), Close_word(word='coup', distance=0.1622067308253734), Close_word(word='crew', distance=0.1622067308253734), Close_word(word='crewe', distance=0.1622067308253734), Close_word(word='cue', distance=0.1622067308253734), Close_word(word='deux', distance=0.1622067308253734), Close_word(word='dew', distance=0.1622067308253734), Close_word(word='do', distance=0.1622067308253734), Close_word(word='doo', distance=0.1622067308253734), Close_word(word='douwe', distance=0.1622067308253734), Close_word(word='drew', distance=0.1622067308253734), Close_word(word='dru', distance=0.1622067308253734), Close_word(word='du', distance=0.1622067308253734), Close_word(word='due', distance=0.1622067308253734), Close_word(word='ewe', distance=0.1622067308253734), Close_word(word='few', distance=0.1622067308253734), Close_word(word='flew', distance=0.1622067308253734), Close_word(word='flu', distance=0.1622067308253734), Close_word(word='flue', distance=0.1622067308253734), Close_word(word='foo', distance=0.1622067308253734), Close_word(word='frew', distance=0.1622067308253734), Close_word(word='frueh', distance=0.1622067308253734), Close_word(word='fu', distance=0.1622067308253734), Close_word(word='geroux', distance=0.1622067308253734), Close_word(word='glew', distance=0.1622067308253734), Close_word(word='glue', distance=0.1622067308253734), Close_word(word='gnu', distance=0.1622067308253734), Close_word(word='goo', distance=0.1622067308253734), Close_word(word='graue', distance=0.1622067308253734), Close_word(word='grew', distance=0.1622067308253734), Close_word(word='grewe', distance=0.1622067308253734), Close_word(word='gu', distance=0.1622067308253734), Close_word(word='gue', distance=0.1622067308253734), Close_word(word='heroux', distance=0.1622067308253734), Close_word(word='hew', distance=0.1622067308253734), Close_word(word='hewe', distance=0.1622067308253734), Close_word(word='hoo', distance=0.1622067308253734), Close_word(word='hou', distance=0.1622067308253734), Close_word(word='houx', distance=0.1622067308253734), Close_word(word='hsu', distance=0.1622067308253734), Close_word(word='hu', distance=0.1622067308253734), Close_word(word='hue', distance=0.1622067308253734), Close_word(word='hugh', distance=0.1622067308253734), Close_word(word='jew', distance=0.1622067308253734), Close_word(word='joo', distance=0.1622067308253734), Close_word(word='ju', distance=0.1622067308253734), Close_word(word='jue', distance=0.1622067308253734), Close_word(word='jus', distance=0.1622067308253734), Close_word(word='kew', distance=0.1622067308253734), Close_word(word='khoo', distance=0.1622067308253734), Close_word(word='khuu', distance=0.1622067308253734), Close_word(word='klu', distance=0.1622067308253734), Close_word(word='knew', distance=0.1622067308253734), Close_word(word='koo', distance=0.1622067308253734), Close_word(word='ku', distance=0.1622067308253734), Close_word(word='kyu', distance=0.1622067308253734), Close_word(word='laroux', distance=0.1622067308253734), Close_word(word='larue', distance=0.1622067308253734), Close_word(word='leroux', distance=0.1622067308253734), Close_word(word='leu', distance=0.1622067308253734), Close_word(word='lew', distance=0.1622067308253734), Close_word(word='lieu', distance=0.1622067308253734), Close_word(word='liou', distance=0.1622067308253734), Close_word(word='liu', distance=0.1622067308253734), Close_word(word='loo', distance=0.1622067308253734), Close_word(word='lou', distance=0.1622067308253734), Close_word(word='louw', distance=0.1622067308253734), Close_word(word='loux', distance=0.1622067308253734), Close_word(word='lu', distance=0.1622067308253734), Close_word(word='lue', distance=0.1622067308253734), Close_word(word='mew', distance=0.1622067308253734), Close_word(word='moo', distance=0.1622067308253734), Close_word(word='mu', distance=0.1622067308253734), Close_word(word='new', distance=0.1622067308253734), Close_word(word='nu', distance=0.1622067308253734), Close_word(word='ooh', distance=0.1622067308253734), Close_word(word='oooh', distance=0.1622067308253734), Close_word(word='ou', distance=0.1622067308253734), Close_word(word='peru', distance=0.1622067308253734), Close_word(word='peugh', distance=0.1622067308253734), Close_word(word='pew', distance=0.1622067308253734), Close_word(word='phew', distance=0.1622067308253734), Close_word(word='phu', distance=0.1622067308253734), Close_word(word='plew', distance=0.1622067308253734), Close_word(word='plue', distance=0.1622067308253734), Close_word(word='poo', distance=0.1622067308253734), Close_word(word='pooh', distance=0.1622067308253734), Close_word(word='pou', distance=0.1622067308253734), Close_word(word='prew', distance=0.1622067308253734), Close_word(word='pru', distance=0.1622067308253734), Close_word(word='prue', distance=0.1622067308253734), Close_word(word='prugh', distance=0.1622067308253734), Close_word(word='pshew', distance=0.1622067308253734), Close_word(word='pu', distance=0.1622067308253734), Close_word(word='pugh', distance=0.1622067308253734), Close_word(word='q.', distance=0.1622067308253734), Close_word(word='qu', distance=0.1622067308253734), Close_word(word='que', distance=0.1622067308253734), Close_word(word='queue', distance=0.1622067308253734), Close_word(word='raoux', distance=0.1622067308253734), Close_word(word='rew', distance=0.1622067308253734), Close_word(word='rhew', distance=0.1622067308253734), Close_word(word='rhue', distance=0.1622067308253734), Close_word(word='rioux', distance=0.1622067308253734), Close_word(word='roux', distance=0.1622067308253734), Close_word(word='ru', distance=0.1622067308253734), Close_word(word='rue', distance=0.1622067308253734), Close_word(word='schewe', distance=0.1622067308253734), Close_word(word='schoo', distance=0.1622067308253734), Close_word(word='schou', distance=0.1622067308253734), Close_word(word='schue', distance=0.1622067308253734), Close_word(word='schuh', distance=0.1622067308253734), Close_word(word='screw', distance=0.1622067308253734), Close_word(word='shew', distance=0.1622067308253734), Close_word(word='shiu', distance=0.1622067308253734), Close_word(word='shoe', distance=0.1622067308253734), Close_word(word='shoo', distance=0.1622067308253734), Close_word(word='shu', distance=0.1622067308253734), Close_word(word='shue', distance=0.1622067308253734), Close_word(word='siew', distance=0.1622067308253734), Close_word(word='sioux', distance=0.1622067308253734), Close_word(word='skew', distance=0.1622067308253734), Close_word(word='slew', distance=0.1622067308253734), Close_word(word='soo', distance=0.1622067308253734), Close_word(word='spew', distance=0.1622067308253734), Close_word(word='stew', distance=0.1622067308253734), Close_word(word='strew', distance=0.1622067308253734), Close_word(word='stu', distance=0.1622067308253734), Close_word(word='stuewe', distance=0.1622067308253734), Close_word(word='su', distance=0.1622067308253734), Close_word(word='sue', distance=0.1622067308253734), Close_word(word='theroux', distance=0.1622067308253734), Close_word(word='thew', distance=0.1622067308253734), Close_word(word='threw', distance=0.1622067308253734), Close_word(word='through', distance=0.1622067308253734), Close_word(word='thru', distance=0.1622067308253734), Close_word(word='tieu', distance=0.1622067308253734), Close_word(word='toyoo', distance=0.1622067308253734), Close_word(word='treu', distance=0.1622067308253734), Close_word(word='trew', distance=0.1622067308253734), Close_word(word='trieu', distance=0.1622067308253734), Close_word(word='troyu', distance=0.1622067308253734), Close_word(word='true', distance=0.1622067308253734), Close_word(word='tsu', distance=0.1622067308253734), Close_word(word='u.', distance=0.1622067308253734), Close_word(word='uwe', distance=0.1622067308253734), Close_word(word='view', distance=0.1622067308253734), Close_word(word='vous', distance=0.1622067308253734), Close_word(word='vu', distance=0.1622067308253734), Close_word(word='vue', distance=0.1622067308253734), Close_word(word='whew', distance=0.1622067308253734), Close_word(word='who', distance=0.1622067308253734), Close_word(word='whoo', distance=0.1622067308253734), Close_word(word='woo', distance=0.1622067308253734), Close_word(word='wu', distance=0.1622067308253734), Close_word(word='xu', distance=0.1622067308253734), Close_word(word='xue', distance=0.1622067308253734), Close_word(word='yew', distance=0.1622067308253734), Close_word(word='yoo', distance=0.1622067308253734), Close_word(word='you', distance=0.1622067308253734), Close_word(word='yu', distance=0.1622067308253734), Close_word(word='yue', distance=0.1622067308253734), Close_word(word='zhou', distance=0.1622067308253734), Close_word(word='zhu', distance=0.1622067308253734), Close_word(word='zoo', distance=0.1622067308253734), Close_word(word='zue', distance=0.1622067308253734)]), Phon_family(locus_word=Close_word(word='2', distance=0), close_words=[]), Phon_family(locus_word=Close_word(word='II', distance=0), close_words=[]), Phon_family(locus_word=Close_word(word='deuce', distance=0), close_words=[Close_word(word='boose', distance=0.183761107418429), Close_word(word='bruce', distance=0.183761107418429), Close_word(word='cheuse', distance=0.183761107418429), Close_word(word='coos', distance=0.183761107418429), Close_word(word='cruce', distance=0.183761107418429), Close_word(word='derousse', distance=0.183761107418429), Close_word(word='druce', distance=0.183761107418429), Close_word(word='foose', distance=0.183761107418429), Close_word(word='fuoss', distance=0.183761107418429), Close_word(word='goose', distance=0.183761107418429), Close_word(word='hoose', distance=0.183761107418429), Close_word(word='juice', distance=0.183761107418429), Close_word(word='loose', distance=0.183761107418429), Close_word(word='luce', distance=0.183761107418429), Close_word(word='moose', distance=0.183761107418429), Close_word(word='mousse', distance=0.183761107418429), Close_word(word='noose', distance=0.183761107418429), Close_word(word='nous', distance=0.183761107418429), Close_word(word='preuss', distance=0.183761107418429), Close_word(word='pruess', distance=0.183761107418429), Close_word(word='reuss', distance=0.183761107418429), Close_word(word='ruess', distance=0.183761107418429), Close_word(word='seuss', distance=0.183761107418429), Close_word(word='sluice', distance=0.183761107418429), Close_word(word='spruce', distance=0.183761107418429), Close_word(word='truce', distance=0.183761107418429), Close_word(word='tyus', distance=0.183761107418429), Close_word(word='use', distance=0.183761107418429), Close_word(word='yous', distance=0.183761107418429), Close_word(word='zeus', distance=0.183761107418429)]), Phon_family(locus_word=Close_word(word='pair', distance=0.050000000000000044), close_words=[Close_word(word='aer', distance=0.14108032588735359), Close_word(word='air', distance=0.14108032588735359), Close_word(word='ayre', distance=0.14108032588735359), Close_word(word='baehr', distance=0.14108032588735359), Close_word(word='baer', distance=0.14108032588735359), Close_word(word='bahr', distance=0.14108032588735359), Close_word(word='bair', distance=0.14108032588735359), Close_word(word='bare', distance=0.14108032588735359), Close_word(word='bear', distance=0.14108032588735359), Close_word(word='behr', distance=0.14108032588735359), Close_word(word='blair', distance=0.14108032588735359), Close_word(word='blare', distance=0.14108032588735359), Close_word(word='caire', distance=0.14108032588735359), Close_word(word='care', distance=0.14108032588735359), Close_word(word='chair', distance=0.14108032588735359), Close_word(word='cher', distance=0.14108032588735359), Close_word(word='clair', distance=0.14108032588735359), Close_word(word='claire', distance=0.14108032588735359), Close_word(word='clare', distance=0.14108032588735359), Close_word(word='dare', distance=0.14108032588735359), Close_word(word='darr', distance=0.14108032588735359), Close_word(word='derr', distance=0.14108032588735359), Close_word(word='dreher', distance=0.14108032588735359), Close_word(word='ere', distance=0.14108032588735359), Close_word(word='err', distance=0.14108032588735359), Close_word(word='eyre', distance=0.14108032588735359), Close_word(word='fair', distance=0.14108032588735359), Close_word(word='faire', distance=0.14108032588735359), Close_word(word='fare', distance=0.14108032588735359), Close_word(word='fehr', distance=0.14108032588735359), Close_word(word='fer', distance=0.14108032588735359), Close_word(word='ferre', distance=0.14108032588735359), Close_word(word='flair', distance=0.14108032588735359), Close_word(word='flare', distance=0.14108032588735359), Close_word(word='fraire', distance=0.14108032588735359), Close_word(word='frere', distance=0.14108032588735359), Close_word(word='freyre', distance=0.14108032588735359), Close_word(word='gair', distance=0.14108032588735359), Close_word(word='gare', distance=0.14108032588735359), Close_word(word='gehr', distance=0.14108032588735359), Close_word(word='glare', distance=0.14108032588735359), Close_word(word='guerre', distance=0.14108032588735359), Close_word(word='hair', distance=0.14108032588735359), Close_word(word='haire', distance=0.14108032588735359), Close_word(word='hairr', distance=0.14108032588735359), Close_word(word='hare', distance=0.14108032588735359), Close_word(word='hehr', distance=0.14108032588735359), Close_word(word='heir', distance=0.14108032588735359), Close_word(word='herr', distance=0.14108032588735359), Close_word(word='herre', distance=0.14108032588735359), Close_word(word='kahre', distance=0.14108032588735359), Close_word(word='kehr', distance=0.14108032588735359), Close_word(word='khmer', distance=0.14108032588735359), Close_word(word='klare', distance=0.14108032588735359), Close_word(word='knerr', distance=0.14108032588735359), Close_word(word='kreher', distance=0.14108032588735359), Close_word(word='lair', distance=0.14108032588735359), Close_word(word='lare', distance=0.14108032588735359), Close_word(word='lehr', distance=0.14108032588735359), Close_word(word='mair', distance=0.14108032588735359), Close_word(word='maire', distance=0.14108032588735359), Close_word(word='mare', distance=0.14108032588735359), Close_word(word='mehr', distance=0.14108032588735359), Close_word(word='mer', distance=0.14108032588735359), Close_word(word='nair', distance=0.14108032588735359), Close_word(word=\"ne'er\", distance=0.14108032588735359), Close_word(word='phair', distance=0.14108032588735359), Close_word(word='pierre', distance=0.14108032588735359), Close_word(word='plair', distance=0.14108032588735359), Close_word(word='prayer', distance=0.14108032588735359), Close_word(word='rare', distance=0.14108032588735359), Close_word(word='reher', distance=0.14108032588735359), Close_word(word='sare', distance=0.14108032588735359), Close_word(word='sayre', distance=0.14108032588735359), Close_word(word='scare', distance=0.14108032588735359), Close_word(word='schehr', distance=0.14108032588735359), Close_word(word='scherr', distance=0.14108032588735359), Close_word(word='sehr', distance=0.14108032588735359), Close_word(word='serr', distance=0.14108032588735359), Close_word(word='share', distance=0.14108032588735359), Close_word(word='sherr', distance=0.14108032588735359), Close_word(word='skare', distance=0.14108032588735359), Close_word(word='snare', distance=0.14108032588735359), Close_word(word='spare', distance=0.14108032588735359), Close_word(word='square', distance=0.14108032588735359), Close_word(word='stair', distance=0.14108032588735359), Close_word(word='stare', distance=0.14108032588735359), Close_word(word='stehr', distance=0.14108032588735359), Close_word(word='sterr', distance=0.14108032588735359), Close_word(word='swear', distance=0.14108032588735359), Close_word(word='tear', distance=0.14108032588735359), Close_word(word='their', distance=0.14108032588735359), Close_word(word='there', distance=0.14108032588735359), Close_word(word=\"they're\", distance=0.14108032588735359), Close_word(word='traer', distance=0.14108032588735359), Close_word(word='ware', distance=0.14108032588735359), Close_word(word='wear', distance=0.14108032588735359), Close_word(word='wehr', distance=0.14108032588735359), Close_word(word='werre', distance=0.14108032588735359), Close_word(word='where', distance=0.14108032588735359), Close_word(word='zehr', distance=0.14108032588735359)]), Phon_family(locus_word=Close_word(word='twice', distance=0.09999999999999998), close_words=[Close_word(word='bice', distance=0.18376369495395412), Close_word(word='brice', distance=0.18376369495395412), Close_word(word='bryce', distance=0.18376369495395412), Close_word(word='buysse', distance=0.18376369495395412), Close_word(word='deiss', distance=0.18376369495395412), Close_word(word='dice', distance=0.18376369495395412), Close_word(word='dise', distance=0.18376369495395412), Close_word(word='dyce', distance=0.18376369495395412), Close_word(word='feis', distance=0.18376369495395412), Close_word(word='fleiss', distance=0.18376369495395412), Close_word(word=\"fleiss'\", distance=0.18376369495395412), Close_word(word='geise', distance=0.18376369495395412), Close_word(word='geiss', distance=0.18376369495395412), Close_word(word='gneiss', distance=0.18376369495395412), Close_word(word='grice', distance=0.18376369495395412), Close_word(word='guice', distance=0.18376369495395412), Close_word(word='heise', distance=0.18376369495395412), Close_word(word='heiss', distance=0.18376369495395412), Close_word(word='hice', distance=0.18376369495395412), Close_word(word='ice', distance=0.18376369495395412), Close_word(word='kies', distance=0.18376369495395412), Close_word(word='kleiss', distance=0.18376369495395412), Close_word(word='kreiss', distance=0.18376369495395412), Close_word(word='leiss', distance=0.18376369495395412), Close_word(word='lice', distance=0.18376369495395412), Close_word(word='meiss', distance=0.18376369495395412), Close_word(word='mice', distance=0.18376369495395412), Close_word(word='nice', distance=0.18376369495395412), Close_word(word='nyce', distance=0.18376369495395412), Close_word(word='preiss', distance=0.18376369495395412), Close_word(word='price', distance=0.18376369495395412), Close_word(word='pryce', distance=0.18376369495395412), Close_word(word='reiss', distance=0.18376369495395412), Close_word(word='rice', distance=0.18376369495395412), Close_word(word='schweiss', distance=0.18376369495395412), Close_word(word='slice', distance=0.18376369495395412), Close_word(word='spice', distance=0.18376369495395412), Close_word(word='splice', distance=0.18376369495395412), Close_word(word='stice', distance=0.18376369495395412), Close_word(word='theiss', distance=0.18376369495395412), Close_word(word='thrice', distance=0.18376369495395412), Close_word(word='tice', distance=0.18376369495395412), Close_word(word='trice', distance=0.18376369495395412), Close_word(word='tyce', distance=0.18376369495395412), Close_word(word='vice', distance=0.18376369495395412), Close_word(word='vise', distance=0.18376369495395412), Close_word(word='weis', distance=0.18376369495395412), Close_word(word='weiss', distance=0.18376369495395412), Close_word(word='weisse', distance=0.18376369495395412), Close_word(word='wice', distance=0.18376369495395412), Close_word(word='wrice', distance=0.18376369495395412), Close_word(word='zeiss', distance=0.18376369495395412)])])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_sem_fam = make_phon_fams_and_sem_family('two')\n",
    "two_sem_fam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-vampire",
   "metadata": {},
   "source": [
    "## 4 — Gather candidate phrases\n",
    "\n",
    "For each word in the phonetic family, of each word in the semantic family, of each object label, retrieve phrases containing the word.\n",
    "Add the phrase_Id, as well as the stats on the object centrality, semantic distance, and phonetic distance, to a dataframe.\n",
    "\n",
    "Compute _suitability score_ for each word-phrase match and add this to that column of the dataframe\n",
    "\n",
    "Also, for each word in the semantic family, search the joke list for match and add that these to a joke_match dataframe, to use if there's too low a suitability score using a substitution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-aerospace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "classical-joseph",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-fishing",
   "metadata": {},
   "source": [
    "## TO CODE NEXT\n",
    "\n",
    "Write code that takes the word `twice` and returns its `semantic_family` which is a list of words \n",
    "('pair', and 'twice' in this case) and returns either (TBD) the list phonetically similar words or \n",
    "the pboneticized version of the word to be compared with the phoneticized variants of words in\n",
    "the phrases\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-generator",
   "metadata": {},
   "source": [
    "#### Define dataframe for candidate phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "political-symphony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>semantic_match</th>\n",
       "      <th>sem_dist</th>\n",
       "      <th>phonetic_match</th>\n",
       "      <th>phon_dist</th>\n",
       "      <th>phrase_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [semantic_match, sem_dist, phonetic_match, phon_dist, phrase_id, score]\n",
       "Index: []"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ['semantic_match', 'sem_dist', 'phonetic_match', 'phon_dist', 'phrase_id', 'score']\n",
    "\n",
    "cand_df = pd.DataFrame(columns= col_names)\n",
    "cand_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-condition",
   "metadata": {},
   "source": [
    "#### Need to write body of function that will convert to phoneticized version of word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "superior-winter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phoneticized( w ):\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-capacity",
   "metadata": {},
   "source": [
    "### ALERT:  Instead, pre-generate a dictionary of phoneticized versions of the words in the list of idioms. Each phonetic word should map to a list of duples each of which is a phrase id and the corresponding word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "molecular-bobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matching_phrases( w ):\n",
    "    matched_id_list = []\n",
    "    for phrase_id in phrase_dict.keys():\n",
    "        if w in phrase_dict[phrase_id].phon_list:\n",
    "            matched_id_list.append(phrase_id)\n",
    "    return matched_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "small-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_matching_phrases('bear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "prostate-paint",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  cycles through each phonetic family in the semantic family to get matching phrases\n",
    "\n",
    "#def get_phrases_for_phon_fam( phon_fam_, sem_dist_ ):\n",
    "def get_phrases_for_phon_fam( phon_fam_ ):\n",
    "\n",
    "    word_match_records_ = []\n",
    "\n",
    "    #phon_fam_ = pair_phon_fam\n",
    "    for word in phon_fam_.close_words:\n",
    "        matched_phrases = get_matching_phrases( word.word )\n",
    "        #print(word, len(matched_phrases))\n",
    "        if matched_phrases:\n",
    "            for p_id in matched_phrases:\n",
    "                word_match_records_.append({'semantic_match': phon_fam_.locus_word.word, 'sem_dist': phon_fam_.locus_word.distance, 'phonetic_match': word.word, 'phon_dist': word.distance, 'phrase_id': p_id, 'score': ''})\n",
    "    return word_match_records_ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "surprised-birthday",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phrases_for_sem_fam( sem_fam_ ):\n",
    "    word_match_records_ = []\n",
    "    for phon_fam_ in sem_fam_.sem_fam_words:\n",
    "        print( phon_fam_.locus_word.distance )\n",
    "        #word_match_records_.extend( get_phrases_for_phon_fam( phon_fam_, sem_fam_.locus_word.distance ) )\n",
    "        word_match_records_.extend( get_phrases_for_phon_fam( phon_fam_ ) )\n",
    "    return word_match_records_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "preliminary-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_match_records = []   \n",
    "\n",
    "# word_match_records.extend( get_phrases_for_phon_fam( two_phon_fam ) ) \n",
    "# word_match_records.extend( get_phrases_for_phon_fam( pair_phon_fam ) )\n",
    "# word_match_records.extend( get_phrases_for_phon_fam( twice_phon_fam ) )  \n",
    "# word_match_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "adjustable-reason",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cand_df = cand_df.append(word_match_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "according-seller",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sem_family(locus_word=Close_word(word='two', distance=0.0), sem_fam_words=[Phon_family(locus_word=Close_word(word='two', distance=0.0), close_words=[Close_word(word='beu', distance=0.16464397316487445), Close_word(word='bleu', distance=0.16464397316487445), Close_word(word='blew', distance=0.16464397316487445), Close_word(word='blue', distance=0.16464397316487445), Close_word(word='boo', distance=0.16464397316487445), Close_word(word='breaux', distance=0.16464397316487445), Close_word(word='brew', distance=0.16464397316487445), Close_word(word='brue', distance=0.16464397316487445), Close_word(word='chew', distance=0.16464397316487445), Close_word(word='chiu', distance=0.16464397316487445), Close_word(word='choo', distance=0.16464397316487445), Close_word(word='chou', distance=0.16464397316487445), Close_word(word='chu', distance=0.16464397316487445), Close_word(word='clue', distance=0.16464397316487445), Close_word(word='coo', distance=0.16464397316487445), Close_word(word='cou', distance=0.16464397316487445), Close_word(word='coup', distance=0.16464397316487445), Close_word(word='crew', distance=0.16464397316487445), Close_word(word='crewe', distance=0.16464397316487445), Close_word(word='cue', distance=0.16464397316487445), Close_word(word='deux', distance=0.16464397316487445), Close_word(word='dew', distance=0.16464397316487445), Close_word(word='do', distance=0.16464397316487445), Close_word(word='doo', distance=0.16464397316487445), Close_word(word='douwe', distance=0.16464397316487445), Close_word(word='drew', distance=0.16464397316487445), Close_word(word='dru', distance=0.16464397316487445), Close_word(word='du', distance=0.16464397316487445), Close_word(word='due', distance=0.16464397316487445), Close_word(word='ewe', distance=0.16464397316487445), Close_word(word='few', distance=0.16464397316487445), Close_word(word='flew', distance=0.16464397316487445), Close_word(word='flu', distance=0.16464397316487445), Close_word(word='flue', distance=0.16464397316487445), Close_word(word='foo', distance=0.16464397316487445), Close_word(word='frew', distance=0.16464397316487445), Close_word(word='frueh', distance=0.16464397316487445), Close_word(word='fu', distance=0.16464397316487445), Close_word(word='geroux', distance=0.16464397316487445), Close_word(word='glew', distance=0.16464397316487445), Close_word(word='glue', distance=0.16464397316487445), Close_word(word='gnu', distance=0.16464397316487445), Close_word(word='goo', distance=0.16464397316487445), Close_word(word='graue', distance=0.16464397316487445), Close_word(word='grew', distance=0.16464397316487445), Close_word(word='grewe', distance=0.16464397316487445), Close_word(word='gu', distance=0.16464397316487445), Close_word(word='gue', distance=0.16464397316487445), Close_word(word='heroux', distance=0.16464397316487445), Close_word(word='hew', distance=0.16464397316487445), Close_word(word='hewe', distance=0.16464397316487445), Close_word(word='hoo', distance=0.16464397316487445), Close_word(word='hou', distance=0.16464397316487445), Close_word(word='houx', distance=0.16464397316487445), Close_word(word='hsu', distance=0.16464397316487445), Close_word(word='hu', distance=0.16464397316487445), Close_word(word='hue', distance=0.16464397316487445), Close_word(word='hugh', distance=0.16464397316487445), Close_word(word='jew', distance=0.16464397316487445), Close_word(word='joo', distance=0.16464397316487445), Close_word(word='ju', distance=0.16464397316487445), Close_word(word='jue', distance=0.16464397316487445), Close_word(word='jus', distance=0.16464397316487445), Close_word(word='kew', distance=0.16464397316487445), Close_word(word='khoo', distance=0.16464397316487445), Close_word(word='khuu', distance=0.16464397316487445), Close_word(word='klu', distance=0.16464397316487445), Close_word(word='knew', distance=0.16464397316487445), Close_word(word='koo', distance=0.16464397316487445), Close_word(word='ku', distance=0.16464397316487445), Close_word(word='kyu', distance=0.16464397316487445), Close_word(word='laroux', distance=0.16464397316487445), Close_word(word='larue', distance=0.16464397316487445), Close_word(word='leroux', distance=0.16464397316487445), Close_word(word='leu', distance=0.16464397316487445), Close_word(word='lew', distance=0.16464397316487445), Close_word(word='lieu', distance=0.16464397316487445), Close_word(word='liou', distance=0.16464397316487445), Close_word(word='liu', distance=0.16464397316487445), Close_word(word='loo', distance=0.16464397316487445), Close_word(word='lou', distance=0.16464397316487445), Close_word(word='louw', distance=0.16464397316487445), Close_word(word='loux', distance=0.16464397316487445), Close_word(word='lu', distance=0.16464397316487445), Close_word(word='lue', distance=0.16464397316487445), Close_word(word='mew', distance=0.16464397316487445), Close_word(word='moo', distance=0.16464397316487445), Close_word(word='mu', distance=0.16464397316487445), Close_word(word='new', distance=0.16464397316487445), Close_word(word='nu', distance=0.16464397316487445), Close_word(word='ooh', distance=0.16464397316487445), Close_word(word='oooh', distance=0.16464397316487445), Close_word(word='ou', distance=0.16464397316487445), Close_word(word='peru', distance=0.16464397316487445), Close_word(word='peugh', distance=0.16464397316487445), Close_word(word='pew', distance=0.16464397316487445), Close_word(word='phew', distance=0.16464397316487445), Close_word(word='phu', distance=0.16464397316487445), Close_word(word='plew', distance=0.16464397316487445), Close_word(word='plue', distance=0.16464397316487445), Close_word(word='poo', distance=0.16464397316487445), Close_word(word='pooh', distance=0.16464397316487445), Close_word(word='pou', distance=0.16464397316487445), Close_word(word='prew', distance=0.16464397316487445), Close_word(word='pru', distance=0.16464397316487445), Close_word(word='prue', distance=0.16464397316487445), Close_word(word='prugh', distance=0.16464397316487445), Close_word(word='pshew', distance=0.16464397316487445), Close_word(word='pu', distance=0.16464397316487445), Close_word(word='pugh', distance=0.16464397316487445), Close_word(word='q.', distance=0.16464397316487445), Close_word(word='qu', distance=0.16464397316487445), Close_word(word='que', distance=0.16464397316487445), Close_word(word='queue', distance=0.16464397316487445), Close_word(word='raoux', distance=0.16464397316487445), Close_word(word='rew', distance=0.16464397316487445), Close_word(word='rhew', distance=0.16464397316487445), Close_word(word='rhue', distance=0.16464397316487445), Close_word(word='rioux', distance=0.16464397316487445), Close_word(word='roux', distance=0.16464397316487445), Close_word(word='ru', distance=0.16464397316487445), Close_word(word='rue', distance=0.16464397316487445), Close_word(word='schewe', distance=0.16464397316487445), Close_word(word='schoo', distance=0.16464397316487445), Close_word(word='schou', distance=0.16464397316487445), Close_word(word='schue', distance=0.16464397316487445), Close_word(word='schuh', distance=0.16464397316487445), Close_word(word='screw', distance=0.16464397316487445), Close_word(word='shew', distance=0.16464397316487445), Close_word(word='shiu', distance=0.16464397316487445), Close_word(word='shoe', distance=0.16464397316487445), Close_word(word='shoo', distance=0.16464397316487445), Close_word(word='shu', distance=0.16464397316487445), Close_word(word='shue', distance=0.16464397316487445), Close_word(word='siew', distance=0.16464397316487445), Close_word(word='sioux', distance=0.16464397316487445), Close_word(word='skew', distance=0.16464397316487445), Close_word(word='slew', distance=0.16464397316487445), Close_word(word='soo', distance=0.16464397316487445), Close_word(word='spew', distance=0.16464397316487445), Close_word(word='stew', distance=0.16464397316487445), Close_word(word='strew', distance=0.16464397316487445), Close_word(word='stu', distance=0.16464397316487445), Close_word(word='stuewe', distance=0.16464397316487445), Close_word(word='su', distance=0.16464397316487445), Close_word(word='sue', distance=0.16464397316487445), Close_word(word='theroux', distance=0.16464397316487445), Close_word(word='thew', distance=0.16464397316487445), Close_word(word='threw', distance=0.16464397316487445), Close_word(word='through', distance=0.16464397316487445), Close_word(word='thru', distance=0.16464397316487445), Close_word(word='tieu', distance=0.16464397316487445), Close_word(word='toyoo', distance=0.16464397316487445), Close_word(word='treu', distance=0.16464397316487445), Close_word(word='trew', distance=0.16464397316487445), Close_word(word='trieu', distance=0.16464397316487445), Close_word(word='troyu', distance=0.16464397316487445), Close_word(word='true', distance=0.16464397316487445), Close_word(word='tsu', distance=0.16464397316487445), Close_word(word='u.', distance=0.16464397316487445), Close_word(word='uwe', distance=0.16464397316487445), Close_word(word='view', distance=0.16464397316487445), Close_word(word='vous', distance=0.16464397316487445), Close_word(word='vu', distance=0.16464397316487445), Close_word(word='vue', distance=0.16464397316487445), Close_word(word='whew', distance=0.16464397316487445), Close_word(word='who', distance=0.16464397316487445), Close_word(word='whoo', distance=0.16464397316487445), Close_word(word='woo', distance=0.16464397316487445), Close_word(word='wu', distance=0.16464397316487445), Close_word(word='xu', distance=0.16464397316487445), Close_word(word='xue', distance=0.16464397316487445), Close_word(word='yew', distance=0.16464397316487445), Close_word(word='yoo', distance=0.16464397316487445), Close_word(word='you', distance=0.16464397316487445), Close_word(word='yu', distance=0.16464397316487445), Close_word(word='yue', distance=0.16464397316487445), Close_word(word='zhou', distance=0.16464397316487445), Close_word(word='zhu', distance=0.16464397316487445), Close_word(word='zoo', distance=0.16464397316487445), Close_word(word='zue', distance=0.16464397316487445)]), Phon_family(locus_word=Close_word(word='two', distance=0), close_words=[Close_word(word='beu', distance=0.1622067308253734), Close_word(word='bleu', distance=0.1622067308253734), Close_word(word='blew', distance=0.1622067308253734), Close_word(word='blue', distance=0.1622067308253734), Close_word(word='boo', distance=0.1622067308253734), Close_word(word='breaux', distance=0.1622067308253734), Close_word(word='brew', distance=0.1622067308253734), Close_word(word='brue', distance=0.1622067308253734), Close_word(word='chew', distance=0.1622067308253734), Close_word(word='chiu', distance=0.1622067308253734), Close_word(word='choo', distance=0.1622067308253734), Close_word(word='chou', distance=0.1622067308253734), Close_word(word='chu', distance=0.1622067308253734), Close_word(word='clue', distance=0.1622067308253734), Close_word(word='coo', distance=0.1622067308253734), Close_word(word='cou', distance=0.1622067308253734), Close_word(word='coup', distance=0.1622067308253734), Close_word(word='crew', distance=0.1622067308253734), Close_word(word='crewe', distance=0.1622067308253734), Close_word(word='cue', distance=0.1622067308253734), Close_word(word='deux', distance=0.1622067308253734), Close_word(word='dew', distance=0.1622067308253734), Close_word(word='do', distance=0.1622067308253734), Close_word(word='doo', distance=0.1622067308253734), Close_word(word='douwe', distance=0.1622067308253734), Close_word(word='drew', distance=0.1622067308253734), Close_word(word='dru', distance=0.1622067308253734), Close_word(word='du', distance=0.1622067308253734), Close_word(word='due', distance=0.1622067308253734), Close_word(word='ewe', distance=0.1622067308253734), Close_word(word='few', distance=0.1622067308253734), Close_word(word='flew', distance=0.1622067308253734), Close_word(word='flu', distance=0.1622067308253734), Close_word(word='flue', distance=0.1622067308253734), Close_word(word='foo', distance=0.1622067308253734), Close_word(word='frew', distance=0.1622067308253734), Close_word(word='frueh', distance=0.1622067308253734), Close_word(word='fu', distance=0.1622067308253734), Close_word(word='geroux', distance=0.1622067308253734), Close_word(word='glew', distance=0.1622067308253734), Close_word(word='glue', distance=0.1622067308253734), Close_word(word='gnu', distance=0.1622067308253734), Close_word(word='goo', distance=0.1622067308253734), Close_word(word='graue', distance=0.1622067308253734), Close_word(word='grew', distance=0.1622067308253734), Close_word(word='grewe', distance=0.1622067308253734), Close_word(word='gu', distance=0.1622067308253734), Close_word(word='gue', distance=0.1622067308253734), Close_word(word='heroux', distance=0.1622067308253734), Close_word(word='hew', distance=0.1622067308253734), Close_word(word='hewe', distance=0.1622067308253734), Close_word(word='hoo', distance=0.1622067308253734), Close_word(word='hou', distance=0.1622067308253734), Close_word(word='houx', distance=0.1622067308253734), Close_word(word='hsu', distance=0.1622067308253734), Close_word(word='hu', distance=0.1622067308253734), Close_word(word='hue', distance=0.1622067308253734), Close_word(word='hugh', distance=0.1622067308253734), Close_word(word='jew', distance=0.1622067308253734), Close_word(word='joo', distance=0.1622067308253734), Close_word(word='ju', distance=0.1622067308253734), Close_word(word='jue', distance=0.1622067308253734), Close_word(word='jus', distance=0.1622067308253734), Close_word(word='kew', distance=0.1622067308253734), Close_word(word='khoo', distance=0.1622067308253734), Close_word(word='khuu', distance=0.1622067308253734), Close_word(word='klu', distance=0.1622067308253734), Close_word(word='knew', distance=0.1622067308253734), Close_word(word='koo', distance=0.1622067308253734), Close_word(word='ku', distance=0.1622067308253734), Close_word(word='kyu', distance=0.1622067308253734), Close_word(word='laroux', distance=0.1622067308253734), Close_word(word='larue', distance=0.1622067308253734), Close_word(word='leroux', distance=0.1622067308253734), Close_word(word='leu', distance=0.1622067308253734), Close_word(word='lew', distance=0.1622067308253734), Close_word(word='lieu', distance=0.1622067308253734), Close_word(word='liou', distance=0.1622067308253734), Close_word(word='liu', distance=0.1622067308253734), Close_word(word='loo', distance=0.1622067308253734), Close_word(word='lou', distance=0.1622067308253734), Close_word(word='louw', distance=0.1622067308253734), Close_word(word='loux', distance=0.1622067308253734), Close_word(word='lu', distance=0.1622067308253734), Close_word(word='lue', distance=0.1622067308253734), Close_word(word='mew', distance=0.1622067308253734), Close_word(word='moo', distance=0.1622067308253734), Close_word(word='mu', distance=0.1622067308253734), Close_word(word='new', distance=0.1622067308253734), Close_word(word='nu', distance=0.1622067308253734), Close_word(word='ooh', distance=0.1622067308253734), Close_word(word='oooh', distance=0.1622067308253734), Close_word(word='ou', distance=0.1622067308253734), Close_word(word='peru', distance=0.1622067308253734), Close_word(word='peugh', distance=0.1622067308253734), Close_word(word='pew', distance=0.1622067308253734), Close_word(word='phew', distance=0.1622067308253734), Close_word(word='phu', distance=0.1622067308253734), Close_word(word='plew', distance=0.1622067308253734), Close_word(word='plue', distance=0.1622067308253734), Close_word(word='poo', distance=0.1622067308253734), Close_word(word='pooh', distance=0.1622067308253734), Close_word(word='pou', distance=0.1622067308253734), Close_word(word='prew', distance=0.1622067308253734), Close_word(word='pru', distance=0.1622067308253734), Close_word(word='prue', distance=0.1622067308253734), Close_word(word='prugh', distance=0.1622067308253734), Close_word(word='pshew', distance=0.1622067308253734), Close_word(word='pu', distance=0.1622067308253734), Close_word(word='pugh', distance=0.1622067308253734), Close_word(word='q.', distance=0.1622067308253734), Close_word(word='qu', distance=0.1622067308253734), Close_word(word='que', distance=0.1622067308253734), Close_word(word='queue', distance=0.1622067308253734), Close_word(word='raoux', distance=0.1622067308253734), Close_word(word='rew', distance=0.1622067308253734), Close_word(word='rhew', distance=0.1622067308253734), Close_word(word='rhue', distance=0.1622067308253734), Close_word(word='rioux', distance=0.1622067308253734), Close_word(word='roux', distance=0.1622067308253734), Close_word(word='ru', distance=0.1622067308253734), Close_word(word='rue', distance=0.1622067308253734), Close_word(word='schewe', distance=0.1622067308253734), Close_word(word='schoo', distance=0.1622067308253734), Close_word(word='schou', distance=0.1622067308253734), Close_word(word='schue', distance=0.1622067308253734), Close_word(word='schuh', distance=0.1622067308253734), Close_word(word='screw', distance=0.1622067308253734), Close_word(word='shew', distance=0.1622067308253734), Close_word(word='shiu', distance=0.1622067308253734), Close_word(word='shoe', distance=0.1622067308253734), Close_word(word='shoo', distance=0.1622067308253734), Close_word(word='shu', distance=0.1622067308253734), Close_word(word='shue', distance=0.1622067308253734), Close_word(word='siew', distance=0.1622067308253734), Close_word(word='sioux', distance=0.1622067308253734), Close_word(word='skew', distance=0.1622067308253734), Close_word(word='slew', distance=0.1622067308253734), Close_word(word='soo', distance=0.1622067308253734), Close_word(word='spew', distance=0.1622067308253734), Close_word(word='stew', distance=0.1622067308253734), Close_word(word='strew', distance=0.1622067308253734), Close_word(word='stu', distance=0.1622067308253734), Close_word(word='stuewe', distance=0.1622067308253734), Close_word(word='su', distance=0.1622067308253734), Close_word(word='sue', distance=0.1622067308253734), Close_word(word='theroux', distance=0.1622067308253734), Close_word(word='thew', distance=0.1622067308253734), Close_word(word='threw', distance=0.1622067308253734), Close_word(word='through', distance=0.1622067308253734), Close_word(word='thru', distance=0.1622067308253734), Close_word(word='tieu', distance=0.1622067308253734), Close_word(word='toyoo', distance=0.1622067308253734), Close_word(word='treu', distance=0.1622067308253734), Close_word(word='trew', distance=0.1622067308253734), Close_word(word='trieu', distance=0.1622067308253734), Close_word(word='troyu', distance=0.1622067308253734), Close_word(word='true', distance=0.1622067308253734), Close_word(word='tsu', distance=0.1622067308253734), Close_word(word='u.', distance=0.1622067308253734), Close_word(word='uwe', distance=0.1622067308253734), Close_word(word='view', distance=0.1622067308253734), Close_word(word='vous', distance=0.1622067308253734), Close_word(word='vu', distance=0.1622067308253734), Close_word(word='vue', distance=0.1622067308253734), Close_word(word='whew', distance=0.1622067308253734), Close_word(word='who', distance=0.1622067308253734), Close_word(word='whoo', distance=0.1622067308253734), Close_word(word='woo', distance=0.1622067308253734), Close_word(word='wu', distance=0.1622067308253734), Close_word(word='xu', distance=0.1622067308253734), Close_word(word='xue', distance=0.1622067308253734), Close_word(word='yew', distance=0.1622067308253734), Close_word(word='yoo', distance=0.1622067308253734), Close_word(word='you', distance=0.1622067308253734), Close_word(word='yu', distance=0.1622067308253734), Close_word(word='yue', distance=0.1622067308253734), Close_word(word='zhou', distance=0.1622067308253734), Close_word(word='zhu', distance=0.1622067308253734), Close_word(word='zoo', distance=0.1622067308253734), Close_word(word='zue', distance=0.1622067308253734)]), Phon_family(locus_word=Close_word(word='2', distance=0), close_words=[]), Phon_family(locus_word=Close_word(word='II', distance=0), close_words=[]), Phon_family(locus_word=Close_word(word='deuce', distance=0), close_words=[Close_word(word='boose', distance=0.183761107418429), Close_word(word='bruce', distance=0.183761107418429), Close_word(word='cheuse', distance=0.183761107418429), Close_word(word='coos', distance=0.183761107418429), Close_word(word='cruce', distance=0.183761107418429), Close_word(word='derousse', distance=0.183761107418429), Close_word(word='druce', distance=0.183761107418429), Close_word(word='foose', distance=0.183761107418429), Close_word(word='fuoss', distance=0.183761107418429), Close_word(word='goose', distance=0.183761107418429), Close_word(word='hoose', distance=0.183761107418429), Close_word(word='juice', distance=0.183761107418429), Close_word(word='loose', distance=0.183761107418429), Close_word(word='luce', distance=0.183761107418429), Close_word(word='moose', distance=0.183761107418429), Close_word(word='mousse', distance=0.183761107418429), Close_word(word='noose', distance=0.183761107418429), Close_word(word='nous', distance=0.183761107418429), Close_word(word='preuss', distance=0.183761107418429), Close_word(word='pruess', distance=0.183761107418429), Close_word(word='reuss', distance=0.183761107418429), Close_word(word='ruess', distance=0.183761107418429), Close_word(word='seuss', distance=0.183761107418429), Close_word(word='sluice', distance=0.183761107418429), Close_word(word='spruce', distance=0.183761107418429), Close_word(word='truce', distance=0.183761107418429), Close_word(word='tyus', distance=0.183761107418429), Close_word(word='use', distance=0.183761107418429), Close_word(word='yous', distance=0.183761107418429), Close_word(word='zeus', distance=0.183761107418429)]), Phon_family(locus_word=Close_word(word='pair', distance=0.050000000000000044), close_words=[Close_word(word='aer', distance=0.14108032588735359), Close_word(word='air', distance=0.14108032588735359), Close_word(word='ayre', distance=0.14108032588735359), Close_word(word='baehr', distance=0.14108032588735359), Close_word(word='baer', distance=0.14108032588735359), Close_word(word='bahr', distance=0.14108032588735359), Close_word(word='bair', distance=0.14108032588735359), Close_word(word='bare', distance=0.14108032588735359), Close_word(word='bear', distance=0.14108032588735359), Close_word(word='behr', distance=0.14108032588735359), Close_word(word='blair', distance=0.14108032588735359), Close_word(word='blare', distance=0.14108032588735359), Close_word(word='caire', distance=0.14108032588735359), Close_word(word='care', distance=0.14108032588735359), Close_word(word='chair', distance=0.14108032588735359), Close_word(word='cher', distance=0.14108032588735359), Close_word(word='clair', distance=0.14108032588735359), Close_word(word='claire', distance=0.14108032588735359), Close_word(word='clare', distance=0.14108032588735359), Close_word(word='dare', distance=0.14108032588735359), Close_word(word='darr', distance=0.14108032588735359), Close_word(word='derr', distance=0.14108032588735359), Close_word(word='dreher', distance=0.14108032588735359), Close_word(word='ere', distance=0.14108032588735359), Close_word(word='err', distance=0.14108032588735359), Close_word(word='eyre', distance=0.14108032588735359), Close_word(word='fair', distance=0.14108032588735359), Close_word(word='faire', distance=0.14108032588735359), Close_word(word='fare', distance=0.14108032588735359), Close_word(word='fehr', distance=0.14108032588735359), Close_word(word='fer', distance=0.14108032588735359), Close_word(word='ferre', distance=0.14108032588735359), Close_word(word='flair', distance=0.14108032588735359), Close_word(word='flare', distance=0.14108032588735359), Close_word(word='fraire', distance=0.14108032588735359), Close_word(word='frere', distance=0.14108032588735359), Close_word(word='freyre', distance=0.14108032588735359), Close_word(word='gair', distance=0.14108032588735359), Close_word(word='gare', distance=0.14108032588735359), Close_word(word='gehr', distance=0.14108032588735359), Close_word(word='glare', distance=0.14108032588735359), Close_word(word='guerre', distance=0.14108032588735359), Close_word(word='hair', distance=0.14108032588735359), Close_word(word='haire', distance=0.14108032588735359), Close_word(word='hairr', distance=0.14108032588735359), Close_word(word='hare', distance=0.14108032588735359), Close_word(word='hehr', distance=0.14108032588735359), Close_word(word='heir', distance=0.14108032588735359), Close_word(word='herr', distance=0.14108032588735359), Close_word(word='herre', distance=0.14108032588735359), Close_word(word='kahre', distance=0.14108032588735359), Close_word(word='kehr', distance=0.14108032588735359), Close_word(word='khmer', distance=0.14108032588735359), Close_word(word='klare', distance=0.14108032588735359), Close_word(word='knerr', distance=0.14108032588735359), Close_word(word='kreher', distance=0.14108032588735359), Close_word(word='lair', distance=0.14108032588735359), Close_word(word='lare', distance=0.14108032588735359), Close_word(word='lehr', distance=0.14108032588735359), Close_word(word='mair', distance=0.14108032588735359), Close_word(word='maire', distance=0.14108032588735359), Close_word(word='mare', distance=0.14108032588735359), Close_word(word='mehr', distance=0.14108032588735359), Close_word(word='mer', distance=0.14108032588735359), Close_word(word='nair', distance=0.14108032588735359), Close_word(word=\"ne'er\", distance=0.14108032588735359), Close_word(word='phair', distance=0.14108032588735359), Close_word(word='pierre', distance=0.14108032588735359), Close_word(word='plair', distance=0.14108032588735359), Close_word(word='prayer', distance=0.14108032588735359), Close_word(word='rare', distance=0.14108032588735359), Close_word(word='reher', distance=0.14108032588735359), Close_word(word='sare', distance=0.14108032588735359), Close_word(word='sayre', distance=0.14108032588735359), Close_word(word='scare', distance=0.14108032588735359), Close_word(word='schehr', distance=0.14108032588735359), Close_word(word='scherr', distance=0.14108032588735359), Close_word(word='sehr', distance=0.14108032588735359), Close_word(word='serr', distance=0.14108032588735359), Close_word(word='share', distance=0.14108032588735359), Close_word(word='sherr', distance=0.14108032588735359), Close_word(word='skare', distance=0.14108032588735359), Close_word(word='snare', distance=0.14108032588735359), Close_word(word='spare', distance=0.14108032588735359), Close_word(word='square', distance=0.14108032588735359), Close_word(word='stair', distance=0.14108032588735359), Close_word(word='stare', distance=0.14108032588735359), Close_word(word='stehr', distance=0.14108032588735359), Close_word(word='sterr', distance=0.14108032588735359), Close_word(word='swear', distance=0.14108032588735359), Close_word(word='tear', distance=0.14108032588735359), Close_word(word='their', distance=0.14108032588735359), Close_word(word='there', distance=0.14108032588735359), Close_word(word=\"they're\", distance=0.14108032588735359), Close_word(word='traer', distance=0.14108032588735359), Close_word(word='ware', distance=0.14108032588735359), Close_word(word='wear', distance=0.14108032588735359), Close_word(word='wehr', distance=0.14108032588735359), Close_word(word='werre', distance=0.14108032588735359), Close_word(word='where', distance=0.14108032588735359), Close_word(word='zehr', distance=0.14108032588735359)]), Phon_family(locus_word=Close_word(word='twice', distance=0.09999999999999998), close_words=[Close_word(word='bice', distance=0.18376369495395412), Close_word(word='brice', distance=0.18376369495395412), Close_word(word='bryce', distance=0.18376369495395412), Close_word(word='buysse', distance=0.18376369495395412), Close_word(word='deiss', distance=0.18376369495395412), Close_word(word='dice', distance=0.18376369495395412), Close_word(word='dise', distance=0.18376369495395412), Close_word(word='dyce', distance=0.18376369495395412), Close_word(word='feis', distance=0.18376369495395412), Close_word(word='fleiss', distance=0.18376369495395412), Close_word(word=\"fleiss'\", distance=0.18376369495395412), Close_word(word='geise', distance=0.18376369495395412), Close_word(word='geiss', distance=0.18376369495395412), Close_word(word='gneiss', distance=0.18376369495395412), Close_word(word='grice', distance=0.18376369495395412), Close_word(word='guice', distance=0.18376369495395412), Close_word(word='heise', distance=0.18376369495395412), Close_word(word='heiss', distance=0.18376369495395412), Close_word(word='hice', distance=0.18376369495395412), Close_word(word='ice', distance=0.18376369495395412), Close_word(word='kies', distance=0.18376369495395412), Close_word(word='kleiss', distance=0.18376369495395412), Close_word(word='kreiss', distance=0.18376369495395412), Close_word(word='leiss', distance=0.18376369495395412), Close_word(word='lice', distance=0.18376369495395412), Close_word(word='meiss', distance=0.18376369495395412), Close_word(word='mice', distance=0.18376369495395412), Close_word(word='nice', distance=0.18376369495395412), Close_word(word='nyce', distance=0.18376369495395412), Close_word(word='preiss', distance=0.18376369495395412), Close_word(word='price', distance=0.18376369495395412), Close_word(word='pryce', distance=0.18376369495395412), Close_word(word='reiss', distance=0.18376369495395412), Close_word(word='rice', distance=0.18376369495395412), Close_word(word='schweiss', distance=0.18376369495395412), Close_word(word='slice', distance=0.18376369495395412), Close_word(word='spice', distance=0.18376369495395412), Close_word(word='splice', distance=0.18376369495395412), Close_word(word='stice', distance=0.18376369495395412), Close_word(word='theiss', distance=0.18376369495395412), Close_word(word='thrice', distance=0.18376369495395412), Close_word(word='tice', distance=0.18376369495395412), Close_word(word='trice', distance=0.18376369495395412), Close_word(word='tyce', distance=0.18376369495395412), Close_word(word='vice', distance=0.18376369495395412), Close_word(word='vise', distance=0.18376369495395412), Close_word(word='weis', distance=0.18376369495395412), Close_word(word='weiss', distance=0.18376369495395412), Close_word(word='weisse', distance=0.18376369495395412), Close_word(word='wice', distance=0.18376369495395412), Close_word(word='wrice', distance=0.18376369495395412), Close_word(word='zeiss', distance=0.18376369495395412)])])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_sem_fam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "favorite-plane",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_match_records = get_phrases_for_sem_fam( two_sem_fam )\n",
    "# word_match_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "vulnerable-quality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be replaced with image recognition algorithms\n",
    "def get_image_topics():\n",
    "    return [test_image_topic]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-israel",
   "metadata": {},
   "source": [
    "## The equivalent of `main` for the time being, until two or more image topics are handled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "lined-cursor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Close_word(word='three', distance=0)\n",
      "Close_word(word='3', distance=0)\n",
      "Close_word(word='III', distance=0)\n",
      "Close_word(word='trio', distance=0)\n",
      "Close_word(word='threesome', distance=0)\n",
      "Close_word(word='tierce', distance=0)\n",
      "Close_word(word='leash', distance=0)\n",
      "Close_word(word='troika', distance=0)\n",
      "Close_word(word='triad', distance=0)\n",
      "Close_word(word='trine', distance=0)\n",
      "Close_word(word='trinity', distance=0)\n",
      "Close_word(word='ternary', distance=0)\n",
      "Close_word(word='ternion', distance=0)\n",
      "Close_word(word='triplet', distance=0)\n",
      "Close_word(word='tercet', distance=0)\n",
      "Close_word(word='terzetto', distance=0)\n",
      "Close_word(word='trey', distance=0)\n",
      "Close_word(word='deuce-ace', distance=0)\n",
      "0.0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "image_topics     = get_image_topics()\n",
    "image_topic_word = image_topics[0]\n",
    "\n",
    "two_sem_fam = make_phon_fams_and_sem_family( image_topic_word )\n",
    "#two_sem_fam\n",
    "\n",
    "word_match_records = get_phrases_for_sem_fam( two_sem_fam )\n",
    "\n",
    "cand_df = cand_df.append(word_match_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "intellectual-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cand_df = pd.DataFrame({\"semantic_match\": ['pair','pair','twice'], \"sem_dist\": [5, 5, 4.1], \"phonetic_match\": ['bear', 'hair','mice'], \"phon_dist\": [1.5, 2.7, 2.1], \"phrase_id\":  [ph_id1, ph_id2,ph_id3], \"phrase_type\":  ['idiom', 'idiom','idiom'],'score': [.5, .3, 1.1]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "mobile-composer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>semantic_match</th>\n",
       "      <th>sem_dist</th>\n",
       "      <th>phonetic_match</th>\n",
       "      <th>phon_dist</th>\n",
       "      <th>phrase_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>three</td>\n",
       "      <td>0.0</td>\n",
       "      <td>be</td>\n",
       "      <td>0.147436</td>\n",
       "      <td>2b026a7a-7fdb-11eb-aa6b-acde48001122</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>three</td>\n",
       "      <td>0.0</td>\n",
       "      <td>be</td>\n",
       "      <td>0.113288</td>\n",
       "      <td>2b026a7a-7fdb-11eb-aa6b-acde48001122</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trey</td>\n",
       "      <td>0.0</td>\n",
       "      <td>say</td>\n",
       "      <td>0.147278</td>\n",
       "      <td>2b025a44-7fdb-11eb-aa6b-acde48001122</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  semantic_match  sem_dist phonetic_match  phon_dist  \\\n",
       "0          three       0.0             be   0.147436   \n",
       "1          three       0.0             be   0.113288   \n",
       "2           trey       0.0            say   0.147278   \n",
       "\n",
       "                              phrase_id score  \n",
       "0  2b026a7a-7fdb-11eb-aa6b-acde48001122        \n",
       "1  2b026a7a-7fdb-11eb-aa6b-acde48001122        \n",
       "2  2b025a44-7fdb-11eb-aa6b-acde48001122        "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cand_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "spread-alaska",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>semantic_match</th>\n",
       "      <th>sem_dist</th>\n",
       "      <th>phonetic_match</th>\n",
       "      <th>phon_dist</th>\n",
       "      <th>phrase_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>three</td>\n",
       "      <td>0.0</td>\n",
       "      <td>be</td>\n",
       "      <td>0.147436</td>\n",
       "      <td>2b026a7a-7fdb-11eb-aa6b-acde48001122</td>\n",
       "      <td>6.782603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>three</td>\n",
       "      <td>0.0</td>\n",
       "      <td>be</td>\n",
       "      <td>0.113288</td>\n",
       "      <td>2b026a7a-7fdb-11eb-aa6b-acde48001122</td>\n",
       "      <td>8.827025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trey</td>\n",
       "      <td>0.0</td>\n",
       "      <td>say</td>\n",
       "      <td>0.147278</td>\n",
       "      <td>2b025a44-7fdb-11eb-aa6b-acde48001122</td>\n",
       "      <td>6.789861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  semantic_match  sem_dist phonetic_match  phon_dist  \\\n",
       "0          three       0.0             be   0.147436   \n",
       "1          three       0.0             be   0.113288   \n",
       "2           trey       0.0            say   0.147278   \n",
       "\n",
       "                              phrase_id     score  \n",
       "0  2b026a7a-7fdb-11eb-aa6b-acde48001122  6.782603  \n",
       "1  2b026a7a-7fdb-11eb-aa6b-acde48001122  8.827025  \n",
       "2  2b025a44-7fdb-11eb-aa6b-acde48001122  6.789861  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cand_df['score'] = cand_df.apply(lambda row: 1.0/(row['sem_dist'] + row['phon_dist']), axis=1)\n",
    "cand_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-flower",
   "metadata": {},
   "source": [
    "## 5 —  Choose captions\n",
    "\n",
    "Sort captions dataframe by the _suitability score_\n",
    "\n",
    "Choose the top 10(?) and generate a list containing each caption with the original semantic family word substituted into the idiom in addition to jokes containing any of the semantic family words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "surprised-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub(phrase, orig_word='', new_word=''):\n",
    "    return phrase.text_string.replace(orig_word, new_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-sleeping",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ceramic-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_caption( row ):\n",
    "    return sub( phrase_dict[ row['phrase_id']], row['phonetic_match'],  row['semantic_match']  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "tribal-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_captions(df, selection_size=10):\n",
    "    df.sort_values(by='score', inplace=True)\n",
    "    best_df = df.head(selection_size)\n",
    "    best_df['caption'] = best_df.apply(construct_caption, axis=1 )    \n",
    "    return best_df\n",
    "    #return best_df['_caption'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-pantyhose",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "reduced-hollywood",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-153-0abcd1c06ef8>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  best_df['caption'] = best_df.apply(construct_caption, axis=1 )\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>semantic_match</th>\n",
       "      <th>sem_dist</th>\n",
       "      <th>phonetic_match</th>\n",
       "      <th>phon_dist</th>\n",
       "      <th>phrase_id</th>\n",
       "      <th>score</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>three</td>\n",
       "      <td>0.0</td>\n",
       "      <td>be</td>\n",
       "      <td>0.147436</td>\n",
       "      <td>2b026a7a-7fdb-11eb-aa6b-acde48001122</td>\n",
       "      <td>6.782603</td>\n",
       "      <td>Wouldn't it three nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trey</td>\n",
       "      <td>0.0</td>\n",
       "      <td>say</td>\n",
       "      <td>0.147278</td>\n",
       "      <td>2b025a44-7fdb-11eb-aa6b-acde48001122</td>\n",
       "      <td>6.789861</td>\n",
       "      <td>I just called to trey I love you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>three</td>\n",
       "      <td>0.0</td>\n",
       "      <td>be</td>\n",
       "      <td>0.113288</td>\n",
       "      <td>2b026a7a-7fdb-11eb-aa6b-acde48001122</td>\n",
       "      <td>8.827025</td>\n",
       "      <td>Wouldn't it three nice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  semantic_match  sem_dist phonetic_match  phon_dist  \\\n",
       "0          three       0.0             be   0.147436   \n",
       "2           trey       0.0            say   0.147278   \n",
       "1          three       0.0             be   0.113288   \n",
       "\n",
       "                              phrase_id     score  \\\n",
       "0  2b026a7a-7fdb-11eb-aa6b-acde48001122  6.782603   \n",
       "2  2b025a44-7fdb-11eb-aa6b-acde48001122  6.789861   \n",
       "1  2b026a7a-7fdb-11eb-aa6b-acde48001122  8.827025   \n",
       "\n",
       "                            caption  \n",
       "0            Wouldn't it three nice  \n",
       "2  I just called to trey I love you  \n",
       "1            Wouldn't it three nice  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_captions_df = get_best_captions(cand_df)\n",
    "best_captions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "confirmed-screw",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Wouldn't it three nice\",\n",
       " 'I just called to trey I love you',\n",
       " \"Wouldn't it three nice\"]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_captions_list = best_captions_df['caption'].to_list()\n",
    "best_captions_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-fundamental",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-madrid",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-telescope",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-burlington",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-ministry",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
