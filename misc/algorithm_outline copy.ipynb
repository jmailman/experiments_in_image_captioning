{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "veterinary-scanning",
   "metadata": {},
   "source": [
    "## 1 — Recognize objects in image (or classify image)\n",
    "\n",
    "Using trained NN, get object label or labels for image, or otherwise provide a label for the image. Also store the centrality of the object. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-arctic",
   "metadata": {},
   "source": [
    "## 2  — Generate semantic word families\n",
    "\n",
    "For each label, use Word2Vec `similar` to retrieve list of words semantically related to the image object labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-parameter",
   "metadata": {},
   "source": [
    "## 3 — Generate all related words\n",
    "\n",
    "For each semantically related (below a distance threshold) word to each object label, measure its phonetic similarity to all words in the dictionary. Also store each words's distance.\n",
    "\n",
    "For each word in each semantic family, sort and choose the phonetically closest (below a distance threshold) words.\n",
    "(One way is to convert the word to IPA and compare to an IPA converted version of every word in the CMU dictionary.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-doctrine",
   "metadata": {},
   "source": [
    "## 4 — Gather candidate phrases\n",
    "\n",
    "For each word in the phonetic family, of each word in the semantic family, of each object label, retrieve each idiom containing the word.\n",
    "Add the idiom Id, as well as the stats on the object centrality, semantic distance, and phonetic distance, to a dataframe.\n",
    "\n",
    "Compute _suitability score_ for each word-idiom match and add this to that column of the dataframe\n",
    "\n",
    "Also, for each word in the semantic family, search the joke list for match and add that these to a joke_match dataframe, to use if there's too low a suitability score using a substitution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-maker",
   "metadata": {},
   "source": [
    "## 5 — Choose captions\n",
    "\n",
    "Sort captions dataframe by the _suitability score_\n",
    "\n",
    "Choose the top 10 and generate a list containing each caption with the original semantic family word substituted into the idiom in addition to jokes containing any of the semantic family words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-console",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "conventional-communist",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-setting",
   "metadata": {},
   "source": [
    "## -1  — Webscrape and process phrases (idioms, sayings, aphorisms)\n",
    "\n",
    "They should be converted into lists of phonetic sounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-accommodation",
   "metadata": {},
   "source": [
    "## 0  — Load `phrase_dict` pickled and processed after being scraped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-prisoner",
   "metadata": {},
   "source": [
    "#### Data structures defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "super-diesel",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Phrase = namedtuple('Phrase',['text_string', 'word_list','phon_list','string_length', 'word_count', 'prefix', 'phrase_type'])\n",
    "phrase_dict = dict()\n",
    "\n",
    "Close_word = namedtuple('Close_word', ['word', 'distance'])\n",
    "#Sem_family = namedtuple('Sem_family', ['locus_word', 'close_words'])\n",
    "Sem_family = namedtuple('Sem_family', ['locus_word', 'sem_fam_words'])\n",
    "#Sem_family = namedtuple('Sem_family', ['locus_word', 'phon_fams'])\n",
    "Phon_family = namedtuple('Phon_family', ['locus_word_str', 'close_words'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-plate",
   "metadata": {},
   "source": [
    "#### Temporary toy example of the dict of phrases, to be replaced with idioms etc. scraped from web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "living-helmet",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_string = 'Smarter than the average bear'\n",
    "w_list = t_string.lower().split()\n",
    "ph_id1 = uuid.uuid1()\n",
    "phrase_dict[ph_id1] = Phrase(text_string = t_string, word_list = w_list, phon_list = w_list, string_length = len(t_string), word_count = len(w_list), prefix=\"As usual: \", phrase_type='idiom' )\n",
    "\n",
    "# toy example of the dict\n",
    "t_string = 'Not a hair out of place'\n",
    "w_list = t_string.lower().split()\n",
    "ph_id2 = uuid.uuid1()\n",
    "phrase_dict[ph_id2] = Phrase(text_string = t_string, word_list = w_list, phon_list = w_list, string_length = len(t_string), word_count = len(w_list), prefix=\"As usual: \", phrase_type='idiom' )\n",
    "\n",
    "# toy example of the dict\n",
    "t_string = 'Three blind mice'\n",
    "w_list = t_string.lower().split()\n",
    "ph_id3 = uuid.uuid1()\n",
    "phrase_dict[ph_id3] = Phrase(text_string = t_string, word_list = w_list, phon_list = w_list, string_length = len(t_string), word_count = len(w_list), prefix=\"As usual: \", phrase_type='idiom' )\n",
    "\n",
    "# toy example of the dict\n",
    "t_string = 'I just called to say I love you'\n",
    "w_list = t_string.lower().split()\n",
    "ph_id3 = uuid.uuid1()\n",
    "phrase_dict[ph_id3] = Phrase(text_string = t_string, word_list = w_list, phon_list = w_list, string_length = len(t_string), word_count = len(w_list), prefix=\"As usual: \", phrase_type='idiom' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-termination",
   "metadata": {},
   "source": [
    "## 1 — Recognize objects in image (or classify image)\n",
    "\n",
    "Using trained NN, get object label or labels for image, or otherwise provide a label for the image. Also store the centrality of the object. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-reality",
   "metadata": {},
   "source": [
    "## 2 — Generate semantic word families\n",
    "\n",
    "For each label, use Word2Vec `similar` to retrieve list of words semantically related to the image object labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-herald",
   "metadata": {},
   "source": [
    "## 3 — Generate all related words\n",
    "\n",
    "For each semantically related (below a distance threshold) word to each object label, measure its phonetic similarity to all words in the dictionary. Also store each words's distance.\n",
    "\n",
    "For each word in each semantic family, sort and choose the phonetically closest (below a distance threshold) words.\n",
    "(One way is to convert the word to IPA and compare to an IPA converted version of every word in the CMU dictionary.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "competent-photographer",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_dictionary = ['two', 'pair', 'bear', 'scare', 'you', 'twice', 'hair', 'mice', 'speaker', 'book']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "french-trade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two_phon_fam = Phon_family(locus_word=Close_word('two', 3), close_words = [Close_word('you', 2.1)])\n",
    "# two_phon_fam\n",
    "\n",
    "# pair_phon_fam = Phon_family(locus_word=Close_word('pair', 5), close_words = [Close_word('bear', 1.5), Close_word('hair', 2.7)])\n",
    "# pair_phon_fam\n",
    "\n",
    "# twice_phon_fam = Phon_family(locus_word=Close_word('twice', 4.1), close_words = [Close_word('mice', 2.1)])\n",
    "# twice_phon_fam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "final-treasurer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import eng_to_ipa as ipa\n",
    "# ipa.get_rhymes(\"words to rhyme with)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "configured-replacement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPA_get_rhymes( w ):\n",
    "    if w == 'two':\n",
    "        return [['you']]\n",
    "    elif w == 'pair':\n",
    "        return [['bear', 'hair']]\n",
    "    else:\n",
    "        return [['mice']]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-counter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "polished-worcester",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Temporary stand-in function, to be replaced with one that computes phonetic distance\n",
    "def lev_dist( phon1, phon2 ):\n",
    "    return 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "configured-wisdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_fam_member_list = ['you']\n",
    "pair_fam_member_list = ['bear', 'hair']\n",
    "twice_fam_member_list = ['mice']\n",
    "\n",
    "def make_phon_fam_for_sem_fam_member( w, thresh=.2 ):\n",
    "    w_phon_code = w\n",
    "    close_word_list = []\n",
    "    \n",
    "    # Find words that are not necessarily rhyms but phonetically similar\n",
    "    for word in english_dictionary:\n",
    "        word_phon_code = word\n",
    "        dist = lev_dist(w_phon_code, word_phon_code)\n",
    "        if dist < thresh:\n",
    "            close_word_list.append( Close_word(word, dist) )\n",
    "    \n",
    "    rhyme_dist = .1\n",
    "    rhyme_word_list = IPA_get_rhymes( w )[0]\n",
    "    \n",
    "    # Find words that are rhymes\n",
    "    for word in rhyme_word_list:\n",
    "         close_word_list.append( Close_word(word, rhyme_dist) )\n",
    "    \n",
    "    return Phon_family(locus_word_str= w, close_words=close_word_list )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bibliographic-outside",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two_phon_fam = get_phon_fam_for_sem_fam_member( 'two' )\n",
    "# pair_phon_fam = get_phon_fam_for_sem_fam_member( 'pair' )\n",
    "# twice_phon_fam = get_phon_fam_for_sem_fam_member( 'twice' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "golden-crash",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALERT:  Need to incorporate the semantic distance somewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "waiting-covering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two_sem_fam = Sem_family(locus_word='two', phon_fams = [make_phon_fam_for_sem_fam_member( 'two' ), \\\n",
    "#                                                         make_phon_fam_for_sem_fam_member( 'pair' ), \\\n",
    "#                                                         make_phon_fam_for_sem_fam_member( 'twice' )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "blank-decade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be replaced with Word2Vec `most_similar()`\n",
    "\n",
    "def get_most_similar( w ):  \n",
    "    list_of_duples =  [('pair', .95), ('twice', .90)]\n",
    "    list_of_close_words = [Close_word( word=w_str, distance= 1 - w_sim) for w_str, w_sim in list_of_duples ]\n",
    "        \n",
    "    return list_of_close_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-wayne",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "intermediate-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_phon_fams_and_sem_family( w ):\n",
    "    sem_sim_words = get_most_similar( w )  # Eventually replace with call to Word2Vec\n",
    "\n",
    "    phon_fams_list = [make_phon_fam_for_sem_fam_member( w )]\n",
    "    \n",
    "    for close_w in sem_sim_words:\n",
    "        print( close_w )\n",
    "        phon_fams_list.append( make_phon_fam_for_sem_fam_member( close_w.word ) )\n",
    "    \n",
    "    # pass\n",
    "    # Use the code in the cell above as the basis for a for loop  \n",
    "    # First make a phonetic family for the locus word\n",
    "    # Then go trough each member of the semantic family and add a phonetic family for each\n",
    "    \n",
    "#     close_word_list = [sem_fam.locus_word]\n",
    "#     for w in sem_fam.close_words:\n",
    "\n",
    "    locus_word_ =   Close_word(w, 0.0)\n",
    "    return Sem_family(locus_word= locus_word_ , sem_fam_words = phon_fams_list)\n",
    "   \n",
    "    \n",
    "#     return Sem_family(locus_word= locus_word_ , phon_fams = [make_phon_fam_for_sem_fam_member( w ), \\\n",
    "#                                                      make_phon_fam_for_sem_fam_member( 'pair' ), \\\n",
    "#                                                      make_phon_fam_for_sem_fam_member( 'twice' )])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "abstract-amber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Close_word(word='pair', distance=0.050000000000000044)\n",
      "Close_word(word='twice', distance=0.09999999999999998)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sem_family(locus_word=Close_word(word='two', distance=0.0), sem_fam_words=[Phon_family(locus_word_str='two', close_words=[Close_word(word='you', distance=0.1)]), Phon_family(locus_word_str='pair', close_words=[Close_word(word='bear', distance=0.1), Close_word(word='hair', distance=0.1)]), Phon_family(locus_word_str='twice', close_words=[Close_word(word='mice', distance=0.1)])])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_sem_fam = make_phon_fams_and_sem_family('two')\n",
    "two_sem_fam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-flood",
   "metadata": {},
   "source": [
    "## 4 — Gather candidate phrases\n",
    "\n",
    "For each word in the phonetic family, of each word in the semantic family, of each object label, retrieve phrases containing the word.\n",
    "Add the phrase_Id, as well as the stats on the object centrality, semantic distance, and phonetic distance, to a dataframe.\n",
    "\n",
    "Compute _suitability score_ for each word-phrase match and add this to that column of the dataframe\n",
    "\n",
    "Also, for each word in the semantic family, search the joke list for match and add that these to a joke_match dataframe, to use if there's too low a suitability score using a substitution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-payment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-terrorist",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "short-dodge",
   "metadata": {},
   "source": [
    "## TO CODE NEXT\n",
    "\n",
    "Write code that takes the word `twice` and returns its `semantic_family` which is a list of words \n",
    "('pair', and 'twice' in this case) and returns either (TBD) the list phonetically similar words or \n",
    "the pboneticized version of the word to be compared with the phoneticized variants of words in\n",
    "the phrases\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-questionnaire",
   "metadata": {},
   "source": [
    "#### Define dataframe for candidate phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "boolean-details",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>semantic_match</th>\n",
       "      <th>sem_dist</th>\n",
       "      <th>phonetic_match</th>\n",
       "      <th>phon_dist</th>\n",
       "      <th>phrase_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [semantic_match, sem_dist, phonetic_match, phon_dist, phrase_id, score]\n",
       "Index: []"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ['semantic_match', 'sem_dist', 'phonetic_match', 'phon_dist', 'phrase_id', 'score']\n",
    "\n",
    "cand_df = pd.DataFrame(columns= col_names)\n",
    "cand_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-skill",
   "metadata": {},
   "source": [
    "#### Need to write body of function that will convert to phoneticized version of word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "communist-quality",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phoneticized( w ):\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-updating",
   "metadata": {},
   "source": [
    "### ALERT:  Instead, pre-generate a dictionary of phoneticized versions of the words in the list of idioms. Each phonetic word should map to a list of duples each of which is a phrase id and the corresponding word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "surprised-homework",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matching_phrases( w ):\n",
    "    matched_id_list = []\n",
    "    for phrase_id in phrase_dict.keys():\n",
    "        if w in phrase_dict[phrase_id].phon_list:\n",
    "            matched_id_list.append(phrase_id)\n",
    "    return matched_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "outside-northwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_matching_phrases('bear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "overall-private",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  cycles through each phonetic family in the semantic family to get matching phrases\n",
    "\n",
    "def get_phrases_for_phon_fam( phon_fam_, sem_dist_ ):\n",
    "\n",
    "    word_match_records_ = []\n",
    "\n",
    "    #phon_fam_ = pair_phon_fam\n",
    "    for word in phon_fam_.close_words:\n",
    "        matched_phrases = get_matching_phrases( word.word )\n",
    "        #print(word, len(matched_phrases))\n",
    "        if matched_phrases:\n",
    "            for p_id in matched_phrases:\n",
    "                word_match_records_.append({'semantic_match': phon_fam_.locus_word_str, 'sem_dist': sem_dist_, 'phonetic_match': word.word, 'phon_dist': word.distance, 'phrase_id': p_id, 'score': ''})\n",
    "    return word_match_records_ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "sorted-tribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phrases_for_sem_fam( sem_fam_ ):\n",
    "    word_match_records_ = []\n",
    "    for phon_fam_ in sem_fam_.sem_fam_words:\n",
    "        print( sem_fam_.locus_word.distance )\n",
    "        word_match_records_.extend( get_phrases_for_phon_fam( phon_fam_, sem_fam_.locus_word.distance ) )\n",
    "    return word_match_records_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "terminal-mixer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_match_records = []   \n",
    "\n",
    "# word_match_records.extend( get_phrases_for_phon_fam( two_phon_fam ) ) \n",
    "# word_match_records.extend( get_phrases_for_phon_fam( pair_phon_fam ) )\n",
    "# word_match_records.extend( get_phrases_for_phon_fam( twice_phon_fam ) )  \n",
    "# word_match_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "independent-turning",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cand_df = cand_df.append(word_match_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "partial-thanks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sem_family(locus_word=Close_word(word='two', distance=0.0), sem_fam_words=[Phon_family(locus_word_str='two', close_words=[Close_word(word='you', distance=0.1)]), Phon_family(locus_word_str='pair', close_words=[Close_word(word='bear', distance=0.1), Close_word(word='hair', distance=0.1)]), Phon_family(locus_word_str='twice', close_words=[Close_word(word='mice', distance=0.1)])])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_sem_fam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "trained-prefix",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_match_records = get_phrases_for_sem_fam( two_sem_fam )\n",
    "# word_match_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "black-brush",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be replaced with image recognition algorithms\n",
    "def get_image_topics():\n",
    "    return ['two']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-pollution",
   "metadata": {},
   "source": [
    "## The equivalent of `main` for the time being, until two or more image topics are handled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "driving-submission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Close_word(word='pair', distance=0.050000000000000044)\n",
      "Close_word(word='twice', distance=0.09999999999999998)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "image_topics     = get_image_topics()\n",
    "image_topic_word = image_topics[0]\n",
    "\n",
    "two_sem_fam = make_phon_fams_and_sem_family( image_topic_word )\n",
    "#two_sem_fam\n",
    "\n",
    "word_match_records = get_phrases_for_sem_fam( two_sem_fam )\n",
    "\n",
    "cand_df = cand_df.append(word_match_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "resistant-proceeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cand_df = pd.DataFrame({\"semantic_match\": ['pair','pair','twice'], \"sem_dist\": [5, 5, 4.1], \"phonetic_match\": ['bear', 'hair','mice'], \"phon_dist\": [1.5, 2.7, 2.1], \"phrase_id\":  [ph_id1, ph_id2,ph_id3], \"phrase_type\":  ['idiom', 'idiom','idiom'],'score': [.5, .3, 1.1]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "heard-crest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>semantic_match</th>\n",
       "      <th>sem_dist</th>\n",
       "      <th>phonetic_match</th>\n",
       "      <th>phon_dist</th>\n",
       "      <th>phrase_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>two</td>\n",
       "      <td>0.0</td>\n",
       "      <td>you</td>\n",
       "      <td>0.1</td>\n",
       "      <td>c2c6cf42-7fc5-11eb-9afd-acde48001122</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pair</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bear</td>\n",
       "      <td>0.1</td>\n",
       "      <td>c2c6be08-7fc5-11eb-9afd-acde48001122</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pair</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hair</td>\n",
       "      <td>0.1</td>\n",
       "      <td>c2c6c45c-7fc5-11eb-9afd-acde48001122</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>twice</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mice</td>\n",
       "      <td>0.1</td>\n",
       "      <td>c2c6c9f2-7fc5-11eb-9afd-acde48001122</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  semantic_match  sem_dist phonetic_match  phon_dist  \\\n",
       "0            two       0.0            you        0.1   \n",
       "1           pair       0.0           bear        0.1   \n",
       "2           pair       0.0           hair        0.1   \n",
       "3          twice       0.0           mice        0.1   \n",
       "\n",
       "                              phrase_id score  \n",
       "0  c2c6cf42-7fc5-11eb-9afd-acde48001122        \n",
       "1  c2c6be08-7fc5-11eb-9afd-acde48001122        \n",
       "2  c2c6c45c-7fc5-11eb-9afd-acde48001122        \n",
       "3  c2c6c9f2-7fc5-11eb-9afd-acde48001122        "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cand_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "grateful-favor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>semantic_match</th>\n",
       "      <th>sem_dist</th>\n",
       "      <th>phonetic_match</th>\n",
       "      <th>phon_dist</th>\n",
       "      <th>phrase_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>two</td>\n",
       "      <td>0.0</td>\n",
       "      <td>you</td>\n",
       "      <td>0.1</td>\n",
       "      <td>c2c6cf42-7fc5-11eb-9afd-acde48001122</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pair</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bear</td>\n",
       "      <td>0.1</td>\n",
       "      <td>c2c6be08-7fc5-11eb-9afd-acde48001122</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pair</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hair</td>\n",
       "      <td>0.1</td>\n",
       "      <td>c2c6c45c-7fc5-11eb-9afd-acde48001122</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>twice</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mice</td>\n",
       "      <td>0.1</td>\n",
       "      <td>c2c6c9f2-7fc5-11eb-9afd-acde48001122</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  semantic_match  sem_dist phonetic_match  phon_dist  \\\n",
       "0            two       0.0            you        0.1   \n",
       "1           pair       0.0           bear        0.1   \n",
       "2           pair       0.0           hair        0.1   \n",
       "3          twice       0.0           mice        0.1   \n",
       "\n",
       "                              phrase_id  score  \n",
       "0  c2c6cf42-7fc5-11eb-9afd-acde48001122   10.0  \n",
       "1  c2c6be08-7fc5-11eb-9afd-acde48001122   10.0  \n",
       "2  c2c6c45c-7fc5-11eb-9afd-acde48001122   10.0  \n",
       "3  c2c6c9f2-7fc5-11eb-9afd-acde48001122   10.0  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cand_df['score'] = cand_df.apply(lambda row: 1.0/(row['sem_dist'] + row['phon_dist']), axis=1)\n",
    "cand_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-dressing",
   "metadata": {},
   "source": [
    "## 5 —  Choose captions\n",
    "\n",
    "Sort captions dataframe by the _suitability score_\n",
    "\n",
    "Choose the top 10(?) and generate a list containing each caption with the original semantic family word substituted into the idiom in addition to jokes containing any of the semantic family words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "facial-brooks",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub(phrase, orig_word='', new_word=''):\n",
    "    return phrase.text_string.replace(orig_word, new_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-musical",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "nutritional-friendship",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_caption( row ):\n",
    "    return sub( phrase_dict[ row['phrase_id']], row['phonetic_match'],  row['semantic_match']  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "accessible-modem",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_captions(df, selection_size=10):\n",
    "    df.sort_values(by='score', inplace=True)\n",
    "    best_df = df.head(selection_size)\n",
    "    best_df['caption'] = best_df.apply(construct_caption, axis=1 )    \n",
    "    return best_df\n",
    "    #return best_df['_caption'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-supervision",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "authentic-appeal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-148-0abcd1c06ef8>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  best_df['caption'] = best_df.apply(construct_caption, axis=1 )\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>semantic_match</th>\n",
       "      <th>sem_dist</th>\n",
       "      <th>phonetic_match</th>\n",
       "      <th>phon_dist</th>\n",
       "      <th>phrase_id</th>\n",
       "      <th>score</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>two</td>\n",
       "      <td>0.0</td>\n",
       "      <td>you</td>\n",
       "      <td>0.1</td>\n",
       "      <td>c2c6cf42-7fc5-11eb-9afd-acde48001122</td>\n",
       "      <td>10.0</td>\n",
       "      <td>I just called to say I love two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pair</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bear</td>\n",
       "      <td>0.1</td>\n",
       "      <td>c2c6be08-7fc5-11eb-9afd-acde48001122</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Smarter than the average pair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pair</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hair</td>\n",
       "      <td>0.1</td>\n",
       "      <td>c2c6c45c-7fc5-11eb-9afd-acde48001122</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Not a pair out of place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>twice</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mice</td>\n",
       "      <td>0.1</td>\n",
       "      <td>c2c6c9f2-7fc5-11eb-9afd-acde48001122</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Three blind twice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  semantic_match  sem_dist phonetic_match  phon_dist  \\\n",
       "0            two       0.0            you        0.1   \n",
       "1           pair       0.0           bear        0.1   \n",
       "2           pair       0.0           hair        0.1   \n",
       "3          twice       0.0           mice        0.1   \n",
       "\n",
       "                              phrase_id  score  \\\n",
       "0  c2c6cf42-7fc5-11eb-9afd-acde48001122   10.0   \n",
       "1  c2c6be08-7fc5-11eb-9afd-acde48001122   10.0   \n",
       "2  c2c6c45c-7fc5-11eb-9afd-acde48001122   10.0   \n",
       "3  c2c6c9f2-7fc5-11eb-9afd-acde48001122   10.0   \n",
       "\n",
       "                           caption  \n",
       "0  I just called to say I love two  \n",
       "1    Smarter than the average pair  \n",
       "2          Not a pair out of place  \n",
       "3                Three blind twice  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_captions_df = get_best_captions(cand_df)\n",
    "best_captions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "radical-burner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I just called to say I love two',\n",
       " 'Smarter than the average pair',\n",
       " 'Not a pair out of place',\n",
       " 'Three blind twice']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_captions_list = best_captions_df['caption'].to_list()\n",
    "best_captions_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-thompson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resistant-reducing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-equivalent",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-issue",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-nursery",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
