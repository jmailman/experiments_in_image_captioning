{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bound-accommodation",
   "metadata": {},
   "source": [
    "## 1 Recognize objects in image (or classify image)\n",
    "\n",
    "Using trained NN, get object label or labels for image, or otherwise provide a label for the image. Also store the centrality of the object. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-laundry",
   "metadata": {},
   "source": [
    "## 2 Generate semantic word families\n",
    "\n",
    "For each label, use Word2Vec `similar` to retrieve list of words semantically related to the image object labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-fleet",
   "metadata": {},
   "source": [
    "## 3 Generate all related words\n",
    "\n",
    "For each semantically related (below a distance threshold) word to each object label, measure its phonetic similarity to all words in the dictionary. Also store each words's distance.\n",
    "\n",
    "For each word in each semantic family, sort and choose the phonetically closest (below a distance threshold) words.\n",
    "(One way is to convert the word to IPA and compare to an IPA converted version of every word in the CMU dictionary.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identified-shame",
   "metadata": {},
   "source": [
    "## 4 Generate captions\n",
    "\n",
    "For each word in the phonetic family, of each word in the semantic family, of each object label, retrieve each idiom containing the word.\n",
    "Add the idiom Id, as well as the stats on the object centrality, semantic distance, and phonetic distance, to a dataframe.\n",
    "\n",
    "Compute _suitability score_ for each word-idiom match and add this to that column of the dataframe\n",
    "\n",
    "Also, for each word in the semantic family, search the joke list for match and add that these to a joke_match dataframe, to use if there's too low a suitability score using a substitution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-alpha",
   "metadata": {},
   "source": [
    "## 5 Choose captions\n",
    "\n",
    "Sort captions dataframe by the _suitability score_\n",
    "\n",
    "Choose the top 10 and generate a list containing each caption with the original semantic family word substituted into the idiom in addition to jokes containing any of the semantic family words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-bones",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "prepared-edinburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-wildlife",
   "metadata": {},
   "source": [
    "## 1 Recognize objects in image (or classify image)\n",
    "\n",
    "Using trained NN, get object label or labels for image, or otherwise provide a label for the image. Also store the centrality of the object. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-prison",
   "metadata": {},
   "source": [
    "## 2 Generate semantic word families\n",
    "\n",
    "For each label, use Word2Vec `similar` to retrieve list of words semantically related to the image object labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-technician",
   "metadata": {},
   "source": [
    "## 3 Generate all related words\n",
    "\n",
    "For each semantically related (below a distance threshold) word to each object label, measure its phonetic similarity to all words in the dictionary. Also store each words's distance.\n",
    "\n",
    "For each word in each semantic family, sort and choose the phonetically closest (below a distance threshold) words.\n",
    "(One way is to convert the word to IPA and compare to an IPA converted version of every word in the CMU dictionary.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-blackberry",
   "metadata": {},
   "source": [
    "## 4 Generate captions\n",
    "\n",
    "For each word in the phonetic family, of each word in the semantic family, of each object label, retrieve phrases containing the word.\n",
    "Add the phrase_Id, as well as the stats on the object centrality, semantic distance, and phonetic distance, to a dataframe.\n",
    "\n",
    "Compute _suitability score_ for each word-phrase match and add this to that column of the dataframe\n",
    "\n",
    "Also, for each word in the semantic family, search the joke list for match and add that these to a joke_match dataframe, to use if there's too low a suitability score using a substitution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "forced-amount",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "delayed-adobe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Phrase = namedtuple('Phrase',['text_string', 'word_list','phon_list','string_length', 'word_count', 'prefix', 'phrase_type'])\n",
    "phrase_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "impressive-means",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# toy example of the dict of phrases\n",
    "t_string = 'Smarter than the average bear'\n",
    "w_list = t_string.lower().split()\n",
    "ph_id1 = uuid.uuid1()\n",
    "phrase_dict[ph_id1] = Phrase(text_string = t_string, word_list = w_list, phon_list = w_list, string_length = len(t_string), word_count = len(w_list), prefix=\"As usual: \", phrase_type='idiom' )\n",
    "\n",
    "# toy example of the dict\n",
    "t_string = 'Not a hair out of place'\n",
    "w_list = t_string.lower().split()\n",
    "ph_id2 = uuid.uuid1()\n",
    "phrase_dict[ph_id2] = Phrase(text_string = t_string, word_list = w_list, phon_list = w_list, string_length = len(t_string), word_count = len(w_list), prefix=\"As usual: \", phrase_type='idiom' )\n",
    "\n",
    "# toy example of the dict\n",
    "t_string = 'Three blind mice'\n",
    "w_list = t_string.lower().split()\n",
    "ph_id3 = uuid.uuid1()\n",
    "phrase_dict[ph_id3] = Phrase(text_string = t_string, word_list = w_list, phon_list = w_list, string_length = len(t_string), word_count = len(w_list), prefix=\"As usual: \", phrase_type='idiom' )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-signal",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_dict[ph_id1].word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "surprised-shift",
   "metadata": {},
   "outputs": [],
   "source": [
    "Close_word = namedtuple('Close_word', ['word', 'distance'])\n",
    "Phon_family = namedtuple('Phon_family', ['locus_word', 'close_words'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "bound-revolution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Phon_family(locus_word='twice', close_words=[Close_word(word='mice', distance=2.1)])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_phon_fam = Phon_family(locus_word='pair', close_words = [Close_word('bear', 1.5), Close_word('hair', 2.7)])\n",
    "pair_phon_fam\n",
    "\n",
    "twice_phon_fam = Phon_family(locus_word='twice', close_words = [Close_word('mice', 2.1)])\n",
    "twice_phon_fam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "auburn-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "col_names = ['semantic_match', 'sem_dist', 'phonetic_match', 'phon_dist', 'phrase_id', 'score']\n",
    "\n",
    "cand_df = pd.DataFrame({\"semantic_match\": ['pair','pair','twice'], \"sem_dist\": [5, 5, 4.1], \"phonetic_match\": ['bear', 'hair','mice'], \"phon_dist\": [1.5, 2.7, 2.1], \"phrase_id\":  [ph_id1, ph_id2,ph_id3], \"phrase_type\":  ['idiom', 'idiom','idiom'],'score': [.5, .3, 1.1]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-gross",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "fancy-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "cand_df['score'] = cand_df.apply(lambda row: 1.0/(row['sem_dist'] + row['phon_dist']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-burst",
   "metadata": {},
   "source": [
    "## 5 Choose captions\n",
    "\n",
    "Sort captions dataframe by the _suitability score_\n",
    "\n",
    "Choose the top 10(?) and generate a list containing each caption with the original semantic family word substituted into the idiom in addition to jokes containing any of the semantic family words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "magnetic-poland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub(phrase, orig_word='', new_word=''):\n",
    "    return phrase.text_string.replace(orig_word, new_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "dying-alpha",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_caption( row ):\n",
    "    return sub( phrase_dict[ row['phrase_id']], row['phonetic_match'],  row['semantic_match']  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "threaded-density",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_captions(df, selection_size=10):\n",
    "    df.sort_values(by='score', inplace=True)\n",
    "    best_df = df.head(selection_size)\n",
    "    best_df['caption'] = best_df.apply(construct_caption, axis=1 )    \n",
    "    return best_df\n",
    "    #return best_df['_caption'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-vocabulary",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "stainless-strike",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-194-0abcd1c06ef8>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  best_df['caption'] = best_df.apply(construct_caption, axis=1 )\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>semantic_match</th>\n",
       "      <th>sem_dist</th>\n",
       "      <th>phonetic_match</th>\n",
       "      <th>phon_dist</th>\n",
       "      <th>phrase_id</th>\n",
       "      <th>phrase_type</th>\n",
       "      <th>score</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pair</td>\n",
       "      <td>5.0</td>\n",
       "      <td>hair</td>\n",
       "      <td>2.7</td>\n",
       "      <td>affde124-7ed1-11eb-ba55-acde48001122</td>\n",
       "      <td>idiom</td>\n",
       "      <td>0.129870</td>\n",
       "      <td>Not a pair out of place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pair</td>\n",
       "      <td>5.0</td>\n",
       "      <td>bear</td>\n",
       "      <td>1.5</td>\n",
       "      <td>affdd990-7ed1-11eb-ba55-acde48001122</td>\n",
       "      <td>idiom</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>Smarter than the average pair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>twice</td>\n",
       "      <td>4.1</td>\n",
       "      <td>mice</td>\n",
       "      <td>2.1</td>\n",
       "      <td>affde7be-7ed1-11eb-ba55-acde48001122</td>\n",
       "      <td>idiom</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>Three blind twice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  semantic_match  sem_dist phonetic_match  phon_dist  \\\n",
       "1           pair       5.0           hair        2.7   \n",
       "0           pair       5.0           bear        1.5   \n",
       "2          twice       4.1           mice        2.1   \n",
       "\n",
       "                              phrase_id phrase_type     score  \\\n",
       "1  affde124-7ed1-11eb-ba55-acde48001122       idiom  0.129870   \n",
       "0  affdd990-7ed1-11eb-ba55-acde48001122       idiom  0.153846   \n",
       "2  affde7be-7ed1-11eb-ba55-acde48001122       idiom  0.161290   \n",
       "\n",
       "                         caption  \n",
       "1        Not a pair out of place  \n",
       "0  Smarter than the average pair  \n",
       "2              Three blind twice  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_captions_df = get_best_captions(cand_df)\n",
    "best_captions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "loose-skiing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Not a pair out of place',\n",
       " 'Smarter than the average pair',\n",
       " 'Three blind twice']"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_captions_list = best_captions_df['caption'].to_list()\n",
    "best_captions_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-milwaukee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-christopher",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-sixth",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
