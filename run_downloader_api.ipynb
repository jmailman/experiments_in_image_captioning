{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "How to download pre-trained models and corpora\n",
    "==============================================\n",
    "\n",
    "Demonstrates simple and quick access to common corpora and pretrained models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of Gensim's features is simple and easy access to common data.\n",
    "The `gensim-data <https://github.com/RaRe-Technologies/gensim-data>`_ project stores a\n",
    "variety of corpora and pretrained models.\n",
    "Gensim has a :py:mod:`gensim.downloader` module for programmatically accessing this data.\n",
    "This module leverages a local cache (in user's home folder, by default) that\n",
    "ensures data is downloaded at most once.\n",
    "\n",
    "This tutorial:\n",
    "\n",
    "* Downloads the text8 corpus, unless it is already on your local machine\n",
    "* Trains a Word2Vec model from the corpus (see `sphx_glr_auto_examples_tutorials_run_doc2vec_lee.py` for a detailed tutorial)\n",
    "* Leverages the model to calculate word similarity\n",
    "* Demonstrates using the API to load other models and corpora\n",
    "\n",
    "Let's start by importing the api module.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's download the text8 corpus and load it as a Python object\n",
    "that supports streamed access.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-19 00:00:26,643 : INFO : Creating /Users/joshuamailman/gensim-data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 31.6/31.6MB downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-19 00:00:41,083 : INFO : text8 downloaded\n"
     ]
    }
   ],
   "source": [
    "corpus = api.load('text8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, our corpus is an iterable.\n",
    "If you look under the covers, it has the following definition:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class Dataset(object):\n",
      "    def __init__(self, fn):\n",
      "        self.fn = fn\n",
      "\n",
      "    def __iter__(self):\n",
      "        corpus = Text8Corpus(self.fn)\n",
      "        for doc in corpus:\n",
      "            yield doc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "print(inspect.getsource(corpus.__class__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more details, look inside the file that defines the Dataset class for your particular resource.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joshuamailman/gensim-data/text8/__init__.py\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getfile(corpus.__class__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the corpus has been downloaded and loaded, let's use it to train a word2vec model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-19 00:02:48,447 : INFO : collecting all words and their counts\n",
      "2021-03-19 00:02:48,458 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-03-19 00:03:11,880 : INFO : collected 253854 word types from a corpus of 17005207 raw words and 1701 sentences\n",
      "2021-03-19 00:03:11,887 : INFO : Loading a fresh vocabulary\n",
      "2021-03-19 00:03:13,035 : INFO : effective_min_count=5 retains 71290 unique words (28% of original 253854, drops 182564)\n",
      "2021-03-19 00:03:13,048 : INFO : effective_min_count=5 leaves 16718844 word corpus (98% of original 17005207, drops 286363)\n",
      "2021-03-19 00:03:13,580 : INFO : deleting the raw counts dictionary of 253854 items\n",
      "2021-03-19 00:03:13,598 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2021-03-19 00:03:13,600 : INFO : downsampling leaves estimated 12506280 word corpus (74.8% of prior 16718844)\n",
      "2021-03-19 00:03:14,225 : INFO : estimated required memory for 71290 words and 100 dimensions: 92677000 bytes\n",
      "2021-03-19 00:03:14,230 : INFO : resetting layer weights\n",
      "2021-03-19 00:03:57,393 : INFO : training model with 3 workers on 71290 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2021-03-19 00:03:58,458 : INFO : EPOCH 1 - PROGRESS: at 3.12% examples, 377583 words/s, in_qsize 5, out_qsize 1\n",
      "2021-03-19 00:03:59,475 : INFO : EPOCH 1 - PROGRESS: at 6.35% examples, 383459 words/s, in_qsize 6, out_qsize 0\n",
      "2021-03-19 00:04:00,495 : INFO : EPOCH 1 - PROGRESS: at 9.05% examples, 365336 words/s, in_qsize 4, out_qsize 1\n",
      "2021-03-19 00:04:01,508 : INFO : EPOCH 1 - PROGRESS: at 11.99% examples, 364216 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:04:02,530 : INFO : EPOCH 1 - PROGRESS: at 14.81% examples, 360135 words/s, in_qsize 4, out_qsize 2\n",
      "2021-03-19 00:04:03,573 : INFO : EPOCH 1 - PROGRESS: at 17.64% examples, 356601 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:04:04,597 : INFO : EPOCH 1 - PROGRESS: at 20.63% examples, 357868 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:04:05,599 : INFO : EPOCH 1 - PROGRESS: at 23.40% examples, 356719 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:04:06,602 : INFO : EPOCH 1 - PROGRESS: at 26.40% examples, 358863 words/s, in_qsize 6, out_qsize 0\n",
      "2021-03-19 00:04:07,619 : INFO : EPOCH 1 - PROGRESS: at 29.34% examples, 359594 words/s, in_qsize 4, out_qsize 1\n",
      "2021-03-19 00:04:08,627 : INFO : EPOCH 1 - PROGRESS: at 32.39% examples, 361824 words/s, in_qsize 4, out_qsize 1\n",
      "2021-03-19 00:04:09,662 : INFO : EPOCH 1 - PROGRESS: at 35.27% examples, 361012 words/s, in_qsize 3, out_qsize 2\n",
      "2021-03-19 00:04:10,663 : INFO : EPOCH 1 - PROGRESS: at 38.45% examples, 363776 words/s, in_qsize 6, out_qsize 0\n",
      "2021-03-19 00:04:11,710 : INFO : EPOCH 1 - PROGRESS: at 41.45% examples, 363395 words/s, in_qsize 4, out_qsize 1\n",
      "2021-03-19 00:04:12,755 : INFO : EPOCH 1 - PROGRESS: at 44.80% examples, 366149 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:04:13,789 : INFO : EPOCH 1 - PROGRESS: at 47.80% examples, 366020 words/s, in_qsize 3, out_qsize 2\n",
      "2021-03-19 00:04:14,801 : INFO : EPOCH 1 - PROGRESS: at 50.85% examples, 366878 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:04:15,809 : INFO : EPOCH 1 - PROGRESS: at 53.62% examples, 365571 words/s, in_qsize 3, out_qsize 2\n",
      "2021-03-19 00:04:16,812 : INFO : EPOCH 1 - PROGRESS: at 56.91% examples, 367987 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:04:17,844 : INFO : EPOCH 1 - PROGRESS: at 59.79% examples, 367104 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:04:18,880 : INFO : EPOCH 1 - PROGRESS: at 62.96% examples, 367930 words/s, in_qsize 5, out_qsize 1\n",
      "2021-03-19 00:04:19,897 : INFO : EPOCH 1 - PROGRESS: at 66.14% examples, 368940 words/s, in_qsize 6, out_qsize 0\n",
      "2021-03-19 00:04:20,913 : INFO : EPOCH 1 - PROGRESS: at 69.37% examples, 370292 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:04:21,918 : INFO : EPOCH 1 - PROGRESS: at 72.55% examples, 371377 words/s, in_qsize 4, out_qsize 0\n",
      "2021-03-19 00:04:22,918 : INFO : EPOCH 1 - PROGRESS: at 75.43% examples, 370712 words/s, in_qsize 4, out_qsize 1\n",
      "2021-03-19 00:04:23,950 : INFO : EPOCH 1 - PROGRESS: at 78.60% examples, 370882 words/s, in_qsize 4, out_qsize 1\n",
      "2021-03-19 00:04:24,968 : INFO : EPOCH 1 - PROGRESS: at 81.60% examples, 370716 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:04:25,972 : INFO : EPOCH 1 - PROGRESS: at 84.54% examples, 370534 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:04:26,977 : INFO : EPOCH 1 - PROGRESS: at 87.48% examples, 370347 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:04:27,997 : INFO : EPOCH 1 - PROGRESS: at 90.30% examples, 369647 words/s, in_qsize 5, out_qsize 1\n",
      "2021-03-19 00:04:29,022 : INFO : EPOCH 1 - PROGRESS: at 93.30% examples, 369381 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:04:30,043 : INFO : EPOCH 1 - PROGRESS: at 95.59% examples, 366596 words/s, in_qsize 4, out_qsize 1\n",
      "2021-03-19 00:04:31,045 : INFO : EPOCH 1 - PROGRESS: at 98.35% examples, 365807 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:04:31,589 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-19 00:04:31,597 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-19 00:04:31,613 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-19 00:04:31,615 : INFO : EPOCH - 1 : training on 17005207 raw words (12505970 effective words) took 34.2s, 365719 effective words/s\n",
      "2021-03-19 00:04:32,645 : INFO : EPOCH 2 - PROGRESS: at 3.29% examples, 402871 words/s, in_qsize 4, out_qsize 1\n",
      "2021-03-19 00:04:33,656 : INFO : EPOCH 2 - PROGRESS: at 6.23% examples, 380316 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:04:34,664 : INFO : EPOCH 2 - PROGRESS: at 9.29% examples, 378642 words/s, in_qsize 4, out_qsize 1\n",
      "2021-03-19 00:04:35,668 : INFO : EPOCH 2 - PROGRESS: at 12.17% examples, 373429 words/s, in_qsize 4, out_qsize 1\n",
      "2021-03-19 00:04:36,678 : INFO : EPOCH 2 - PROGRESS: at 15.29% examples, 375602 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:04:37,718 : INFO : EPOCH 2 - PROGRESS: at 18.28% examples, 373136 words/s, in_qsize 6, out_qsize 0\n",
      "2021-03-19 00:04:38,722 : INFO : EPOCH 2 - PROGRESS: at 21.34% examples, 374270 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:04:39,769 : INFO : EPOCH 2 - PROGRESS: at 23.75% examples, 363680 words/s, in_qsize 4, out_qsize 1\n",
      "2021-03-19 00:04:40,807 : INFO : EPOCH 2 - PROGRESS: at 26.57% examples, 361128 words/s, in_qsize 4, out_qsize 2\n",
      "2021-03-19 00:04:41,811 : INFO : EPOCH 2 - PROGRESS: at 29.39% examples, 360631 words/s, in_qsize 6, out_qsize 0\n",
      "2021-03-19 00:04:42,833 : INFO : EPOCH 2 - PROGRESS: at 32.04% examples, 357709 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:04:43,849 : INFO : EPOCH 2 - PROGRESS: at 35.04% examples, 359050 words/s, in_qsize 6, out_qsize 0\n",
      "2021-03-19 00:04:44,888 : INFO : EPOCH 2 - PROGRESS: at 37.68% examples, 356020 words/s, in_qsize 4, out_qsize 1\n",
      "2021-03-19 00:04:45,928 : INFO : EPOCH 2 - PROGRESS: at 40.68% examples, 356362 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:04:46,936 : INFO : EPOCH 2 - PROGRESS: at 43.45% examples, 355576 words/s, in_qsize 4, out_qsize 0\n",
      "2021-03-19 00:04:47,953 : INFO : EPOCH 2 - PROGRESS: at 46.50% examples, 356964 words/s, in_qsize 6, out_qsize 0\n",
      "2021-03-19 00:04:48,963 : INFO : EPOCH 2 - PROGRESS: at 49.32% examples, 356602 words/s, in_qsize 4, out_qsize 1\n",
      "2021-03-19 00:04:49,973 : INFO : EPOCH 2 - PROGRESS: at 52.50% examples, 358642 words/s, in_qsize 6, out_qsize 0\n",
      "2021-03-19 00:04:51,004 : INFO : EPOCH 2 - PROGRESS: at 55.32% examples, 357961 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:04:52,050 : INFO : EPOCH 2 - PROGRESS: at 58.50% examples, 359093 words/s, in_qsize 5, out_qsize 1\n",
      "2021-03-19 00:04:53,081 : INFO : EPOCH 2 - PROGRESS: at 61.49% examples, 359431 words/s, in_qsize 5, out_qsize 1\n",
      "2021-03-19 00:04:54,107 : INFO : EPOCH 2 - PROGRESS: at 64.49% examples, 359695 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:04:55,116 : INFO : EPOCH 2 - PROGRESS: at 67.43% examples, 359902 words/s, in_qsize 4, out_qsize 0\n",
      "2021-03-19 00:04:56,117 : INFO : EPOCH 2 - PROGRESS: at 70.61% examples, 361515 words/s, in_qsize 3, out_qsize 2\n",
      "2021-03-19 00:04:57,127 : INFO : EPOCH 2 - PROGRESS: at 73.66% examples, 362296 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:04:58,135 : INFO : EPOCH 2 - PROGRESS: at 76.84% examples, 362956 words/s, in_qsize 5, out_qsize 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-19 00:04:59,145 : INFO : EPOCH 2 - PROGRESS: at 79.89% examples, 363390 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:05:00,170 : INFO : EPOCH 2 - PROGRESS: at 83.07% examples, 364163 words/s, in_qsize 4, out_qsize 1\n",
      "2021-03-19 00:05:01,172 : INFO : EPOCH 2 - PROGRESS: at 86.13% examples, 364789 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:05:02,179 : INFO : EPOCH 2 - PROGRESS: at 89.30% examples, 365789 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:05:03,183 : INFO : EPOCH 2 - PROGRESS: at 91.71% examples, 363654 words/s, in_qsize 6, out_qsize 0\n",
      "2021-03-19 00:05:04,221 : INFO : EPOCH 2 - PROGRESS: at 94.53% examples, 362817 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:05:05,222 : INFO : EPOCH 2 - PROGRESS: at 97.18% examples, 361803 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:05:05,943 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-19 00:05:05,947 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-19 00:05:05,949 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-19 00:05:05,950 : INFO : EPOCH - 2 : training on 17005207 raw words (12507847 effective words) took 34.3s, 364335 effective words/s\n",
      "2021-03-19 00:05:06,991 : INFO : EPOCH 3 - PROGRESS: at 4.64% examples, 578583 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:05:08,031 : INFO : EPOCH 3 - PROGRESS: at 7.58% examples, 460543 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:05:09,034 : INFO : EPOCH 3 - PROGRESS: at 10.88% examples, 442736 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:05:10,056 : INFO : EPOCH 3 - PROGRESS: at 13.76% examples, 420331 words/s, in_qsize 4, out_qsize 1\n",
      "2021-03-19 00:05:11,062 : INFO : EPOCH 3 - PROGRESS: at 17.05% examples, 417823 words/s, in_qsize 4, out_qsize 0\n",
      "2021-03-19 00:05:12,097 : INFO : EPOCH 3 - PROGRESS: at 19.93% examples, 405840 words/s, in_qsize 6, out_qsize 0\n",
      "2021-03-19 00:05:13,131 : INFO : EPOCH 3 - PROGRESS: at 23.10% examples, 403133 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:05:14,139 : INFO : EPOCH 3 - PROGRESS: at 25.75% examples, 394253 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:05:15,165 : INFO : EPOCH 3 - PROGRESS: at 28.98% examples, 394685 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:05:16,177 : INFO : EPOCH 3 - PROGRESS: at 31.98% examples, 392761 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:05:17,185 : INFO : EPOCH 3 - PROGRESS: at 35.57% examples, 398006 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:05:18,187 : INFO : EPOCH 3 - PROGRESS: at 38.62% examples, 396690 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:05:19,192 : INFO : EPOCH 3 - PROGRESS: at 41.86% examples, 397229 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:05:20,195 : INFO : EPOCH 3 - PROGRESS: at 44.74% examples, 394667 words/s, in_qsize 4, out_qsize 1\n",
      "2021-03-19 00:05:21,196 : INFO : EPOCH 3 - PROGRESS: at 48.09% examples, 396386 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:05:22,197 : INFO : EPOCH 3 - PROGRESS: at 51.03% examples, 394667 words/s, in_qsize 4, out_qsize 1\n",
      "2021-03-19 00:05:23,207 : INFO : EPOCH 3 - PROGRESS: at 54.38% examples, 396035 words/s, in_qsize 5, out_qsize 1\n",
      "2021-03-19 00:05:24,239 : INFO : EPOCH 3 - PROGRESS: at 58.08% examples, 399016 words/s, in_qsize 3, out_qsize 2\n",
      "2021-03-19 00:05:25,241 : INFO : EPOCH 3 - PROGRESS: at 63.49% examples, 413520 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:05:26,242 : INFO : EPOCH 3 - PROGRESS: at 72.02% examples, 445848 words/s, in_qsize 4, out_qsize 0\n",
      "2021-03-19 00:05:27,244 : INFO : EPOCH 3 - PROGRESS: at 80.54% examples, 474249 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:05:28,245 : INFO : EPOCH 3 - PROGRESS: at 88.89% examples, 499818 words/s, in_qsize 4, out_qsize 0\n",
      "2021-03-19 00:05:29,245 : INFO : EPOCH 3 - PROGRESS: at 97.59% examples, 524794 words/s, in_qsize 3, out_qsize 0\n",
      "2021-03-19 00:05:29,515 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-19 00:05:29,518 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-19 00:05:29,523 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-19 00:05:29,524 : INFO : EPOCH - 3 : training on 17005207 raw words (12506122 effective words) took 23.5s, 531335 effective words/s\n",
      "2021-03-19 00:05:30,530 : INFO : EPOCH 4 - PROGRESS: at 8.70% examples, 1075189 words/s, in_qsize 0, out_qsize 0\n",
      "2021-03-19 00:05:31,533 : INFO : EPOCH 4 - PROGRESS: at 17.40% examples, 1078741 words/s, in_qsize 0, out_qsize 0\n",
      "2021-03-19 00:05:32,537 : INFO : EPOCH 4 - PROGRESS: at 26.28% examples, 1089612 words/s, in_qsize 3, out_qsize 0\n",
      "2021-03-19 00:05:33,542 : INFO : EPOCH 4 - PROGRESS: at 35.21% examples, 1098715 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:05:34,544 : INFO : EPOCH 4 - PROGRESS: at 44.56% examples, 1113352 words/s, in_qsize 0, out_qsize 0\n",
      "2021-03-19 00:05:35,548 : INFO : EPOCH 4 - PROGRESS: at 53.26% examples, 1109290 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:05:36,554 : INFO : EPOCH 4 - PROGRESS: at 63.08% examples, 1125781 words/s, in_qsize 1, out_qsize 0\n",
      "2021-03-19 00:05:37,561 : INFO : EPOCH 4 - PROGRESS: at 71.90% examples, 1122456 words/s, in_qsize 0, out_qsize 0\n",
      "2021-03-19 00:05:38,565 : INFO : EPOCH 4 - PROGRESS: at 80.54% examples, 1115546 words/s, in_qsize 0, out_qsize 0\n",
      "2021-03-19 00:05:39,567 : INFO : EPOCH 4 - PROGRESS: at 88.42% examples, 1102238 words/s, in_qsize 3, out_qsize 0\n",
      "2021-03-19 00:05:40,571 : INFO : EPOCH 4 - PROGRESS: at 98.12% examples, 1111292 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:05:40,772 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-19 00:05:40,774 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-19 00:05:40,775 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-19 00:05:40,775 : INFO : EPOCH - 4 : training on 17005207 raw words (12508189 effective words) took 11.2s, 1111938 effective words/s\n",
      "2021-03-19 00:05:41,782 : INFO : EPOCH 5 - PROGRESS: at 9.35% examples, 1155120 words/s, in_qsize 3, out_qsize 0\n",
      "2021-03-19 00:05:42,789 : INFO : EPOCH 5 - PROGRESS: at 18.75% examples, 1160552 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:05:43,791 : INFO : EPOCH 5 - PROGRESS: at 28.34% examples, 1175179 words/s, in_qsize 0, out_qsize 0\n",
      "2021-03-19 00:05:44,793 : INFO : EPOCH 5 - PROGRESS: at 37.27% examples, 1163243 words/s, in_qsize 0, out_qsize 0\n",
      "2021-03-19 00:05:45,794 : INFO : EPOCH 5 - PROGRESS: at 45.21% examples, 1129594 words/s, in_qsize 0, out_qsize 0\n",
      "2021-03-19 00:05:46,801 : INFO : EPOCH 5 - PROGRESS: at 53.20% examples, 1107447 words/s, in_qsize 1, out_qsize 0\n",
      "2021-03-19 00:05:47,807 : INFO : EPOCH 5 - PROGRESS: at 61.49% examples, 1097238 words/s, in_qsize 2, out_qsize 0\n",
      "2021-03-19 00:05:48,815 : INFO : EPOCH 5 - PROGRESS: at 70.08% examples, 1093454 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-19 00:05:49,815 : INFO : EPOCH 5 - PROGRESS: at 79.25% examples, 1097818 words/s, in_qsize 0, out_qsize 0\n",
      "2021-03-19 00:05:50,816 : INFO : EPOCH 5 - PROGRESS: at 87.48% examples, 1090638 words/s, in_qsize 4, out_qsize 0\n",
      "2021-03-19 00:05:51,819 : INFO : EPOCH 5 - PROGRESS: at 95.88% examples, 1086690 words/s, in_qsize 4, out_qsize 0\n",
      "2021-03-19 00:05:52,340 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-19 00:05:52,346 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-19 00:05:52,348 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-19 00:05:52,349 : INFO : EPOCH - 5 : training on 17005207 raw words (12505848 effective words) took 11.6s, 1080824 effective words/s\n",
      "2021-03-19 00:05:52,350 : INFO : training on a 85026035 raw words (62533976 effective words) took 114.9s, 544022 effective words/s\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "model = Word2Vec(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our word2vec model, let's find words that are similar to 'tree'.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-19 00:06:02,681 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('leaf', 0.7059791088104248), ('trees', 0.6996309161186218), ('bark', 0.6464654803276062), ('flower', 0.6286193132400513), ('bird', 0.6203575730323792), ('fruit', 0.6173238754272461), ('avl', 0.6114338040351868), ('cactus', 0.5901271104812622), ('pond', 0.5722821950912476), ('leaves', 0.5659260153770447)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar('tree'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the API to download several different corpora and pretrained models.\n",
    "Here's how to list all resources available in gensim-data:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('glass', 0.004556643),\n",
       " ('hot', 0.0027073936),\n",
       " ('powder', 0.0025544222),\n",
       " ('soft', 0.002444317)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_output_word(['bottle'], topn=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bucket', 0.8313448429107666),\n",
       " ('bag', 0.810011088848114),\n",
       " ('lamp', 0.7992446422576904),\n",
       " ('pile', 0.7955589890480042),\n",
       " ('cake', 0.7852670550346375),\n",
       " ('bottles', 0.7827358245849609),\n",
       " ('jar', 0.7749974727630615),\n",
       " ('needle', 0.7721670269966125),\n",
       " ('toilet', 0.7720123529434204),\n",
       " ('glass', 0.7589759230613708)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('bottle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "info = api.info()\n",
    "print(json.dumps(info, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types of data resources: corpora and models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(info.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the available corpora:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for corpus_name, corpus_data in sorted(info['corpora'].items()):\n",
    "    print(\n",
    "        '%s (%d records): %s' % (\n",
    "            corpus_name,\n",
    "            corpus_data.get('num_records', -1),\n",
    "            corpus_data['description'][:40] + '...',\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and the same for models:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model_data in sorted(info['models'].items()):\n",
    "    print(\n",
    "        '%s (%d records): %s' % (\n",
    "            model_name,\n",
    "            model_data.get('num_records', -1),\n",
    "            model_data['description'][:40] + '...',\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to get detailed information about a model/corpus, use:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news_info = api.info('fake-news')\n",
    "print(json.dumps(fake_news_info, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, you do not want to load a model into memory. Instead, you can request\n",
    "just the filesystem path to the model. For that, use:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(api.load('glove-wiki-gigaword-50', return_path=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to load the model to memory, then:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = api.load(\"glove-wiki-gigaword-50\")\n",
    "model.most_similar(\"glass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For corpora, the corpus is never loaded to memory, all corpora are iterables wrapped in\n",
    "a special class ``Dataset``, with an ``__iter__`` method.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
