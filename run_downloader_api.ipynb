{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "How to download pre-trained models and corpora\n",
    "==============================================\n",
    "\n",
    "Demonstrates simple and quick access to common corpora and pretrained models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of Gensim's features is simple and easy access to common data.\n",
    "The `gensim-data <https://github.com/RaRe-Technologies/gensim-data>`_ project stores a\n",
    "variety of corpora and pretrained models.\n",
    "Gensim has a :py:mod:`gensim.downloader` module for programmatically accessing this data.\n",
    "This module leverages a local cache (in user's home folder, by default) that\n",
    "ensures data is downloaded at most once.\n",
    "\n",
    "This tutorial:\n",
    "\n",
    "* Downloads the text8 corpus, unless it is already on your local machine\n",
    "* Trains a Word2Vec model from the corpus (see `sphx_glr_auto_examples_tutorials_run_doc2vec_lee.py` for a detailed tutorial)\n",
    "* Leverages the model to calculate word similarity\n",
    "* Demonstrates using the API to load other models and corpora\n",
    "\n",
    "Let's start by importing the api module.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's download the text8 corpus and load it as a Python object\n",
    "that supports streamed access.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus = api.load('text8')\n",
    "corpus = api.load(\"text8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, our corpus is an iterable.\n",
    "If you look under the covers, it has the following definition:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class Dataset(object):\n",
      "    def __init__(self, fn):\n",
      "        self.fn = fn\n",
      "\n",
      "    def __iter__(self):\n",
      "        corpus = Text8Corpus(self.fn)\n",
      "        for doc in corpus:\n",
      "            yield doc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "print(inspect.getsource(corpus.__class__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more details, look inside the file that defines the Dataset class for your particular resource.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joshuamailman/gensim-data/text8/__init__.py\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getfile(corpus.__class__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the corpus has been downloaded and loaded, let's use it to train a word2vec model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-20 01:06:36,381 : INFO : collecting all words and their counts\n",
      "2021-03-20 01:06:36,384 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-03-20 01:06:40,194 : INFO : collected 253854 word types from a corpus of 17005207 raw words and 1701 sentences\n",
      "2021-03-20 01:06:40,194 : INFO : Loading a fresh vocabulary\n",
      "2021-03-20 01:06:40,405 : INFO : effective_min_count=5 retains 71290 unique words (28% of original 253854, drops 182564)\n",
      "2021-03-20 01:06:40,406 : INFO : effective_min_count=5 leaves 16718844 word corpus (98% of original 17005207, drops 286363)\n",
      "2021-03-20 01:06:40,544 : INFO : deleting the raw counts dictionary of 253854 items\n",
      "2021-03-20 01:06:40,550 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2021-03-20 01:06:40,550 : INFO : downsampling leaves estimated 12506280 word corpus (74.8% of prior 16718844)\n",
      "2021-03-20 01:06:40,726 : INFO : estimated required memory for 71290 words and 100 dimensions: 92677000 bytes\n",
      "2021-03-20 01:06:40,726 : INFO : resetting layer weights\n",
      "2021-03-20 01:06:50,353 : INFO : training model with 3 workers on 71290 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2021-03-20 01:06:51,362 : INFO : EPOCH 1 - PROGRESS: at 3.35% examples, 418092 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:06:52,364 : INFO : EPOCH 1 - PROGRESS: at 7.29% examples, 450390 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:06:53,365 : INFO : EPOCH 1 - PROGRESS: at 10.76% examples, 443700 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:06:54,366 : INFO : EPOCH 1 - PROGRESS: at 14.46% examples, 448214 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:06:55,368 : INFO : EPOCH 1 - PROGRESS: at 18.17% examples, 451166 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:06:56,370 : INFO : EPOCH 1 - PROGRESS: at 21.81% examples, 451815 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:06:57,417 : INFO : EPOCH 1 - PROGRESS: at 25.51% examples, 451038 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:06:58,448 : INFO : EPOCH 1 - PROGRESS: at 29.39% examples, 454160 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:06:59,452 : INFO : EPOCH 1 - PROGRESS: at 32.75% examples, 450829 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:00,491 : INFO : EPOCH 1 - PROGRESS: at 36.33% examples, 449392 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:01,493 : INFO : EPOCH 1 - PROGRESS: at 39.86% examples, 448537 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:02,513 : INFO : EPOCH 1 - PROGRESS: at 43.56% examples, 449080 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:03,517 : INFO : EPOCH 1 - PROGRESS: at 47.15% examples, 449147 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:04,527 : INFO : EPOCH 1 - PROGRESS: at 50.91% examples, 450538 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:05,528 : INFO : EPOCH 1 - PROGRESS: at 54.61% examples, 451498 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:06,530 : INFO : EPOCH 1 - PROGRESS: at 58.32% examples, 452174 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:07,546 : INFO : EPOCH 1 - PROGRESS: at 62.08% examples, 452915 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:08,550 : INFO : EPOCH 1 - PROGRESS: at 65.96% examples, 454610 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:09,579 : INFO : EPOCH 1 - PROGRESS: at 69.78% examples, 455233 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:10,581 : INFO : EPOCH 1 - PROGRESS: at 73.19% examples, 453949 words/s, in_qsize 5, out_qsize 1\n",
      "2021-03-20 01:07:11,585 : INFO : EPOCH 1 - PROGRESS: at 76.66% examples, 452281 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:12,613 : INFO : EPOCH 1 - PROGRESS: at 80.19% examples, 450970 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:13,646 : INFO : EPOCH 1 - PROGRESS: at 83.72% examples, 449906 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:14,667 : INFO : EPOCH 1 - PROGRESS: at 87.24% examples, 449102 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:15,684 : INFO : EPOCH 1 - PROGRESS: at 90.77% examples, 448557 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:16,697 : INFO : EPOCH 1 - PROGRESS: at 94.30% examples, 447877 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:17,705 : INFO : EPOCH 1 - PROGRESS: at 97.82% examples, 447364 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:18,279 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-20 01:07:18,301 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-20 01:07:18,326 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-20 01:07:18,326 : INFO : EPOCH - 1 : training on 17005207 raw words (12505533 effective words) took 28.0s, 447097 effective words/s\n",
      "2021-03-20 01:07:19,359 : INFO : EPOCH 2 - PROGRESS: at 3.41% examples, 414673 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:20,372 : INFO : EPOCH 2 - PROGRESS: at 7.00% examples, 424358 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:21,375 : INFO : EPOCH 2 - PROGRESS: at 10.52% examples, 428627 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:22,378 : INFO : EPOCH 2 - PROGRESS: at 13.93% examples, 427673 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:23,408 : INFO : EPOCH 2 - PROGRESS: at 17.46% examples, 427602 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:24,427 : INFO : EPOCH 2 - PROGRESS: at 20.99% examples, 428354 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:25,456 : INFO : EPOCH 2 - PROGRESS: at 24.51% examples, 429091 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:26,458 : INFO : EPOCH 2 - PROGRESS: at 27.98% examples, 430125 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:27,492 : INFO : EPOCH 2 - PROGRESS: at 31.39% examples, 428774 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:28,524 : INFO : EPOCH 2 - PROGRESS: at 34.74% examples, 427011 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:29,542 : INFO : EPOCH 2 - PROGRESS: at 38.10% examples, 425879 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:30,544 : INFO : EPOCH 2 - PROGRESS: at 41.50% examples, 425809 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:31,552 : INFO : EPOCH 2 - PROGRESS: at 44.97% examples, 426414 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:32,555 : INFO : EPOCH 2 - PROGRESS: at 48.38% examples, 426414 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:33,572 : INFO : EPOCH 2 - PROGRESS: at 51.91% examples, 426959 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:34,579 : INFO : EPOCH 2 - PROGRESS: at 55.32% examples, 426999 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:35,587 : INFO : EPOCH 2 - PROGRESS: at 58.73% examples, 426810 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:36,620 : INFO : EPOCH 2 - PROGRESS: at 62.26% examples, 426905 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:37,638 : INFO : EPOCH 2 - PROGRESS: at 65.67% examples, 426502 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:38,640 : INFO : EPOCH 2 - PROGRESS: at 68.96% examples, 425837 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:39,649 : INFO : EPOCH 2 - PROGRESS: at 72.31% examples, 425406 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:40,668 : INFO : EPOCH 2 - PROGRESS: at 75.84% examples, 425367 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:41,698 : INFO : EPOCH 2 - PROGRESS: at 79.42% examples, 425468 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:42,739 : INFO : EPOCH 2 - PROGRESS: at 82.95% examples, 425255 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:43,776 : INFO : EPOCH 2 - PROGRESS: at 86.48% examples, 425327 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:44,794 : INFO : EPOCH 2 - PROGRESS: at 90.01% examples, 425710 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:45,800 : INFO : EPOCH 2 - PROGRESS: at 93.53% examples, 425996 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:46,804 : INFO : EPOCH 2 - PROGRESS: at 97.06% examples, 426375 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:47,607 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-20 01:07:47,633 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-20 01:07:47,656 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-20 01:07:47,656 : INFO : EPOCH - 2 : training on 17005207 raw words (12505895 effective words) took 29.3s, 426415 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-20 01:07:48,693 : INFO : EPOCH 3 - PROGRESS: at 3.94% examples, 477027 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:49,716 : INFO : EPOCH 3 - PROGRESS: at 8.05% examples, 486145 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:50,717 : INFO : EPOCH 3 - PROGRESS: at 12.05% examples, 489325 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:51,719 : INFO : EPOCH 3 - PROGRESS: at 15.93% examples, 487789 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:52,725 : INFO : EPOCH 3 - PROGRESS: at 19.93% examples, 489500 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:53,737 : INFO : EPOCH 3 - PROGRESS: at 23.87% examples, 489974 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:54,760 : INFO : EPOCH 3 - PROGRESS: at 27.81% examples, 489252 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:55,762 : INFO : EPOCH 3 - PROGRESS: at 31.69% examples, 489417 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:56,764 : INFO : EPOCH 3 - PROGRESS: at 35.45% examples, 487904 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:57,775 : INFO : EPOCH 3 - PROGRESS: at 39.45% examples, 488714 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:58,776 : INFO : EPOCH 3 - PROGRESS: at 43.33% examples, 488505 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:07:59,781 : INFO : EPOCH 3 - PROGRESS: at 46.80% examples, 483998 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:00,804 : INFO : EPOCH 3 - PROGRESS: at 50.21% examples, 478914 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:01,845 : INFO : EPOCH 3 - PROGRESS: at 53.73% examples, 474935 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:02,873 : INFO : EPOCH 3 - PROGRESS: at 57.26% examples, 471980 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:03,874 : INFO : EPOCH 3 - PROGRESS: at 60.73% examples, 469731 words/s, in_qsize 4, out_qsize 0\n",
      "2021-03-20 01:08:04,882 : INFO : EPOCH 3 - PROGRESS: at 63.96% examples, 465737 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:05,893 : INFO : EPOCH 3 - PROGRESS: at 67.37% examples, 463283 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:06,919 : INFO : EPOCH 3 - PROGRESS: at 70.78% examples, 460865 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:07,921 : INFO : EPOCH 3 - PROGRESS: at 74.19% examples, 459279 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:08,928 : INFO : EPOCH 3 - PROGRESS: at 77.66% examples, 457111 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:09,969 : INFO : EPOCH 3 - PROGRESS: at 81.19% examples, 455446 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:10,983 : INFO : EPOCH 3 - PROGRESS: at 84.60% examples, 453885 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:11,986 : INFO : EPOCH 3 - PROGRESS: at 88.07% examples, 452986 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:12,989 : INFO : EPOCH 3 - PROGRESS: at 91.30% examples, 451036 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:13,993 : INFO : EPOCH 3 - PROGRESS: at 94.65% examples, 449623 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:15,011 : INFO : EPOCH 3 - PROGRESS: at 97.94% examples, 447861 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:15,593 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-20 01:08:15,604 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-20 01:08:15,627 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-20 01:08:15,628 : INFO : EPOCH - 3 : training on 17005207 raw words (12505992 effective words) took 28.0s, 447126 effective words/s\n",
      "2021-03-20 01:08:16,643 : INFO : EPOCH 4 - PROGRESS: at 3.23% examples, 400062 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:17,648 : INFO : EPOCH 4 - PROGRESS: at 6.41% examples, 393896 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:18,653 : INFO : EPOCH 4 - PROGRESS: at 9.58% examples, 393375 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:19,664 : INFO : EPOCH 4 - PROGRESS: at 12.29% examples, 378062 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:20,670 : INFO : EPOCH 4 - PROGRESS: at 15.46% examples, 381074 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:21,676 : INFO : EPOCH 4 - PROGRESS: at 18.81% examples, 387047 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:22,694 : INFO : EPOCH 4 - PROGRESS: at 22.16% examples, 390622 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:23,716 : INFO : EPOCH 4 - PROGRESS: at 25.34% examples, 390839 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:24,717 : INFO : EPOCH 4 - PROGRESS: at 28.57% examples, 392876 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:25,724 : INFO : EPOCH 4 - PROGRESS: at 31.92% examples, 395781 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:26,754 : INFO : EPOCH 4 - PROGRESS: at 35.16% examples, 395908 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:27,764 : INFO : EPOCH 4 - PROGRESS: at 38.51% examples, 397667 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:28,780 : INFO : EPOCH 4 - PROGRESS: at 41.92% examples, 399454 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:29,805 : INFO : EPOCH 4 - PROGRESS: at 45.27% examples, 400246 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:30,811 : INFO : EPOCH 4 - PROGRESS: at 48.56% examples, 401030 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:31,826 : INFO : EPOCH 4 - PROGRESS: at 51.91% examples, 401799 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:32,853 : INFO : EPOCH 4 - PROGRESS: at 55.26% examples, 402403 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:33,864 : INFO : EPOCH 4 - PROGRESS: at 58.61% examples, 403093 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:34,867 : INFO : EPOCH 4 - PROGRESS: at 62.08% examples, 404724 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:35,875 : INFO : EPOCH 4 - PROGRESS: at 65.37% examples, 404924 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:36,887 : INFO : EPOCH 4 - PROGRESS: at 68.61% examples, 404768 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:37,900 : INFO : EPOCH 4 - PROGRESS: at 71.96% examples, 405208 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:38,902 : INFO : EPOCH 4 - PROGRESS: at 75.19% examples, 405019 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:39,945 : INFO : EPOCH 4 - PROGRESS: at 78.72% examples, 405304 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:40,948 : INFO : EPOCH 4 - PROGRESS: at 81.89% examples, 404825 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:41,951 : INFO : EPOCH 4 - PROGRESS: at 85.24% examples, 405328 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:42,952 : INFO : EPOCH 4 - PROGRESS: at 88.48% examples, 405303 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:43,992 : INFO : EPOCH 4 - PROGRESS: at 91.83% examples, 405154 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:45,026 : INFO : EPOCH 4 - PROGRESS: at 95.36% examples, 405852 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:46,043 : INFO : EPOCH 4 - PROGRESS: at 98.53% examples, 405203 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:46,419 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-20 01:08:46,440 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-20 01:08:46,459 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-20 01:08:46,459 : INFO : EPOCH - 4 : training on 17005207 raw words (12506880 effective words) took 30.8s, 405679 effective words/s\n",
      "2021-03-20 01:08:47,475 : INFO : EPOCH 5 - PROGRESS: at 3.23% examples, 400340 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:48,484 : INFO : EPOCH 5 - PROGRESS: at 6.58% examples, 403810 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:49,498 : INFO : EPOCH 5 - PROGRESS: at 10.05% examples, 410758 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:50,501 : INFO : EPOCH 5 - PROGRESS: at 13.52% examples, 416017 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:51,501 : INFO : EPOCH 5 - PROGRESS: at 16.93% examples, 417724 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:52,512 : INFO : EPOCH 5 - PROGRESS: at 20.40% examples, 419513 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:53,554 : INFO : EPOCH 5 - PROGRESS: at 23.93% examples, 420954 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:54,558 : INFO : EPOCH 5 - PROGRESS: at 27.34% examples, 421600 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:55,577 : INFO : EPOCH 5 - PROGRESS: at 30.63% examples, 420289 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-20 01:08:56,583 : INFO : EPOCH 5 - PROGRESS: at 33.98% examples, 420438 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:57,604 : INFO : EPOCH 5 - PROGRESS: at 37.39% examples, 420485 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:58,619 : INFO : EPOCH 5 - PROGRESS: at 40.92% examples, 421691 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:08:59,634 : INFO : EPOCH 5 - PROGRESS: at 44.39% examples, 422268 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:00,678 : INFO : EPOCH 5 - PROGRESS: at 47.91% examples, 422514 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:01,709 : INFO : EPOCH 5 - PROGRESS: at 51.44% examples, 422973 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:02,712 : INFO : EPOCH 5 - PROGRESS: at 54.91% examples, 423742 words/s, in_qsize 4, out_qsize 0\n",
      "2021-03-20 01:09:03,729 : INFO : EPOCH 5 - PROGRESS: at 58.32% examples, 423550 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:04,729 : INFO : EPOCH 5 - PROGRESS: at 61.73% examples, 423796 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:05,758 : INFO : EPOCH 5 - PROGRESS: at 65.20% examples, 423667 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:06,760 : INFO : EPOCH 5 - PROGRESS: at 68.67% examples, 424195 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:07,789 : INFO : EPOCH 5 - PROGRESS: at 72.19% examples, 424503 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:08,791 : INFO : EPOCH 5 - PROGRESS: at 75.72% examples, 424851 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:09,802 : INFO : EPOCH 5 - PROGRESS: at 79.25% examples, 425007 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:10,826 : INFO : EPOCH 5 - PROGRESS: at 82.77% examples, 425142 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:11,849 : INFO : EPOCH 5 - PROGRESS: at 86.30% examples, 425425 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:12,868 : INFO : EPOCH 5 - PROGRESS: at 89.83% examples, 425784 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:13,900 : INFO : EPOCH 5 - PROGRESS: at 93.24% examples, 425183 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:14,908 : INFO : EPOCH 5 - PROGRESS: at 96.71% examples, 425285 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:15,822 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-20 01:09:15,843 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-20 01:09:15,865 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-20 01:09:15,866 : INFO : EPOCH - 5 : training on 17005207 raw words (12505247 effective words) took 29.4s, 425286 effective words/s\n",
      "2021-03-20 01:09:15,866 : INFO : training on a 85026035 raw words (62529547 effective words) took 145.5s, 429725 effective words/s\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "model_skp = Word2Vec(corpus, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-20 01:09:15,871 : INFO : collecting all words and their counts\n",
      "2021-03-20 01:09:15,873 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-03-20 01:09:20,092 : INFO : collected 253854 word types from a corpus of 17005207 raw words and 1701 sentences\n",
      "2021-03-20 01:09:20,092 : INFO : Loading a fresh vocabulary\n",
      "2021-03-20 01:09:20,301 : INFO : effective_min_count=5 retains 71290 unique words (28% of original 253854, drops 182564)\n",
      "2021-03-20 01:09:20,302 : INFO : effective_min_count=5 leaves 16718844 word corpus (98% of original 17005207, drops 286363)\n",
      "2021-03-20 01:09:20,444 : INFO : deleting the raw counts dictionary of 253854 items\n",
      "2021-03-20 01:09:20,450 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2021-03-20 01:09:20,451 : INFO : downsampling leaves estimated 12506280 word corpus (74.8% of prior 16718844)\n",
      "2021-03-20 01:09:20,648 : INFO : estimated required memory for 71290 words and 100 dimensions: 92677000 bytes\n",
      "2021-03-20 01:09:20,649 : INFO : resetting layer weights\n",
      "2021-03-20 01:09:30,333 : INFO : training model with 3 workers on 71290 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2021-03-20 01:09:31,336 : INFO : EPOCH 1 - PROGRESS: at 12.46% examples, 1547095 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:32,339 : INFO : EPOCH 1 - PROGRESS: at 25.22% examples, 1570101 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:33,344 : INFO : EPOCH 1 - PROGRESS: at 37.86% examples, 1577193 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:34,349 : INFO : EPOCH 1 - PROGRESS: at 50.50% examples, 1577665 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:35,351 : INFO : EPOCH 1 - PROGRESS: at 61.43% examples, 1536470 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:36,354 : INFO : EPOCH 1 - PROGRESS: at 72.49% examples, 1510837 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:37,356 : INFO : EPOCH 1 - PROGRESS: at 84.07% examples, 1499215 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:38,359 : INFO : EPOCH 1 - PROGRESS: at 95.47% examples, 1489099 words/s, in_qsize 4, out_qsize 1\n",
      "2021-03-20 01:09:38,725 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-20 01:09:38,727 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-20 01:09:38,728 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-20 01:09:38,729 : INFO : EPOCH - 1 : training on 17005207 raw words (12508328 effective words) took 8.4s, 1490271 effective words/s\n",
      "2021-03-20 01:09:39,736 : INFO : EPOCH 2 - PROGRESS: at 11.93% examples, 1473947 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:40,739 : INFO : EPOCH 2 - PROGRESS: at 24.63% examples, 1529448 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:41,743 : INFO : EPOCH 2 - PROGRESS: at 37.10% examples, 1543324 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:42,748 : INFO : EPOCH 2 - PROGRESS: at 49.56% examples, 1546842 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:43,751 : INFO : EPOCH 2 - PROGRESS: at 61.90% examples, 1546659 words/s, in_qsize 5, out_qsize 1\n",
      "2021-03-20 01:09:44,751 : INFO : EPOCH 2 - PROGRESS: at 74.37% examples, 1549585 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:45,756 : INFO : EPOCH 2 - PROGRESS: at 87.07% examples, 1550955 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:46,758 : INFO : EPOCH 2 - PROGRESS: at 99.65% examples, 1552801 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:46,775 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-20 01:09:46,777 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-20 01:09:46,780 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-20 01:09:46,780 : INFO : EPOCH - 2 : training on 17005207 raw words (12506772 effective words) took 8.0s, 1553692 effective words/s\n",
      "2021-03-20 01:09:47,787 : INFO : EPOCH 3 - PROGRESS: at 12.46% examples, 1540000 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:48,789 : INFO : EPOCH 3 - PROGRESS: at 24.99% examples, 1552011 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:49,792 : INFO : EPOCH 3 - PROGRESS: at 37.39% examples, 1556248 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:50,795 : INFO : EPOCH 3 - PROGRESS: at 49.85% examples, 1557441 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:51,799 : INFO : EPOCH 3 - PROGRESS: at 62.43% examples, 1560403 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:52,800 : INFO : EPOCH 3 - PROGRESS: at 75.07% examples, 1563857 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:53,802 : INFO : EPOCH 3 - PROGRESS: at 86.60% examples, 1543791 words/s, in_qsize 3, out_qsize 0\n",
      "2021-03-20 01:09:54,803 : INFO : EPOCH 3 - PROGRESS: at 97.18% examples, 1515499 words/s, in_qsize 4, out_qsize 0\n",
      "2021-03-20 01:09:55,016 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-20 01:09:55,018 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-20 01:09:55,021 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-20 01:09:55,021 : INFO : EPOCH - 3 : training on 17005207 raw words (12505788 effective words) took 8.2s, 1517799 effective words/s\n",
      "2021-03-20 01:09:56,023 : INFO : EPOCH 4 - PROGRESS: at 12.52% examples, 1555449 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:57,023 : INFO : EPOCH 4 - PROGRESS: at 25.10% examples, 1565681 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:58,026 : INFO : EPOCH 4 - PROGRESS: at 37.80% examples, 1577678 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:09:59,027 : INFO : EPOCH 4 - PROGRESS: at 50.50% examples, 1581473 words/s, in_qsize 6, out_qsize 0\n",
      "2021-03-20 01:10:00,031 : INFO : EPOCH 4 - PROGRESS: at 63.20% examples, 1582524 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:10:01,033 : INFO : EPOCH 4 - PROGRESS: at 75.96% examples, 1583365 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:10:02,035 : INFO : EPOCH 4 - PROGRESS: at 87.71% examples, 1565437 words/s, in_qsize 6, out_qsize 0\n",
      "2021-03-20 01:10:02,999 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-20 01:10:03,001 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-20 01:10:03,003 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-20 01:10:03,003 : INFO : EPOCH - 4 : training on 17005207 raw words (12505202 effective words) took 8.0s, 1567019 effective words/s\n",
      "2021-03-20 01:10:04,008 : INFO : EPOCH 5 - PROGRESS: at 12.29% examples, 1520848 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:10:05,010 : INFO : EPOCH 5 - PROGRESS: at 24.93% examples, 1550039 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:10:06,011 : INFO : EPOCH 5 - PROGRESS: at 37.51% examples, 1563234 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:10:07,012 : INFO : EPOCH 5 - PROGRESS: at 50.21% examples, 1570849 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:10:08,014 : INFO : EPOCH 5 - PROGRESS: at 62.90% examples, 1574884 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:10:09,014 : INFO : EPOCH 5 - PROGRESS: at 75.60% examples, 1576403 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:10:10,016 : INFO : EPOCH 5 - PROGRESS: at 88.36% examples, 1577101 words/s, in_qsize 5, out_qsize 0\n",
      "2021-03-20 01:10:10,918 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-20 01:10:10,921 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-20 01:10:10,924 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-20 01:10:10,924 : INFO : EPOCH - 5 : training on 17005207 raw words (12504458 effective words) took 7.9s, 1578971 effective words/s\n",
      "2021-03-20 01:10:10,924 : INFO : training on a 85026035 raw words (62530548 effective words) took 40.6s, 1540517 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model_bow = Word2Vec(corpus, sg=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our word2vec model, let's find words that are similar to 'tree'.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'rug'\n",
    "words = ['goose' ,'brant', 'honking', 'greylag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('thurs', 0.9178668260574341), ('dripped', 0.9154368042945862), ('nape', 0.9138864278793335), ('shuloch', 0.9128257036209106), ('buries', 0.9122443199157715), ('gagged', 0.9122151732444763), ('calmness', 0.9110994338989258), ('wrestles', 0.9105159044265747), ('latrine', 0.9051564335823059), ('defiled', 0.9051159620285034)]\n"
     ]
    }
   ],
   "source": [
    "print(model_skp.wv.most_similar(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('butts', 0.7981554269790649), ('crabbe', 0.7922760248184204), ('rhadamanthys', 0.7860302329063416), ('stomping', 0.7854064106941223), ('locust', 0.7842223644256592), ('barnacles', 0.7840744256973267), ('choking', 0.7827549576759338), ('aurelia', 0.7816535234451294), ('grizzled', 0.780861496925354), ('pinus', 0.780792236328125)]\n"
     ]
    }
   ],
   "source": [
    "print(model_bow.wv.most_similar(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model_skp.wv.most_similar(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model_bow.wv.most_similar(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the API to download several different corpora and pretrained models.\n",
    "Here's how to list all resources available in gensim-data:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('her', 0.00011968485),\n",
       " ('she', 9.788734e-05),\n",
       " ('called', 8.559184e-05),\n",
       " ('who', 8.2942905e-05)]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_skp.predict_output_word([word], topn=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('al', 2.2131764e-05),\n",
       " ('who', 2.1848786e-05),\n",
       " ('called', 2.1380702e-05),\n",
       " ('john', 2.0971931e-05)]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bow.predict_output_word([word], topn=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos='zebra'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-810-5b024f5276ad>:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  model_skp.most_similar([pos])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('quagga', 0.8735522031784058),\n",
       " ('rhinoceros', 0.863740086555481),\n",
       " ('przewalski', 0.851159930229187),\n",
       " ('equus', 0.8478255271911621),\n",
       " ('humpback', 0.8394851684570312),\n",
       " ('saimiri', 0.8394293785095215),\n",
       " ('grasshopper', 0.8376014232635498),\n",
       " ('hyena', 0.8344372510910034),\n",
       " ('danio', 0.8339352607727051),\n",
       " ('spectacled', 0.8324639201164246)]"
      ]
     },
     "execution_count": 810,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_skp.most_similar([pos])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-811-d37761cc67c5>:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  model_bow.most_similar([pos])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('equus', 0.8659811019897461),\n",
       " ('amaranth', 0.8481062650680542),\n",
       " ('toothed', 0.844868540763855),\n",
       " ('humpback', 0.8387032747268677),\n",
       " ('danio', 0.8349896669387817),\n",
       " ('beaked', 0.8306174874305725),\n",
       " ('catfish', 0.8293459415435791),\n",
       " ('ursus', 0.824088990688324),\n",
       " ('leopard', 0.8222962617874146),\n",
       " ('pigeon', 0.8187264204025269)]"
      ]
     },
     "execution_count": 811,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bow.most_similar([pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-812-43bd429ef04a>:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  model_skp.most_similar(positive=[pos, 'walks'], negative=['man'], topn=20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('bushes', 0.6928241848945618),\n",
       " ('palms', 0.6802634596824646),\n",
       " ('otters', 0.6726007461547852),\n",
       " ('antelope', 0.6682460904121399),\n",
       " ('shrubs', 0.6664403676986694),\n",
       " ('pelicans', 0.6552487015724182),\n",
       " ('gulls', 0.6551059484481812),\n",
       " ('grasshoppers', 0.6497182250022888),\n",
       " ('bumblebee', 0.6476486921310425),\n",
       " ('herons', 0.6462903618812561),\n",
       " ('moths', 0.6440606713294983),\n",
       " ('orchids', 0.643992006778717),\n",
       " ('kingfishers', 0.6433441638946533),\n",
       " ('odontoceti', 0.64076167345047),\n",
       " ('badgers', 0.6404194831848145),\n",
       " ('wasps', 0.6402060985565186),\n",
       " ('hyenas', 0.6384462714195251),\n",
       " ('lizards', 0.6375194787979126),\n",
       " ('deciduous', 0.636717677116394),\n",
       " ('daisies', 0.6310447454452515)]"
      ]
     },
     "execution_count": 812,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_skp.most_similar(positive=[pos, 'walks'], negative=['man'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-813-18f71246285b>:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  model_bow.most_similar(positive=[pos, 'walks'], negative=['man'], topn=5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('poplar', 0.7040863037109375),\n",
       " ('bedrock', 0.6735628843307495),\n",
       " ('toothed', 0.6691359281539917),\n",
       " ('hiking', 0.6683255434036255),\n",
       " ('lizards', 0.6669633388519287)]"
      ]
     },
     "execution_count": 813,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bow.most_similar(positive=[pos, 'walks'], negative=['man'], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-814-04217b8d44ba>:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  model_bow.most_similar(positive=[pos, 'fingers'], negative=['man'], topn=5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('odontoceti', 0.6995912790298462),\n",
       " ('cones', 0.6942052841186523),\n",
       " ('striped', 0.687303900718689),\n",
       " ('pea', 0.6815760135650635),\n",
       " ('grooves', 0.6767802238464355)]"
      ]
     },
     "execution_count": 814,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bow.most_similar(positive=[pos, 'fingers'], negative=['man'], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-815-fdf4e8b0ce64>:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  model_skp.most_similar(positive=[pos, 'says'], negative=['man'], topn=5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('subfamilia', 0.6191520094871521),\n",
       " ('bovidae', 0.6139534711837769),\n",
       " ('carassius', 0.6130903959274292),\n",
       " ('brachydanio', 0.6126963496208191),\n",
       " ('proteles', 0.6119928956031799)]"
      ]
     },
     "execution_count": 815,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_skp.most_similar(positive=[pos, 'says'], negative=['man'], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-816-9e68f51f8997>:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  model_bow.most_similar(positive=[pos, 'says'], negative=['man'], topn=5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('conjectured', 0.5926094055175781),\n",
       " ('dagestani', 0.5866895914077759),\n",
       " ('manatee', 0.5680640339851379),\n",
       " ('surmised', 0.5677024126052856),\n",
       " ('manatus', 0.5585182905197144)]"
      ]
     },
     "execution_count": 816,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bow.most_similar(positive=[pos, 'says'], negative=['man'], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-817-895717079158>:1: DeprecationWarning: Call to deprecated `n_similarity` (Method will be removed in 4.0.0, use self.wv.n_similarity() instead).\n",
      "  model_skp.n_similarity(['train'], ['epicycle','southbound'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5088859"
      ]
     },
     "execution_count": 817,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_skp.n_similarity(['train'], ['epicycle','southbound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_skp.predict_output_word(words, topn=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_bow.predict_output_word(words, topn=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.wv.most_similar(word, topn=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"corpora\": {\n",
      "        \"semeval-2016-2017-task3-subtaskBC\": {\n",
      "            \"num_records\": -1,\n",
      "            \"record_format\": \"dict\",\n",
      "            \"file_size\": 6344358,\n",
      "            \"reader_code\": \"https://github.com/RaRe-Technologies/gensim-data/releases/download/semeval-2016-2017-task3-subtaskB-eng/__init__.py\",\n",
      "            \"license\": \"All files released for the task are free for general research use\",\n",
      "            \"fields\": {\n",
      "                \"2016-train\": [\n",
      "                    \"...\"\n",
      "                ],\n",
      "                \"2016-dev\": [\n",
      "                    \"...\"\n",
      "                ],\n",
      "                \"2017-test\": [\n",
      "                    \"...\"\n",
      "                ],\n",
      "                \"2016-test\": [\n",
      "                    \"...\"\n",
      "                ]\n",
      "            },\n",
      "            \"description\": \"SemEval 2016 / 2017 Task 3 Subtask B and C datasets contain train+development (317 original questions, 3,169 related questions, and 31,690 comments), and test datasets in English. The description of the tasks and the collected data is given in sections 3 and 4.1 of the task paper http://alt.qcri.org/semeval2016/task3/data/uploads/semeval2016-task3-report.pdf linked in section \\u201cPapers\\u201d of https://github.com/RaRe-Technologies/gensim-data/issues/18.\",\n",
      "            \"checksum\": \"701ea67acd82e75f95e1d8e62fb0ad29\",\n",
      "            \"file_name\": \"semeval-2016-2017-task3-subtaskBC.gz\",\n",
      "            \"read_more\": [\n",
      "                \"http://alt.qcri.org/semeval2017/task3/\",\n",
      "                \"http://alt.qcri.org/semeval2017/task3/data/uploads/semeval2017-task3.pdf\",\n",
      "                \"https://github.com/RaRe-Technologies/gensim-data/issues/18\",\n",
      "                \"https://github.com/Witiko/semeval-2016_2017-task3-subtaskB-english\"\n",
      "            ],\n",
      "            \"parts\": 1\n",
      "        },\n",
      "        \"semeval-2016-2017-task3-subtaskA-unannotated\": {\n",
      "            \"num_records\": 189941,\n",
      "            \"record_format\": \"dict\",\n",
      "            \"file_size\": 234373151,\n",
      "            \"reader_code\": \"https://github.com/RaRe-Technologies/gensim-data/releases/download/semeval-2016-2017-task3-subtaskA-unannotated-eng/__init__.py\",\n",
      "            \"license\": \"These datasets are free for general research use.\",\n",
      "            \"fields\": {\n",
      "                \"THREAD_SEQUENCE\": \"\",\n",
      "                \"RelQuestion\": {\n",
      "                    \"RELQ_CATEGORY\": \"question category, according to the Qatar Living taxonomy\",\n",
      "                    \"RELQ_DATE\": \"date of posting\",\n",
      "                    \"RELQ_ID\": \"question indentifier\",\n",
      "                    \"RELQ_USERID\": \"identifier of the user asking the question\",\n",
      "                    \"RELQ_USERNAME\": \"name of the user asking the question\",\n",
      "                    \"RelQBody\": \"body of question\",\n",
      "                    \"RelQSubject\": \"subject of question\"\n",
      "                },\n",
      "                \"RelComments\": [\n",
      "                    {\n",
      "                        \"RelCText\": \"text of answer\",\n",
      "                        \"RELC_USERID\": \"identifier of the user posting the comment\",\n",
      "                        \"RELC_ID\": \"comment identifier\",\n",
      "                        \"RELC_USERNAME\": \"name of the user posting the comment\",\n",
      "                        \"RELC_DATE\": \"date of posting\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            \"description\": \"SemEval 2016 / 2017 Task 3 Subtask A unannotated dataset contains 189,941 questions and 1,894,456 comments in English collected from the Community Question Answering (CQA) web forum of Qatar Living. These can be used as a corpus for language modelling.\",\n",
      "            \"checksum\": \"2de0e2f2c4f91c66ae4fcf58d50ba816\",\n",
      "            \"file_name\": \"semeval-2016-2017-task3-subtaskA-unannotated.gz\",\n",
      "            \"read_more\": [\n",
      "                \"http://alt.qcri.org/semeval2016/task3/\",\n",
      "                \"http://alt.qcri.org/semeval2016/task3/data/uploads/semeval2016-task3-report.pdf\",\n",
      "                \"https://github.com/RaRe-Technologies/gensim-data/issues/18\",\n",
      "                \"https://github.com/Witiko/semeval-2016_2017-task3-subtaskA-unannotated-english\"\n",
      "            ],\n",
      "            \"parts\": 1\n",
      "        },\n",
      "        \"patent-2017\": {\n",
      "            \"num_records\": 353197,\n",
      "            \"record_format\": \"dict\",\n",
      "            \"file_size\": 3087262469,\n",
      "            \"reader_code\": \"https://github.com/RaRe-Technologies/gensim-data/releases/download/patent-2017/__init__.py\",\n",
      "            \"license\": \"not found\",\n",
      "            \"description\": \"Patent Grant Full Text. Contains the full text including tables, sequence data and 'in-line' mathematical expressions of each patent grant issued in 2017.\",\n",
      "            \"checksum-0\": \"818501f0b9af62d3b88294d86d509f8f\",\n",
      "            \"checksum-1\": \"66c05635c1d3c7a19b4a335829d09ffa\",\n",
      "            \"file_name\": \"patent-2017.gz\",\n",
      "            \"read_more\": [\n",
      "                \"http://patents.reedtech.com/pgrbft.php\"\n",
      "            ],\n",
      "            \"parts\": 2\n",
      "        },\n",
      "        \"quora-duplicate-questions\": {\n",
      "            \"num_records\": 404290,\n",
      "            \"record_format\": \"dict\",\n",
      "            \"file_size\": 21684784,\n",
      "            \"reader_code\": \"https://github.com/RaRe-Technologies/gensim-data/releases/download/quora-duplicate-questions/__init__.py\",\n",
      "            \"license\": \"probably https://www.quora.com/about/tos\",\n",
      "            \"fields\": {\n",
      "                \"question1\": \"the full text of each question\",\n",
      "                \"question2\": \"the full text of each question\",\n",
      "                \"qid1\": \"unique ids of each question\",\n",
      "                \"qid2\": \"unique ids of each question\",\n",
      "                \"id\": \"the id of a training set question pair\",\n",
      "                \"is_duplicate\": \"the target variable, set to 1 if question1 and question2 have essentially the same meaning, and 0 otherwise\"\n",
      "            },\n",
      "            \"description\": \"Over 400,000 lines of potential question duplicate pairs. Each line contains IDs for each question in the pair, the full text for each question, and a binary value that indicates whether the line contains a duplicate pair or not.\",\n",
      "            \"checksum\": \"d7cfa7fbc6e2ec71ab74c495586c6365\",\n",
      "            \"file_name\": \"quora-duplicate-questions.gz\",\n",
      "            \"read_more\": [\n",
      "                \"https://data.quora.com/First-Quora-Dataset-Release-Question-Pairs\"\n",
      "            ],\n",
      "            \"parts\": 1\n",
      "        },\n",
      "        \"wiki-english-20171001\": {\n",
      "            \"num_records\": 4924894,\n",
      "            \"record_format\": \"dict\",\n",
      "            \"file_size\": 6516051717,\n",
      "            \"reader_code\": \"https://github.com/RaRe-Technologies/gensim-data/releases/download/wiki-english-20171001/__init__.py\",\n",
      "            \"license\": \"https://dumps.wikimedia.org/legal.html\",\n",
      "            \"fields\": {\n",
      "                \"section_texts\": \"list of body of sections\",\n",
      "                \"section_titles\": \"list of titles of sections\",\n",
      "                \"title\": \"Title of wiki article\"\n",
      "            },\n",
      "            \"description\": \"Extracted Wikipedia dump from October 2017. Produced by `python -m gensim.scripts.segment_wiki -f enwiki-20171001-pages-articles.xml.bz2 -o wiki-en.gz`\",\n",
      "            \"checksum-0\": \"a7d7d7fd41ea7e2d7fa32ec1bb640d71\",\n",
      "            \"checksum-1\": \"b2683e3356ffbca3b6c2dca6e9801f9f\",\n",
      "            \"checksum-2\": \"c5cde2a9ae77b3c4ebce804f6df542c2\",\n",
      "            \"checksum-3\": \"00b71144ed5e3aeeb885de84f7452b81\",\n",
      "            \"file_name\": \"wiki-english-20171001.gz\",\n",
      "            \"read_more\": [\n",
      "                \"https://dumps.wikimedia.org/enwiki/20171001/\"\n",
      "            ],\n",
      "            \"parts\": 4\n",
      "        },\n",
      "        \"text8\": {\n",
      "            \"num_records\": 1701,\n",
      "            \"record_format\": \"list of str (tokens)\",\n",
      "            \"file_size\": 33182058,\n",
      "            \"reader_code\": \"https://github.com/RaRe-Technologies/gensim-data/releases/download/text8/__init__.py\",\n",
      "            \"license\": \"not found\",\n",
      "            \"description\": \"First 100,000,000 bytes of plain text from Wikipedia. Used for testing purposes; see wiki-english-* for proper full Wikipedia datasets.\",\n",
      "            \"checksum\": \"68799af40b6bda07dfa47a32612e5364\",\n",
      "            \"file_name\": \"text8.gz\",\n",
      "            \"read_more\": [\n",
      "                \"http://mattmahoney.net/dc/textdata.html\"\n",
      "            ],\n",
      "            \"parts\": 1\n",
      "        },\n",
      "        \"fake-news\": {\n",
      "            \"num_records\": 12999,\n",
      "            \"record_format\": \"dict\",\n",
      "            \"file_size\": 20102776,\n",
      "            \"reader_code\": \"https://github.com/RaRe-Technologies/gensim-data/releases/download/fake-news/__init__.py\",\n",
      "            \"license\": \"https://creativecommons.org/publicdomain/zero/1.0/\",\n",
      "            \"fields\": {\n",
      "                \"crawled\": \"date the story was archived\",\n",
      "                \"ord_in_thread\": \"\",\n",
      "                \"published\": \"date published\",\n",
      "                \"participants_count\": \"number of participants\",\n",
      "                \"shares\": \"number of Facebook shares\",\n",
      "                \"replies_count\": \"number of replies\",\n",
      "                \"main_img_url\": \"image from story\",\n",
      "                \"spam_score\": \"data from webhose.io\",\n",
      "                \"uuid\": \"unique identifier\",\n",
      "                \"language\": \"data from webhose.io\",\n",
      "                \"title\": \"title of story\",\n",
      "                \"country\": \"data from webhose.io\",\n",
      "                \"domain_rank\": \"data from webhose.io\",\n",
      "                \"author\": \"author of story\",\n",
      "                \"comments\": \"number of Facebook comments\",\n",
      "                \"site_url\": \"site URL from BS detector\",\n",
      "                \"text\": \"text of story\",\n",
      "                \"thread_title\": \"\",\n",
      "                \"type\": \"type of website (label from BS detector)\",\n",
      "                \"likes\": \"number of Facebook likes\"\n",
      "            },\n",
      "            \"description\": \"News dataset, contains text and metadata from 244 websites and represents 12,999 posts in total from a specific window of 30 days. The data was pulled using the webhose.io API, and because it's coming from their crawler, not all websites identified by their BS Detector are present in this dataset. Data sources that were missing a label were simply assigned a label of 'bs'. There are (ostensibly) no genuine, reliable, or trustworthy news sources represented in this dataset (so far), so don't trust anything you read.\",\n",
      "            \"checksum\": \"5e64e942df13219465927f92dcefd5fe\",\n",
      "            \"file_name\": \"fake-news.gz\",\n",
      "            \"read_more\": [\n",
      "                \"https://www.kaggle.com/mrisdal/fake-news\"\n",
      "            ],\n",
      "            \"parts\": 1\n",
      "        },\n",
      "        \"20-newsgroups\": {\n",
      "            \"num_records\": 18846,\n",
      "            \"record_format\": \"dict\",\n",
      "            \"file_size\": 14483581,\n",
      "            \"reader_code\": \"https://github.com/RaRe-Technologies/gensim-data/releases/download/20-newsgroups/__init__.py\",\n",
      "            \"license\": \"not found\",\n",
      "            \"fields\": {\n",
      "                \"topic\": \"name of topic (20 variant of possible values)\",\n",
      "                \"set\": \"marker of original split (possible values 'train' and 'test')\",\n",
      "                \"data\": \"\",\n",
      "                \"id\": \"original id inferred from folder name\"\n",
      "            },\n",
      "            \"description\": \"The notorious collection of approximately 20,000 newsgroup posts, partitioned (nearly) evenly across 20 different newsgroups.\",\n",
      "            \"checksum\": \"c92fd4f6640a86d5ba89eaad818a9891\",\n",
      "            \"file_name\": \"20-newsgroups.gz\",\n",
      "            \"read_more\": [\n",
      "                \"http://qwone.com/~jason/20Newsgroups/\"\n",
      "            ],\n",
      "            \"parts\": 1\n",
      "        },\n",
      "        \"__testing_matrix-synopsis\": {\n",
      "            \"description\": \"[THIS IS ONLY FOR TESTING] Synopsis of the movie matrix.\",\n",
      "            \"checksum\": \"1767ac93a089b43899d54944b07d9dc5\",\n",
      "            \"file_name\": \"__testing_matrix-synopsis.gz\",\n",
      "            \"read_more\": [\n",
      "                \"http://www.imdb.com/title/tt0133093/plotsummary?ref_=ttpl_pl_syn#synopsis\"\n",
      "            ],\n",
      "            \"parts\": 1\n",
      "        },\n",
      "        \"__testing_multipart-matrix-synopsis\": {\n",
      "            \"description\": \"[THIS IS ONLY FOR TESTING] Synopsis of the movie matrix.\",\n",
      "            \"checksum-0\": \"c8b0c7d8cf562b1b632c262a173ac338\",\n",
      "            \"checksum-1\": \"5ff7fc6818e9a5d9bc1cf12c35ed8b96\",\n",
      "            \"checksum-2\": \"966db9d274d125beaac7987202076cba\",\n",
      "            \"file_name\": \"__testing_multipart-matrix-synopsis.gz\",\n",
      "            \"read_more\": [\n",
      "                \"http://www.imdb.com/title/tt0133093/plotsummary?ref_=ttpl_pl_syn#synopsis\"\n",
      "            ],\n",
      "            \"parts\": 3\n",
      "        }\n",
      "    },\n",
      "    \"models\": {\n",
      "        \"fasttext-wiki-news-subwords-300\": {\n",
      "            \"num_records\": 999999,\n",
      "            \"file_size\": 1005007116,\n",
      "            \"base_dataset\": \"Wikipedia 2017, UMBC webbase corpus and statmt.org news dataset (16B tokens)\",\n",
      "            \"reader_code\": \"https://github.com/RaRe-Technologies/gensim-data/releases/download/fasttext-wiki-news-subwords-300/__init__.py\",\n",
      "            \"license\": \"https://creativecommons.org/licenses/by-sa/3.0/\",\n",
      "            \"parameters\": {\n",
      "                \"dimension\": 300\n",
      "            },\n",
      "            \"description\": \"1 million word vectors trained on Wikipedia 2017, UMBC webbase corpus and statmt.org news dataset (16B tokens).\",\n",
      "            \"read_more\": [\n",
      "                \"https://fasttext.cc/docs/en/english-vectors.html\",\n",
      "                \"https://arxiv.org/abs/1712.09405\",\n",
      "                \"https://arxiv.org/abs/1607.01759\"\n",
      "            ],\n",
      "            \"checksum\": \"de2bb3a20c46ce65c9c131e1ad9a77af\",\n",
      "            \"file_name\": \"fasttext-wiki-news-subwords-300.gz\",\n",
      "            \"parts\": 1\n",
      "        },\n",
      "        \"conceptnet-numberbatch-17-06-300\": {\n",
      "            \"num_records\": 1917247,\n",
      "            \"file_size\": 1225497562,\n",
      "            \"base_dataset\": \"ConceptNet, word2vec, GloVe, and OpenSubtitles 2016\",\n",
      "            \"reader_code\": \"https://github.com/RaRe-Technologies/gensim-data/releases/download/conceptnet-numberbatch-17-06-300/__init__.py\",\n",
      "            \"license\": \"https://github.com/commonsense/conceptnet-numberbatch/blob/master/LICENSE.txt\",\n",
      "            \"parameters\": {\n",
      "                \"dimension\": 300\n",
      "            },\n",
      "            \"description\": \"ConceptNet Numberbatch consists of state-of-the-art semantic vectors (also known as word embeddings) that can be used directly as a representation of word meanings or as a starting point for further machine learning. ConceptNet Numberbatch is part of the ConceptNet open data project. ConceptNet provides lots of ways to compute with word meanings, one of which is word embeddings. ConceptNet Numberbatch is a snapshot of just the word embeddings. It is built using an ensemble that combines data from ConceptNet, word2vec, GloVe, and OpenSubtitles 2016, using a variation on retrofitting.\",\n",
      "            \"read_more\": [\n",
      "                \"http://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14972\",\n",
      "                \"https://github.com/commonsense/conceptnet-numberbatch\",\n",
      "                \"http://conceptnet.io/\"\n",
      "            ],\n",
      "            \"checksum\": \"fd642d457adcd0ea94da0cd21b150847\",\n",
      "            \"file_name\": \"conceptnet-numberbatch-17-06-300.gz\",\n",
      "            \"parts\": 1\n",
      "        },\n",
      "        \"word2vec-ruscorpora-300\": {\n",
      "            \"num_records\": 184973,\n",
      "            \"file_size\": 208427381,\n",
      "            \"base_dataset\": \"Russian National Corpus (about 250M words)\",\n",
      "            \"reader_code\": \"https://github.com/RaRe-Technologies/gensim-data/releases/download/word2vec-ruscorpora-300/__init__.py\",\n",
      "            \"license\": \"https://creativecommons.org/licenses/by/4.0/deed.en\",\n",
      "            \"parameters\": {\n",
      "                \"dimension\": 300,\n",
      "                \"window_size\": 10\n",
      "            },\n",
      "            \"description\": \"Word2vec Continuous Skipgram vectors trained on full Russian National Corpus (about 250M words). The model contains 185K words.\",\n",
      "            \"preprocessing\": \"The corpus was lemmatized and tagged with Universal PoS\",\n",
      "            \"read_more\": [\n",
      "                \"https://www.academia.edu/24306935/WebVectors_a_Toolkit_for_Building_Web_Interfaces_for_Vector_Semantic_Models\",\n",
      "                \"http://rusvectores.org/en/\",\n",
      "                \"https://github.com/RaRe-Technologies/gensim-data/issues/3\"\n",
      "            ],\n",
      "            \"checksum\": \"9bdebdc8ae6d17d20839dd9b5af10bc4\",\n",
      "            \"file_name\": \"word2vec-ruscorpora-300.gz\",\n",
      "            \"parts\": 1\n",
      "        },\n",
      "        \"word2vec-google-news-300\": {\n",
      "            \"num_records\": 3000000,\n",
      "            \"file_size\": 1743563840,\n",
      "            \"base_dataset\": \"Google News (about 100 billion words)\",\n",
      "            \"reader_code\": \"https://github.com/RaRe-Technologies/gensim-data/releases/download/word2vec-google-news-300/__init__.py\",\n",
      "            \"license\": \"not found\",\n",
      "            \"parameters\": {\n",
      "                \"dimension\": 300\n",
      "            },\n",
      "            \"description\": \"Pre-trained vectors trained on a part of the Google News dataset (about 100 billion words). The model contains 300-dimensional vectors for 3 million words and phrases. The phrases were obtained using a simple data-driven approach described in 'Distributed Representations of Words and Phrases and their Compositionality' (https://code.google.com/archive/p/word2vec/).\",\n",
      "            \"read_more\": [\n",
      "                \"https://code.google.com/archive/p/word2vec/\",\n",
      "                \"https://arxiv.org/abs/1301.3781\",\n",
      "                \"https://arxiv.org/abs/1310.4546\",\n",
      "                \"https://www.microsoft.com/en-us/research/publication/linguistic-regularities-in-continuous-space-word-representations/?from=http%3A%2F%2Fresearch.microsoft.com%2Fpubs%2F189726%2Frvecs.pdf\"\n",
      "            ],\n",
      "            \"checksum\": \"a5e5354d40acb95f9ec66d5977d140ef\",\n",
      "            \"file_name\": \"word2vec-google-news-300.gz\",\n",
      "            \"parts\": 1\n",
      "        },\n",
      "        \"glove-wiki-gigaword-50\": {\n",
      "            \"num_records\": 400000,\n",
      "            \"file_size\": 69182535,\n",
      "            \"base_dataset\": \"Wikipedia 2014 + Gigaword 5 (6B tokens, uncased)\",\n",
      "            \"reader_code\": \"https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-wiki-gigaword-50/__init__.py\",\n",
      "            \"license\": \"http://opendatacommons.org/licenses/pddl/\",\n",
      "            \"parameters\": {\n",
      "                \"dimension\": 50\n",
      "            },\n",
      "            \"description\": \"Pre-trained vectors based on Wikipedia 2014 + Gigaword, 5.6B tokens, 400K vocab, uncased (https://nlp.stanford.edu/projects/glove/).\",\n",
      "            \"preprocessing\": \"Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-wiki-gigaword-50.txt`.\",\n",
      "            \"read_more\": [\n",
      "                \"https://nlp.stanford.edu/projects/glove/\",\n",
      "                \"https://nlp.stanford.edu/pubs/glove.pdf\"\n",
      "            ],\n",
      "            \"checksum\": \"c289bc5d7f2f02c6dc9f2f9b67641813\",\n",
      "            \"file_name\": \"glove-wiki-gigaword-50.gz\",\n",
      "            \"parts\": 1\n",
      "        },\n",
      "        \"glove-wiki-gigaword-100\": {\n",
      "            \"num_records\": 400000,\n",
      "            \"file_size\": 134300434,\n",
      "            \"base_dataset\": \"Wikipedia 2014 + Gigaword 5 (6B tokens, uncased)\",\n",
      "            \"reader_code\": \"https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-wiki-gigaword-100/__init__.py\",\n",
      "            \"license\": \"http://opendatacommons.org/licenses/pddl/\",\n",
      "            \"parameters\": {\n",
      "                \"dimension\": 100\n",
      "            },\n",
      "            \"description\": \"Pre-trained vectors based on Wikipedia 2014 + Gigaword 5.6B tokens, 400K vocab, uncased (https://nlp.stanford.edu/projects/glove/).\",\n",
      "            \"preprocessing\": \"Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-wiki-gigaword-100.txt`.\",\n",
      "            \"read_more\": [\n",
      "                \"https://nlp.stanford.edu/projects/glove/\",\n",
      "                \"https://nlp.stanford.edu/pubs/glove.pdf\"\n",
      "            ],\n",
      "            \"checksum\": \"40ec481866001177b8cd4cb0df92924f\",\n",
      "            \"file_name\": \"glove-wiki-gigaword-100.gz\",\n",
      "            \"parts\": 1\n",
      "        },\n",
      "        \"glove-wiki-gigaword-200\": {\n",
      "            \"num_records\": 400000,\n",
      "            \"file_size\": 264336934,\n",
      "            \"base_dataset\": \"Wikipedia 2014 + Gigaword 5 (6B tokens, uncased)\",\n",
      "            \"reader_code\": \"https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-wiki-gigaword-200/__init__.py\",\n",
      "            \"license\": \"http://opendatacommons.org/licenses/pddl/\",\n",
      "            \"parameters\": {\n",
      "                \"dimension\": 200\n",
      "            },\n",
      "            \"description\": \"Pre-trained vectors based on Wikipedia 2014 + Gigaword, 5.6B tokens, 400K vocab, uncased (https://nlp.stanford.edu/projects/glove/).\",\n",
      "            \"preprocessing\": \"Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-wiki-gigaword-200.txt`.\",\n",
      "            \"read_more\": [\n",
      "                \"https://nlp.stanford.edu/projects/glove/\",\n",
      "                \"https://nlp.stanford.edu/pubs/glove.pdf\"\n",
      "            ],\n",
      "            \"checksum\": \"59652db361b7a87ee73834a6c391dfc1\",\n",
      "            \"file_name\": \"glove-wiki-gigaword-200.gz\",\n",
      "            \"parts\": 1\n",
      "        },\n",
      "        \"glove-wiki-gigaword-300\": {\n",
      "            \"num_records\": 400000,\n",
      "            \"file_size\": 394362229,\n",
      "            \"base_dataset\": \"Wikipedia 2014 + Gigaword 5 (6B tokens, uncased)\",\n",
      "            \"reader_code\": \"https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-wiki-gigaword-300/__init__.py\",\n",
      "            \"license\": \"http://opendatacommons.org/licenses/pddl/\",\n",
      "            \"parameters\": {\n",
      "                \"dimension\": 300\n",
      "            },\n",
      "            \"description\": \"Pre-trained vectors based on Wikipedia 2014 + Gigaword, 5.6B tokens, 400K vocab, uncased (https://nlp.stanford.edu/projects/glove/).\",\n",
      "            \"preprocessing\": \"Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-wiki-gigaword-300.txt`.\",\n",
      "            \"read_more\": [\n",
      "                \"https://nlp.stanford.edu/projects/glove/\",\n",
      "                \"https://nlp.stanford.edu/pubs/glove.pdf\"\n",
      "            ],\n",
      "            \"checksum\": \"29e9329ac2241937d55b852e8284e89b\",\n",
      "            \"file_name\": \"glove-wiki-gigaword-300.gz\",\n",
      "            \"parts\": 1\n",
      "        },\n",
      "        \"glove-twitter-25\": {\n",
      "            \"num_records\": 1193514,\n",
      "            \"file_size\": 109885004,\n",
      "            \"base_dataset\": \"Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased)\",\n",
      "            \"reader_code\": \"https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-twitter-25/__init__.py\",\n",
      "            \"license\": \"http://opendatacommons.org/licenses/pddl/\",\n",
      "            \"parameters\": {\n",
      "                \"dimension\": 25\n",
      "            },\n",
      "            \"description\": \"Pre-trained vectors based on 2B tweets, 27B tokens, 1.2M vocab, uncased (https://nlp.stanford.edu/projects/glove/).\",\n",
      "            \"preprocessing\": \"Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-twitter-25.txt`.\",\n",
      "            \"read_more\": [\n",
      "                \"https://nlp.stanford.edu/projects/glove/\",\n",
      "                \"https://nlp.stanford.edu/pubs/glove.pdf\"\n",
      "            ],\n",
      "            \"checksum\": \"50db0211d7e7a2dcd362c6b774762793\",\n",
      "            \"file_name\": \"glove-twitter-25.gz\",\n",
      "            \"parts\": 1\n",
      "        },\n",
      "        \"glove-twitter-50\": {\n",
      "            \"num_records\": 1193514,\n",
      "            \"file_size\": 209216938,\n",
      "            \"base_dataset\": \"Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased)\",\n",
      "            \"reader_code\": \"https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-twitter-50/__init__.py\",\n",
      "            \"license\": \"http://opendatacommons.org/licenses/pddl/\",\n",
      "            \"parameters\": {\n",
      "                \"dimension\": 50\n",
      "            },\n",
      "            \"description\": \"Pre-trained vectors based on 2B tweets, 27B tokens, 1.2M vocab, uncased (https://nlp.stanford.edu/projects/glove/)\",\n",
      "            \"preprocessing\": \"Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-twitter-50.txt`.\",\n",
      "            \"read_more\": [\n",
      "                \"https://nlp.stanford.edu/projects/glove/\",\n",
      "                \"https://nlp.stanford.edu/pubs/glove.pdf\"\n",
      "            ],\n",
      "            \"checksum\": \"c168f18641f8c8a00fe30984c4799b2b\",\n",
      "            \"file_name\": \"glove-twitter-50.gz\",\n",
      "            \"parts\": 1\n",
      "        },\n",
      "        \"glove-twitter-100\": {\n",
      "            \"num_records\": 1193514,\n",
      "            \"file_size\": 405932991,\n",
      "            \"base_dataset\": \"Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased)\",\n",
      "            \"reader_code\": \"https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-twitter-100/__init__.py\",\n",
      "            \"license\": \"http://opendatacommons.org/licenses/pddl/\",\n",
      "            \"parameters\": {\n",
      "                \"dimension\": 100\n",
      "            },\n",
      "            \"description\": \"Pre-trained vectors based on  2B tweets, 27B tokens, 1.2M vocab, uncased (https://nlp.stanford.edu/projects/glove/)\",\n",
      "            \"preprocessing\": \"Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-twitter-100.txt`.\",\n",
      "            \"read_more\": [\n",
      "                \"https://nlp.stanford.edu/projects/glove/\",\n",
      "                \"https://nlp.stanford.edu/pubs/glove.pdf\"\n",
      "            ],\n",
      "            \"checksum\": \"b04f7bed38756d64cf55b58ce7e97b15\",\n",
      "            \"file_name\": \"glove-twitter-100.gz\",\n",
      "            \"parts\": 1\n",
      "        },\n",
      "        \"glove-twitter-200\": {\n",
      "            \"num_records\": 1193514,\n",
      "            \"file_size\": 795373100,\n",
      "            \"base_dataset\": \"Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased)\",\n",
      "            \"reader_code\": \"https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-twitter-200/__init__.py\",\n",
      "            \"license\": \"http://opendatacommons.org/licenses/pddl/\",\n",
      "            \"parameters\": {\n",
      "                \"dimension\": 200\n",
      "            },\n",
      "            \"description\": \"Pre-trained vectors based on 2B tweets, 27B tokens, 1.2M vocab, uncased (https://nlp.stanford.edu/projects/glove/).\",\n",
      "            \"preprocessing\": \"Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-twitter-200.txt`.\",\n",
      "            \"read_more\": [\n",
      "                \"https://nlp.stanford.edu/projects/glove/\",\n",
      "                \"https://nlp.stanford.edu/pubs/glove.pdf\"\n",
      "            ],\n",
      "            \"checksum\": \"e52e8392d1860b95d5308a525817d8f9\",\n",
      "            \"file_name\": \"glove-twitter-200.gz\",\n",
      "            \"parts\": 1\n",
      "        },\n",
      "        \"__testing_word2vec-matrix-synopsis\": {\n",
      "            \"description\": \"[THIS IS ONLY FOR TESTING] Word vecrors of the movie matrix.\",\n",
      "            \"parameters\": {\n",
      "                \"dimensions\": 50\n",
      "            },\n",
      "            \"preprocessing\": \"Converted to w2v using a preprocessed corpus. Converted to w2v format with `python3.5 -m gensim.models.word2vec -train <input_filename> -iter 50 -output <output_filename>`.\",\n",
      "            \"read_more\": [],\n",
      "            \"checksum\": \"534dcb8b56a360977a269b7bfc62d124\",\n",
      "            \"file_name\": \"__testing_word2vec-matrix-synopsis.gz\",\n",
      "            \"parts\": 1\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "info = api.info()\n",
    "print(json.dumps(info, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types of data resources: corpora and models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(info.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the available corpora:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for corpus_name, corpus_data in sorted(info['corpora'].items()):\n",
    "    print(\n",
    "        '%s (%d records): %s' % (\n",
    "            corpus_name,\n",
    "            corpus_data.get('num_records', -1),\n",
    "            corpus_data['description'][:40] + '...',\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and the same for models:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model_data in sorted(info['models'].items()):\n",
    "    print(\n",
    "        '%s (%d records): %s' % (\n",
    "            model_name,\n",
    "            model_data.get('num_records', -1),\n",
    "            model_data['description'][:40] + '...',\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to get detailed information about a model/corpus, use:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news_info = api.info('fake-news')\n",
    "print(json.dumps(fake_news_info, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, you do not want to load a model into memory. Instead, you can request\n",
    "just the filesystem path to the model. For that, use:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(api.load('glove-wiki-gigaword-50', return_path=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to load the model to memory, then:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-20 01:29:26,405 : INFO : loading projection weights from /Users/joshuamailman/gensim-data/glove-wiki-gigaword-50/glove-wiki-gigaword-50.gz\n",
      "2021-03-20 01:29:36,071 : INFO : loaded (400000, 50) matrix from /Users/joshuamailman/gensim-data/glove-wiki-gigaword-50/glove-wiki-gigaword-50.gz\n",
      "2021-03-20 01:29:36,111 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('cobra', 0.708692729473114),\n",
       " ('gts', 0.7059628963470459),\n",
       " ('gaboon', 0.6975671052932739),\n",
       " ('gts-r', 0.67454993724823),\n",
       " ('longhorn', 0.6680278778076172),\n",
       " ('panther', 0.666718065738678),\n",
       " ('cc', 0.6618682742118835),\n",
       " ('ah-1z', 0.6288684606552124),\n",
       " ('scorpions', 0.6254101991653442),\n",
       " ('mustang', 0.6176854968070984)]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = api.load(\"glove-wiki-gigaword-50\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pretzels', 0.6768024563789368),\n",
       " ('waffle', 0.668554425239563),\n",
       " ('itarsi', 0.6505174040794373),\n",
       " ('popsicle', 0.6484500765800476),\n",
       " ('screwdriver', 0.6474739909172058),\n",
       " ('lug', 0.6465184688568115),\n",
       " ('nut', 0.645367443561554),\n",
       " ('keg', 0.6438860893249512),\n",
       " ('snickers', 0.6391291618347168),\n",
       " ('swizzle', 0.6360814571380615)]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"pretzel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('flying', 0.8130614757537842),\n",
       " ('flies', 0.7638437151908875),\n",
       " ('sail', 0.760538637638092),\n",
       " ('cruise', 0.7593040466308594),\n",
       " ('landing', 0.7464283108711243),\n",
       " ('flights', 0.7390480041503906),\n",
       " ('catch', 0.7383242249488831),\n",
       " ('bound', 0.7368704676628113),\n",
       " ('flight', 0.7362315654754639),\n",
       " ('planes', 0.7273046970367432)]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('fly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For corpora, the corpus is never loaded to memory, all corpora are iterables wrapped in\n",
    "a special class ``Dataset``, with an ``__iter__`` method.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
